Calcite parsing passed, start to transform. SELECT COUNT(*) FROM PROJ
[32m- 0000[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM STAFF
[32m- 0001[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM WORKS
[32m- 0002[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM STAFF3
[32m- 0003[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM VTABLE
[32m- 0004[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM UPUNIQ
[32m- 0005[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM CUGINI.AA
[32m- 0006[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM CUGINI.BB
[32m- 0007[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM CUGINI.CC
[32m- 0008[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM CUGINI.DD
[32m- 0009[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM CUGINI.EE
[32m- 0010[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM CUGINI.FF
[32m- 0011[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM CUGINI.GG
[32m- 0012[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM CUGINI.HH
[32m- 0013[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM CUGINI.SRCH1
[32m- 0014[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM CUGINI.BADG1
[32m- 0015[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM CUGINI.BADG2
[32m- 0016[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM BASE_VS1
[32m- 0017[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM USIG
[32m- 0018[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM U_SIG
[32m- 0019[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM PROJ
[32m- 0020[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM STAFF
[32m- 0021[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM WORKS
[32m- 0022[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM STAFF_M
[32m- 0023[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM PROJ_M
[32m- 0024[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM STAFF_C
[32m- 0025[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM SIZ1_P
[32m- 0026[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM SIZ1_F
[32m- 0027[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM SIZ2_P
[32m- 0028[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM SIZ2_F1
[32m- 0029[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM SIZ2_F2
[32m- 0030[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM SIZ2_F3
[32m- 0031[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM SIZ2_F4
[32m- 0032[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM SIZ2_F5
[32m- 0033[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM SIZ2_F6
[32m- 0034[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM SIZ2_F7
[32m- 0035[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM SIZ2_F8
[32m- 0036[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM SIZ2_F9
[32m- 0037[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM SIZ2_F10
[32m- 0038[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM SIZ3_P1
[32m- 0039[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM SIZ3_P2
[32m- 0040[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM SIZ3_P3
[32m- 0041[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM SIZ3_P4
[32m- 0042[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM SIZ3_P5
[32m- 0043[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM SIZ3_P6
[32m- 0044[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM SIZ3_P7
[32m- 0045[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM SIZ3_P8
[32m- 0046[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM SIZ3_P9
[32m- 0047[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM SIZ3_P10
[32m- 0048[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM SIZ3_F
[32m- 0049[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM DEPT
[32m- 0050[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM EMP
[32m- 0051[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM EXPERIENCE
[32m- 0052[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM STAFF_P
[32m- 0053[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM PROJ_P
[32m- 0054[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM ACR_SCH_P
[32m- 0055[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM WORKS_P
[32m- 0056[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM TTT
[32m- 0057[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM STAFF WHERE SUBSTR(EMPNAME,1,3) = 'Ali'
[32m- 0058[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM STAFF WHERE ABS(GRADE) = 12
[32m- 0059[0m
Calcite parsing passed, start to transform. SELECT * FROM CANWEPARSELENGTH18.CHARACTERS18VIEW18
[32m- 0060[0m
Calcite parsing passed, start to transform. SELECT CORRELATIONNAMES18.CHARS18NAME18CHARS FROM CHARACTER18TABLE18 CORRELATIONNAMES18 WHERE CORRELATIONNAMES18.CHARS18NAME18CHARS = 'VAL4'
[32m- 0061[0m
Calcite parsing passed, start to transform. SELECT EMPNUM,PNUM FROM HU.WORKS WHERE EMPNUM='E8'
[32m- 0063[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM DV1
[32m- 0064[0m
Calcite parsing passed, start to transform. SELECT HOURS FROM DV1 ORDER BY HOURS DESC
Calcite parsing passed, start to transform. SELECT HOURS FROM DV1 ORDER BY HOURS DESC
Calcite parsing passed, start to transform. SELECT HOURS FROM DV1 ORDER BY HOURS DESC
[31m- 0065 *** FAILED ***[0m
[31m  Results do not match for 0065:[0m
[31m  == Parsed Logical Plan ==[0m
[31m  'Sort ['HOURS DESC], true[0m
[31m   'Project ['HOURS][0m
[31m    'UnresolvedRelation [DV1], None[0m
  
[31m  == Analyzed Logical Plan ==[0m
[31m  HOURS: double[0m
[31m  Sort [HOURS#7185 DESC], true[0m
[31m   Project [HOURS#7185][0m
[31m    MetastoreRelation FLATER, dv1, None[0m
  
[31m  == Optimized Logical Plan ==[0m
[31m  Sort [HOURS#7185 DESC], true[0m
[31m   Project [HOURS#7185][0m
[31m    MetastoreRelation FLATER, dv1, None[0m
  
[31m  == Physical Plan ==[0m
[31m  TungstenSort [HOURS#7185 DESC], true, 0[0m
[31m   ConvertToUnsafe[0m
[31m    Exchange rangepartitioning(HOURS#7185 DESC)[0m
[31m     HiveTableScan [HOURS#7185], (MetastoreRelation FLATER, dv1, None)[0m
  
[31m  Code Generation: true[0m
[31m  HOURS[0m
[31m  !== HIVE - 4 row(s) ==   == CATALYST - 4 row(s) ==[0m
[31m  !80                      80.0[0m
[31m  !40                      40.0[0m
[31m  !20                      20.0[0m
[31m  !12                      12.0 (HiveComparisonTest.scala:433)[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM VS2 WHERE C1 = 0
[32m- 0066[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM VS2 WHERE C1 = 1
[32m- 0067[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM VS3
[32m- 0068[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM VS4
[32m- 0069[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM VS5
[32m- 0070[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM VS6
[32m- 0071[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM USIG WHERE C1 = 0
[32m- 0072[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM USIG WHERE C1 = 2
[32m- 0073[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM USIG WHERE C_1 = 0
[32m- 0074[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM USIG WHERE C_1 = 2
[32m- 0075[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM USIG WHERE C1 = 4
[32m- 0076[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM U_SIG WHERE C1 = 0
[32m- 0077[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM U_SIG WHERE C1 = 4
[32m- 0078[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM HU.STAFF U_CN WHERE U_CN.GRADE IN (SELECT UCN.GRADE FROM HU.STAFF UCN WHERE UCN.GRADE > 10)
error SELECT COUNT(*) FROM HU.STAFF U_CN WHERE U_CN.GRADE IN (SELECT UCN.GRADE FROM HU.STAFF UCN WHERE UCN.GRADE > 10)[31m- 0079 ***  ***[0m
[31m  java.lang.RuntimeException: Parse failed.[0m
[31m  at scala.sys.package$.error(package.scala:27)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect$$anonfun$parse$1.apply(CalciteDialect.scala:33)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect$$anonfun$parse$1.apply(CalciteDialect.scala:32)[0m
[31m  at scala.Option.getOrElse(Option.scala:120)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect.parse(CalciteDialect.scala:31)[0m
[31m  at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)[0m
[31m  at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)[0m
[31m  at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:115)[0m
[31m  at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:114)[0m
[31m  at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)[0m
[31m  ...[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM HU.STAFF WHERE GRADE > 10
[32m- 0080[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM HU.STAFF WHERE GRADE < 10
[32m- 0081[0m
Calcite parsing passed, start to transform. SELECT EMPNUM, EMPNAME, GRADE, CITY FROM HU.STAFF3 WHERE EMPNUM = 'E1'
Calcite parsing passed, start to transform. SELECT EMPNUM, EMPNAME, GRADE, CITY FROM HU.STAFF3 WHERE EMPNUM = 'E1'
Calcite parsing passed, start to transform. SELECT EMPNUM, EMPNAME, GRADE, CITY FROM HU.STAFF3 WHERE EMPNUM = 'E1'
[31m- 0082 *** FAILED ***[0m
[31m  Results do not match for 0082:[0m
[31m  == Parsed Logical Plan ==[0m
[31m  'Project ['EMPNUM,'EMPNAME,'GRADE,'CITY][0m
[31m   'Filter ('EMPNUM = E1)[0m
[31m    'UnresolvedRelation [HU,STAFF3], None[0m
  
[31m  == Analyzed Logical Plan ==[0m
[31m  EMPNUM: string, EMPNAME: string, GRADE: double, CITY: string[0m
[31m  Project [EMPNUM#9354,EMPNAME#9355,GRADE#9356,CITY#9357][0m
[31m   Filter (EMPNUM#9354 = E1)[0m
[31m    MetastoreRelation hu, staff3, None[0m
  
[31m  == Optimized Logical Plan ==[0m
[31m  Project [EMPNUM#9354,EMPNAME#9355,GRADE#9356,CITY#9357][0m
[31m   Filter (EMPNUM#9354 = E1)[0m
[31m    MetastoreRelation hu, staff3, None[0m
  
[31m  == Physical Plan ==[0m
[31m  Filter (EMPNUM#9354 = E1)[0m
[31m   HiveTableScan [EMPNUM#9354,EMPNAME#9355,GRADE#9356,CITY#9357], (MetastoreRelation hu, staff3, None)[0m
  
[31m  Code Generation: true[0m
[31m  EMPNUM	EMPNAME	GRADE	CITY[0m
[31m  !== HIVE - 1 row(s) ==   == CATALYST - 1 row(s) ==[0m
[31m  !E1	Alice	12	Deale       E1	Alice	12.0	Deale (HiveComparisonTest.scala:433)[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM HU.STAFF3 WHERE CITY = 'Greenmount' OR GRADE = 15
[32m- 0083[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM HU.STAFF3
[32m- 0084[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM HU.STAFF3
[32m- 0085[0m
Calcite parsing passed, start to transform. SELECT EMPNUM, EMPNAME, GRADE, CITY FROM HU.VSTAFF3 WHERE EMPNUM = 'E1'
[32m- 0086[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM HU.VSTAFF3 WHERE CITY = 'Greenmount' OR GRADE = 15
[32m- 0087[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM HU.VSTAFF3
[32m- 0088[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM HU.VSTAFF3
[32m- 0089[0m
Calcite parsing passed, start to transform. SELECT EMPNUM,HOURS FROM WORKS WHERE PNUM='P2' ORDER BY EMPNUM DESC
Calcite parsing passed, start to transform. SELECT EMPNUM,HOURS FROM WORKS WHERE PNUM='P2' ORDER BY EMPNUM DESC
Calcite parsing passed, start to transform. SELECT EMPNUM,HOURS FROM WORKS WHERE PNUM='P2' ORDER BY EMPNUM DESC
[31m- 0090 *** FAILED ***[0m
[31m  Results do not match for 0090:[0m
[31m  == Parsed Logical Plan ==[0m
[31m  'Sort ['EMPNUM DESC], true[0m
[31m   'Project ['EMPNUM,'HOURS][0m
[31m    'Filter ('PNUM = P2)[0m
[31m     'UnresolvedRelation [WORKS], None[0m
  
[31m  == Analyzed Logical Plan ==[0m
[31m  EMPNUM: string, HOURS: double[0m
[31m  Sort [EMPNUM#10493 DESC], true[0m
[31m   Project [EMPNUM#10493,HOURS#10495][0m
[31m    Filter (PNUM#10494 = P2)[0m
[31m     MetastoreRelation HU, works, None[0m
  
[31m  == Optimized Logical Plan ==[0m
[31m  Sort [EMPNUM#10493 DESC], true[0m
[31m   Project [EMPNUM#10493,HOURS#10495][0m
[31m    Filter (PNUM#10494 = P2)[0m
[31m     MetastoreRelation HU, works, None[0m
  
[31m  == Physical Plan ==[0m
[31m  TungstenSort [EMPNUM#10493 DESC], true, 0[0m
[31m   ConvertToUnsafe[0m
[31m    Exchange rangepartitioning(EMPNUM#10493 DESC)[0m
[31m     Project [EMPNUM#10493,HOURS#10495][0m
[31m      Filter (PNUM#10494 = P2)[0m
[31m       HiveTableScan [EMPNUM#10493,HOURS#10495,PNUM#10494], (MetastoreRelation HU, works, None)[0m
  
[31m  Code Generation: true[0m
[31m  EMPNUM	HOURS[0m
[31m  !== HIVE - 3 row(s) ==   == CATALYST - 3 row(s) ==[0m
[31m  !E4	20                   E4	20.0[0m
[31m  !E2	80                   E2	80.0[0m
[31m  !E1	20                   E1	20.0 (HiveComparisonTest.scala:433)[0m
Calcite parsing passed, start to transform. SELECT EMPNUM,HOURS FROM WORKS WHERE PNUM='P2' ORDER BY 2 ASC
Calcite parsing passed, start to transform. SELECT EMPNUM,HOURS FROM WORKS WHERE PNUM='P2' ORDER BY 2 ASC
Calcite parsing passed, start to transform. SELECT EMPNUM,HOURS FROM WORKS WHERE PNUM='P2' ORDER BY 2 ASC
[31m- 0091 *** FAILED ***[0m
[31m  Results do not match for 0091:[0m
[31m  == Parsed Logical Plan ==[0m
[31m  'Sort ['HOURS ASC], true[0m
[31m   'Project ['EMPNUM,'HOURS][0m
[31m    'Filter ('PNUM = P2)[0m
[31m     'UnresolvedRelation [WORKS], None[0m
  
[31m  == Analyzed Logical Plan ==[0m
[31m  EMPNUM: string, HOURS: double[0m
[31m  Sort [HOURS#10829 ASC], true[0m
[31m   Project [EMPNUM#10827,HOURS#10829][0m
[31m    Filter (PNUM#10828 = P2)[0m
[31m     MetastoreRelation HU, works, None[0m
  
[31m  == Optimized Logical Plan ==[0m
[31m  Sort [HOURS#10829 ASC], true[0m
[31m   Project [EMPNUM#10827,HOURS#10829][0m
[31m    Filter (PNUM#10828 = P2)[0m
[31m     MetastoreRelation HU, works, None[0m
  
[31m  == Physical Plan ==[0m
[31m  TungstenSort [HOURS#10829 ASC], true, 0[0m
[31m   ConvertToUnsafe[0m
[31m    Exchange rangepartitioning(HOURS#10829 ASC)[0m
[31m     Project [EMPNUM#10827,HOURS#10829][0m
[31m      Filter (PNUM#10828 = P2)[0m
[31m       HiveTableScan [EMPNUM#10827,HOURS#10829,PNUM#10828], (MetastoreRelation HU, works, None)[0m
  
[31m  Code Generation: true[0m
[31m  EMPNUM	HOURS[0m
[31m  !== HIVE - 3 row(s) ==   == CATALYST - 3 row(s) ==[0m
[31m  !E1	20.0                 E4	20.0[0m
[31m  !E4	20.0                 E1	20.0[0m
[31m   E2	80.0                 E2	80.0 (HiveComparisonTest.scala:433)[0m
Calcite parsing passed, start to transform. SELECT EMPNUM,HOURS FROM WORKS WHERE PNUM = 'P2' ORDER BY 2 DESC,EMPNUM DESC
Calcite parsing passed, start to transform. SELECT EMPNUM,HOURS FROM WORKS WHERE PNUM = 'P2' ORDER BY 2 DESC,EMPNUM DESC
Calcite parsing passed, start to transform. SELECT EMPNUM,HOURS FROM WORKS WHERE PNUM = 'P2' ORDER BY 2 DESC,EMPNUM DESC
[31m- 0092 *** FAILED ***[0m
[31m  Results do not match for 0092:[0m
[31m  == Parsed Logical Plan ==[0m
[31m  'Sort ['HOURS DESC,'EMPNUM DESC], true[0m
[31m   'Project ['EMPNUM,'HOURS][0m
[31m    'Filter ('PNUM = P2)[0m
[31m     'UnresolvedRelation [WORKS], None[0m
  
[31m  == Analyzed Logical Plan ==[0m
[31m  EMPNUM: string, HOURS: double[0m
[31m  Sort [HOURS#11163 DESC,EMPNUM#11161 DESC], true[0m
[31m   Project [EMPNUM#11161,HOURS#11163][0m
[31m    Filter (PNUM#11162 = P2)[0m
[31m     MetastoreRelation HU, works, None[0m
  
[31m  == Optimized Logical Plan ==[0m
[31m  Sort [HOURS#11163 DESC,EMPNUM#11161 DESC], true[0m
[31m   Project [EMPNUM#11161,HOURS#11163][0m
[31m    Filter (PNUM#11162 = P2)[0m
[31m     MetastoreRelation HU, works, None[0m
  
[31m  == Physical Plan ==[0m
[31m  TungstenSort [HOURS#11163 DESC,EMPNUM#11161 DESC], true, 0[0m
[31m   ConvertToUnsafe[0m
[31m    Exchange rangepartitioning(HOURS#11163 DESC,EMPNUM#11161 DESC)[0m
[31m     Project [EMPNUM#11161,HOURS#11163][0m
[31m      Filter (PNUM#11162 = P2)[0m
[31m       HiveTableScan [EMPNUM#11161,HOURS#11163,PNUM#11162], (MetastoreRelation HU, works, None)[0m
  
[31m  Code Generation: true[0m
[31m  EMPNUM	HOURS[0m
[31m  !== HIVE - 3 row(s) ==   == CATALYST - 3 row(s) ==[0m
[31m  !E2	80                   E2	80.0[0m
[31m  !E4	20                   E4	20.0[0m
[31m  !E1	20                   E1	20.0 (HiveComparisonTest.scala:433)[0m
Calcite parsing passed, start to transform. SELECT WORKS.EMPNUM FROM WORKS WHERE WORKS.PNUM = 'P2' UNION SELECT STAFF.EMPNUM FROM STAFF WHERE STAFF.GRADE=13 ORDER BY 1 DESC
error SELECT WORKS.EMPNUM FROM WORKS WHERE WORKS.PNUM = 'P2' UNION SELECT STAFF.EMPNUM FROM STAFF WHERE STAFF.GRADE=13 ORDER BY 1 DESC[31m- 0093 ***  ***[0m
[31m  java.lang.RuntimeException: Parse failed.[0m
[31m  at scala.sys.package$.error(package.scala:27)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect$$anonfun$parse$1.apply(CalciteDialect.scala:33)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect$$anonfun$parse$1.apply(CalciteDialect.scala:32)[0m
[31m  at scala.Option.getOrElse(Option.scala:120)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect.parse(CalciteDialect.scala:31)[0m
[31m  at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)[0m
[31m  at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)[0m
[31m  at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:115)[0m
[31m  at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:114)[0m
[31m  at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)[0m
[31m  ...[0m
Calcite parsing passed, start to transform. SELECT WORKS.EMPNUM FROM WORKS WHERE WORKS.PNUM = 'P2' UNION ALL SELECT STAFF.EMPNUM FROM STAFF WHERE STAFF.GRADE = 13
[32m- 0094[0m
Calcite parsing passed, start to transform. SELECT EMPNAME,PNUM,HOURS FROM STAFF,WORKS WHERE STAFF.EMPNUM = WORKS.EMPNUM UNION SELECT EMPNAME,PNUM,HOURS FROM STAFF,WORKS WHERE NOT EXISTS (SELECT HOURS FROM WORKS WHERE STAFF.EMPNUM = WORKS.EMPNUM)
error SELECT EMPNAME,PNUM,HOURS FROM STAFF,WORKS WHERE STAFF.EMPNUM = WORKS.EMPNUM UNION SELECT EMPNAME,PNUM,HOURS FROM STAFF,WORKS WHERE NOT EXISTS (SELECT HOURS FROM WORKS WHERE STAFF.EMPNUM = WORKS.EMPNUM)[31m- 0095 ***  ***[0m
[31m  java.lang.RuntimeException: Parse failed.[0m
[31m  at scala.sys.package$.error(package.scala:27)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect$$anonfun$parse$1.apply(CalciteDialect.scala:33)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect$$anonfun$parse$1.apply(CalciteDialect.scala:32)[0m
[31m  at scala.Option.getOrElse(Option.scala:120)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect.parse(CalciteDialect.scala:31)[0m
[31m  at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)[0m
[31m  at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)[0m
[31m  at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:115)[0m
[31m  at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:114)[0m
[31m  at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)[0m
[31m  ...[0m
Calcite parsing passed, start to transform. SELECT PNUM,EMPNUM,HOURS FROM WORKS WHERE HOURS=80 UNION SELECT PNUM,EMPNUM,HOURS FROM WORKS WHERE HOURS=40 UNION SELECT PNUM,EMPNUM,HOURS FROM WORKS WHERE HOURS=20 ORDER BY 3,1
error SELECT PNUM,EMPNUM,HOURS FROM WORKS WHERE HOURS=80 UNION SELECT PNUM,EMPNUM,HOURS FROM WORKS WHERE HOURS=40 UNION SELECT PNUM,EMPNUM,HOURS FROM WORKS WHERE HOURS=20 ORDER BY 3,1[31m- 0096 ***  ***[0m
[31m  java.lang.RuntimeException: Parse failed.[0m
[31m  at scala.sys.package$.error(package.scala:27)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect$$anonfun$parse$1.apply(CalciteDialect.scala:33)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect$$anonfun$parse$1.apply(CalciteDialect.scala:32)[0m
[31m  at scala.Option.getOrElse(Option.scala:120)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect.parse(CalciteDialect.scala:31)[0m
[31m  at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)[0m
[31m  at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)[0m
[31m  at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:115)[0m
[31m  at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:114)[0m
[31m  at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)[0m
[31m  ...[0m
Calcite parsing passed, start to transform. SELECT PNUM,EMPNUM,HOURS FROM WORKS WHERE HOURS=12 UNION ALL (SELECT PNUM,EMPNUM,HOURS FROM WORKS UNION SELECT PNUM,EMPNUM,HOURS FROM WORKS WHERE HOURS=80) ORDER BY 2,1
error SELECT PNUM,EMPNUM,HOURS FROM WORKS WHERE HOURS=12 UNION ALL (SELECT PNUM,EMPNUM,HOURS FROM WORKS UNION SELECT PNUM,EMPNUM,HOURS FROM WORKS WHERE HOURS=80) ORDER BY 2,1[31m- 0097 ***  ***[0m
[31m  java.lang.RuntimeException: Parse failed.[0m
[31m  at scala.sys.package$.error(package.scala:27)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect$$anonfun$parse$1.apply(CalciteDialect.scala:33)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect$$anonfun$parse$1.apply(CalciteDialect.scala:32)[0m
[31m  at scala.Option.getOrElse(Option.scala:120)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect.parse(CalciteDialect.scala:31)[0m
[31m  at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)[0m
[31m  at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)[0m
[31m  at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:115)[0m
[31m  at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:114)[0m
[31m  at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)[0m
[31m  ...[0m
Calcite parsing passed, start to transform. SELECT EMPNUM,HOURS FROM WORKS WHERE PNUM = 'P8' ORDER BY EMPNUM DESC
Calcite parsing passed, start to transform. SELECT EMPNUM,HOURS FROM WORKS WHERE PNUM = 'P8' ORDER BY EMPNUM DESC
Calcite parsing passed, start to transform. SELECT EMPNUM,HOURS FROM WORKS WHERE PNUM = 'P8' ORDER BY EMPNUM DESC
[31m- 0098 *** FAILED ***[0m
[31m  Results do not match for 0098:[0m
[31m  == Parsed Logical Plan ==[0m
[31m  'Sort ['EMPNUM DESC], true[0m
[31m   'Project ['EMPNUM,'HOURS][0m
[31m    'Filter ('PNUM = P8)[0m
[31m     'UnresolvedRelation [WORKS], None[0m
  
[31m  == Analyzed Logical Plan ==[0m
[31m  EMPNUM: string, HOURS: double[0m
[31m  Sort [EMPNUM#11983 DESC], true[0m
[31m   Project [EMPNUM#11983,HOURS#11985][0m
[31m    Filter (PNUM#11984 = P8)[0m
[31m     MetastoreRelation HU, works, None[0m
  
[31m  == Optimized Logical Plan ==[0m
[31m  Sort [EMPNUM#11983 DESC], true[0m
[31m   Project [EMPNUM#11983,HOURS#11985][0m
[31m    Filter (PNUM#11984 = P8)[0m
[31m     MetastoreRelation HU, works, None[0m
  
[31m  == Physical Plan ==[0m
[31m  TungstenSort [EMPNUM#11983 DESC], true, 0[0m
[31m   ConvertToUnsafe[0m
[31m    Exchange rangepartitioning(EMPNUM#11983 DESC)[0m
[31m     Project [EMPNUM#11983,HOURS#11985][0m
[31m      Filter (PNUM#11984 = P8)[0m
[31m       HiveTableScan [EMPNUM#11983,HOURS#11985,PNUM#11984], (MetastoreRelation HU, works, None)[0m
  
[31m  Code Generation: true[0m
[31m  EMPNUM	HOURS[0m
[31m  !== HIVE - 1 row(s) ==   == CATALYST - 1 row(s) ==[0m
[31m  !E8	20                   E8	20.0 (HiveComparisonTest.scala:433)[0m
Calcite parsing passed, start to transform. SELECT EMPNUM FROM WORKS WHERE HOURS IS NULL
[32m- 0099[0m
Calcite parsing passed, start to transform. SELECT EMPNUM, HOURS FROM WORKS WHERE PNUM = 'P9' ORDER BY EMPNUM DESC
[32m- 0100[0m
Calcite parsing passed, start to transform. SELECT ALL EMPNUM FROM WORKS WHERE HOURS = 12
[32m- 0101[0m
Calcite parsing passed, start to transform. SELECT EMPNUM FROM WORKS WHERE HOURS = 12
[32m- 0102[0m
Calcite parsing passed, start to transform. SELECT DISTINCT EMPNUM FROM WORKS WHERE HOURS = 12
[32m- 0103[0m
Calcite parsing passed, start to transform. SELECT EMPNUM,PNUM FROM WORKS WHERE EMPNUM = 'E16'
[32m- 0104[0m
Calcite parsing passed, start to transform. SELECT EMPNUM,HOURS FROM WORKS WHERE EMPNUM = 'E1' AND PNUM = 'P4'
Calcite parsing passed, start to transform. SELECT EMPNUM,HOURS FROM WORKS WHERE EMPNUM = 'E1' AND PNUM = 'P4'
Calcite parsing passed, start to transform. SELECT EMPNUM,HOURS FROM WORKS WHERE EMPNUM = 'E1' AND PNUM = 'P4'
[31m- 0105 *** FAILED ***[0m
[31m  Results do not match for 0105:[0m
[31m  == Parsed Logical Plan ==[0m
[31m  'Project ['EMPNUM,'HOURS][0m
[31m   'Filter (('EMPNUM = E1) && ('PNUM = P4))[0m
[31m    'UnresolvedRelation [WORKS], None[0m
  
[31m  == Analyzed Logical Plan ==[0m
[31m  EMPNUM: string, HOURS: double[0m
[31m  Project [EMPNUM#13265,HOURS#13267][0m
[31m   Filter ((EMPNUM#13265 = E1) && (PNUM#13266 = P4))[0m
[31m    MetastoreRelation HU, works, None[0m
  
[31m  == Optimized Logical Plan ==[0m
[31m  Project [EMPNUM#13265,HOURS#13267][0m
[31m   Filter ((EMPNUM#13265 = E1) && (PNUM#13266 = P4))[0m
[31m    MetastoreRelation HU, works, None[0m
  
[31m  == Physical Plan ==[0m
[31m  Project [EMPNUM#13265,HOURS#13267][0m
[31m   Filter ((EMPNUM#13265 = E1) && (PNUM#13266 = P4))[0m
[31m    HiveTableScan [EMPNUM#13265,HOURS#13267,PNUM#13266], (MetastoreRelation HU, works, None)[0m
  
[31m  Code Generation: true[0m
[31m  EMPNUM	HOURS[0m
[31m  !== HIVE - 1 row(s) ==   == CATALYST - 1 row(s) ==[0m
[31m  !E1	20                   E1	20.0 (HiveComparisonTest.scala:433)[0m
Calcite parsing passed, start to transform. SELECT EMPNUM,HOURS FROM   WORKS WHERE  EMPNUM='E18' AND PNUM='P18'
[32m- 0106[0m
Calcite parsing passed, start to transform. SELECT EMPNUM,PNUM FROM   WORKS WHERE  HOURS IS NULL
[32m- 0107[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM TEMP_S
[32m- 0108[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM TEMP_S
[32m- 0109[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM TEMP_S
[32m- 0110[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM STAFF
[32m- 0111[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM STAFF
[32m- 0112[0m
Calcite parsing passed, start to transform. SELECT * FROM TMP WHERE T2 = 23 AND T3 = 'xxxx'
Calcite parsing passed, start to transform. SELECT * FROM TMP WHERE T2 = 23 AND T3 = 'xxxx'
Calcite parsing passed, start to transform. SELECT * FROM TMP WHERE T2 = 23 AND T3 = 'xxxx'
[31m- 0113 *** FAILED ***[0m
[31m  Results do not match for 0113:[0m
[31m  == Parsed Logical Plan ==[0m
[31m  'Project [*][0m
[31m   'Filter (('T2 = 23) && ('T3 = xxxx))[0m
[31m    'UnresolvedRelation [TMP], None[0m
  
[31m  == Analyzed Logical Plan ==[0m
[31m  t1: string, t2: double, t3: string[0m
[31m  Project [t1#14606,t2#14607,t3#14608][0m
[31m   Filter ((T2#14607 = cast(23 as double)) && (T3#14608 = xxxx))[0m
[31m    MetastoreRelation HU, tmp, None[0m
  
[31m  == Optimized Logical Plan ==[0m
[31m  Filter ((T2#14607 = 23.0) && (T3#14608 = xxxx))[0m
[31m   MetastoreRelation HU, tmp, None[0m
  
[31m  == Physical Plan ==[0m
[31m  Filter ((T2#14607 = 23.0) && (T3#14608 = xxxx))[0m
[31m   HiveTableScan [t1#14606,t2#14607,t3#14608], (MetastoreRelation HU, tmp, None)[0m
  
[31m  Code Generation: true[0m
[31m  t1	t2	t3[0m
[31m  !== HIVE - 20 row(s) ==   == CATALYST - 20 row(s) ==[0m
[31m  !xxxx	23	xxxx             xxxx	23.0	xxxx[0m
[31m  !xxxx	23	xxxx             xxxx	23.0	xxxx[0m
[31m  !xxxx	23	xxxx             xxxx	23.0	xxxx[0m
[31m  !xxxx	23	xxxx             xxxx	23.0	xxxx[0m
[31m  !xxxx	23	xxxx             xxxx	23.0	xxxx[0m
[31m  !xxxx	23	xxxx             xxxx	23.0	xxxx[0m
[31m  !xxxx	23	xxxx             xxxx	23.0	xxxx[0m
[31m  !xxxx	23	xxxx             xxxx	23.0	xxxx[0m
[31m  !xxxx	23	xxxx             xxxx	23.0	xxxx[0m
[31m  !xxxx	23	xxxx             xxxx	23.0	xxxx[0m
[31m  !xxxx	23	xxxx             xxxx	23.0	xxxx[0m
[31m  !xxxx	23	xxxx             xxxx	23.0	xxxx[0m
[31m  !xxxx	23	xxxx             xxxx	23.0	xxxx[0m
[31m  !xxxx	23	xxxx             xxxx	23.0	xxxx[0m
[31m  !xxxx	23	xxxx             xxxx	23.0	xxxx[0m
[31m  !xxxx	23	xxxx             xxxx	23.0	xxxx[0m
[31m  !xxxx	23	xxxx             xxxx	23.0	xxxx[0m
[31m  !xxxx	23	xxxx             xxxx	23.0	xxxx[0m
[31m  !xxxx	23	xxxx             xxxx	23.0	xxxx[0m
[31m  !xxxx	23	xxxx             xxxx	23.0	xxxx (HiveComparisonTest.scala:433)[0m
Calcite parsing passed, start to transform. SELECT * FROM TMP WHERE T2 = 23
Calcite parsing passed, start to transform. SELECT * FROM TMP WHERE T2 = 23
Calcite parsing passed, start to transform. SELECT * FROM TMP WHERE T2 = 23
[31m- 0114 *** FAILED ***[0m
[31m  Results do not match for 0114:[0m
[31m  == Parsed Logical Plan ==[0m
[31m  'Project [*][0m
[31m   'Filter ('T2 = 23)[0m
[31m    'UnresolvedRelation [TMP], None[0m
  
[31m  == Analyzed Logical Plan ==[0m
[31m  t1: string, t2: double, t3: string[0m
[31m  Project [t1#14790,t2#14791,t3#14792][0m
[31m   Filter (T2#14791 = cast(23 as double))[0m
[31m    MetastoreRelation HU, tmp, None[0m
  
[31m  == Optimized Logical Plan ==[0m
[31m  Filter (T2#14791 = 23.0)[0m
[31m   MetastoreRelation HU, tmp, None[0m
  
[31m  == Physical Plan ==[0m
[31m  Filter (T2#14791 = 23.0)[0m
[31m   HiveTableScan [t1#14790,t2#14791,t3#14792], (MetastoreRelation HU, tmp, None)[0m
  
[31m  Code Generation: true[0m
[31m  t1	t2	t3[0m
[31m  !== HIVE - 40 row(s) ==     == CATALYST - 40 row(s) ==[0m
[31m  !xxxx	23	xxxx               xxxx	23.0	xxxx[0m
[31m  !xxxx	23	xxxx               xxxx	23.0	xxxx[0m
[31m  !xxxx	23	xxxx               xxxx	23.0	xxxx[0m
[31m  !xxxx	23	xxxx               xxxx	23.0	xxxx[0m
[31m  !xxxx	23	xxxx               xxxx	23.0	xxxx[0m
[31m  !xxxx	23	xxxx               xxxx	23.0	xxxx[0m
[31m  !xxxx	23	xxxx               xxxx	23.0	xxxx[0m
[31m  !xxxx	23	xxxx               xxxx	23.0	xxxx[0m
[31m  !xxxx	23	xxxx               xxxx	23.0	xxxx[0m
[31m  !xxxx	23	xxxx               xxxx	23.0	xxxx[0m
[31m  !xxxx	23	xxxx               xxxx	23.0	xxxx[0m
[31m  !xxxx	23	xxxx               xxxx	23.0	xxxx[0m
[31m  !xxxx	23	xxxx               xxxx	23.0	xxxx[0m
[31m  !xxxx	23	xxxx               xxxx	23.0	xxxx[0m
[31m  !xxxx	23	xxxx               xxxx	23.0	xxxx[0m
[31m  !xxxx	23	xxxx               xxxx	23.0	xxxx[0m
[31m  !xxxx	23	xxxx               xxxx	23.0	xxxx[0m
[31m  !xxxx	23	xxxx               xxxx	23.0	xxxx[0m
[31m  !xxxx	23	xxxx               xxxx	23.0	xxxx[0m
[31m  !xxxx	23	xxxx               xxxx	23.0	xxxx[0m
[31m  !xxxxxxxxxx	23	xxxxxxxxxx   xxxxxxxxxx	23.0	xxxxxxxxxx[0m
[31m  !xxxxxxxxxx	23	xxxxxxxxxx   xxxxxxxxxx	23.0	xxxxxxxxxx[0m
[31m  !xxxxxxxxxx	23	xxxxxxxxxx   xxxxxxxxxx	23.0	xxxxxxxxxx[0m
[31m  !xxxxxxxxxx	23	xxxxxxxxxx   xxxxxxxxxx	23.0	xxxxxxxxxx[0m
[31m  !xxxxxxxxxx	23	xxxxxxxxxx   xxxxxxxxxx	23.0	xxxxxxxxxx[0m
[31m  !xxxxxxxxxx	23	xxxxxxxxxx   xxxxxxxxxx	23.0	xxxxxxxxxx[0m
[31m  !xxxxxxxxxx	23	xxxxxxxxxx   xxxxxxxxxx	23.0	xxxxxxxxxx[0m
[31m  !xxxxxxxxxx	23	xxxxxxxxxx   xxxxxxxxxx	23.0	xxxxxxxxxx[0m
[31m  !xxxxxxxxxx	23	xxxxxxxxxx   xxxxxxxxxx	23.0	xxxxxxxxxx[0m
[31m  !xxxxxxxxxx	23	xxxxxxxxxx   xxxxxxxxxx	23.0	xxxxxxxxxx[0m
[31m  !xxxxxxxxxx	23	xxxxxxxxxx   xxxxxxxxxx	23.0	xxxxxxxxxx[0m
[31m  !xxxxxxxxxx	23	xxxxxxxxxx   xxxxxxxxxx	23.0	xxxxxxxxxx[0m
[31m  !xxxxxxxxxx	23	xxxxxxxxxx   xxxxxxxxxx	23.0	xxxxxxxxxx[0m
[31m  !xxxxxxxxxx	23	xxxxxxxxxx   xxxxxxxxxx	23.0	xxxxxxxxxx[0m
[31m  !xxxxxxxxxx	23	xxxxxxxxxx   xxxxxxxxxx	23.0	xxxxxxxxxx[0m
[31m  !xxxxxxxxxx	23	xxxxxxxxxx   xxxxxxxxxx	23.0	xxxxxxxxxx[0m
[31m  !xxxxxxxxxx	23	xxxxxxxxxx   xxxxxxxxxx	23.0	xxxxxxxxxx[0m
[31m  !xxxxxxxxxx	23	xxxxxxxxxx   xxxxxxxxxx	23.0	xxxxxxxxxx[0m
[31m  !xxxxxxxxxx	23	xxxxxxxxxx   xxxxxxxxxx	23.0	xxxxxxxxxx[0m
[31m  !xxxxxxxxxx	23	xxxxxxxxxx   xxxxxxxxxx	23.0	xxxxxxxxxx (HiveComparisonTest.scala:433)[0m
Calcite parsing passed, start to transform. SELECT * FROM   TMP WHERE  T2 IS NULL
[32m- 0115[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM TEMP_SS WHERE GRADE = 15
[32m- 0116[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM STAFF WHERE GRADE = 26
[32m- 0117[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM   STAFF WHERE  GRADE=130
[32m- 0118[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM STAFF WHERE GRADE = 11
[32m- 0119[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM STAFF WHERE GRADE = 11
[32m- 0120[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM STAFF
[32m- 0121[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM STAFF
[32m- 0122[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM STAFF
[32m- 0123[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM WORKS
[32m- 0124[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM WORKS
[32m- 0125[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM WORKS
[32m- 0126[0m
Calcite parsing passed, start to transform. SELECT COUNT(DISTINCT HOURS) FROM WORKS
[32m- 0127[0m
Calcite parsing passed, start to transform. SELECT SUM(ALL HOURS) FROM WORKS
Calcite parsing passed, start to transform. SELECT SUM(ALL HOURS) FROM WORKS
Calcite parsing passed, start to transform. SELECT SUM(ALL HOURS) FROM WORKS
[31m- 0128 *** FAILED ***[0m
[31m  Results do not match for 0128:[0m
[31m  == Parsed Logical Plan ==[0m
[31m  'Project ['SUM('HOURS) AS c0#17417][0m
[31m   'UnresolvedRelation [WORKS], None[0m
  
[31m  == Analyzed Logical Plan ==[0m
[31m  c0: double[0m
[31m  Aggregate [sum(HOURS#17420) AS c0#17417][0m
[31m   MetastoreRelation HU, works, None[0m
  
[31m  == Optimized Logical Plan ==[0m
[31m  Aggregate [sum(HOURS#17420) AS c0#17417][0m
[31m   Project [HOURS#17420][0m
[31m    MetastoreRelation HU, works, None[0m
  
[31m  == Physical Plan ==[0m
[31m  TungstenAggregate(key=[], functions=[(sum(HOURS#17420),mode=Final,isDistinct=false)], output=[c0#17417])[0m
[31m   TungstenExchange SinglePartition[0m
[31m    TungstenAggregate(key=[], functions=[(sum(HOURS#17420),mode=Partial,isDistinct=false)], output=[currentSum#17423])[0m
[31m     HiveTableScan [HOURS#17420], (MetastoreRelation HU, works, None)[0m
  
[31m  Code Generation: true[0m
[31m  c0[0m
[31m  !== HIVE - 1 row(s) ==   == CATALYST - 1 row(s) ==[0m
[31m  !384                     384.0 (HiveComparisonTest.scala:433)[0m
Calcite parsing passed, start to transform. SELECT SUM(HOURS) FROM WORKS
Calcite parsing passed, start to transform. SELECT SUM(HOURS) FROM WORKS
Calcite parsing passed, start to transform. SELECT SUM(HOURS) FROM WORKS
[31m- 0129 *** FAILED ***[0m
[31m  Results do not match for 0129:[0m
[31m  == Parsed Logical Plan ==[0m
[31m  'Project ['SUM('HOURS) AS c0#17766][0m
[31m   'UnresolvedRelation [WORKS], None[0m
  
[31m  == Analyzed Logical Plan ==[0m
[31m  c0: double[0m
[31m  Aggregate [sum(HOURS#17769) AS c0#17766][0m
[31m   MetastoreRelation HU, works, None[0m
  
[31m  == Optimized Logical Plan ==[0m
[31m  Aggregate [sum(HOURS#17769) AS c0#17766][0m
[31m   Project [HOURS#17769][0m
[31m    MetastoreRelation HU, works, None[0m
  
[31m  == Physical Plan ==[0m
[31m  TungstenAggregate(key=[], functions=[(sum(HOURS#17769),mode=Final,isDistinct=false)], output=[c0#17766])[0m
[31m   TungstenExchange SinglePartition[0m
[31m    TungstenAggregate(key=[], functions=[(sum(HOURS#17769),mode=Partial,isDistinct=false)], output=[currentSum#17772])[0m
[31m     HiveTableScan [HOURS#17769], (MetastoreRelation HU, works, None)[0m
  
[31m  Code Generation: true[0m
[31m  c0[0m
[31m  !== HIVE - 1 row(s) ==   == CATALYST - 1 row(s) ==[0m
[31m  !384                     384.0 (HiveComparisonTest.scala:433)[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM WORKS
[32m- 0130[0m
Calcite parsing passed, start to transform. SELECT SUM(HOURS) FROM WORKS WHERE PNUM = 'P2'
Calcite parsing passed, start to transform. SELECT SUM(HOURS) FROM WORKS WHERE PNUM = 'P2'
Calcite parsing passed, start to transform. SELECT SUM(HOURS) FROM WORKS WHERE PNUM = 'P2'
[31m- 0131 *** FAILED ***[0m
[31m  Results do not match for 0131:[0m
[31m  == Parsed Logical Plan ==[0m
[31m  'Project ['SUM('HOURS) AS c0#18278][0m
[31m   'Filter ('PNUM = P2)[0m
[31m    'UnresolvedRelation [WORKS], None[0m
  
[31m  == Analyzed Logical Plan ==[0m
[31m  c0: double[0m
[31m  Aggregate [sum(HOURS#18281) AS c0#18278][0m
[31m   Filter (PNUM#18280 = P2)[0m
[31m    MetastoreRelation HU, works, None[0m
  
[31m  == Optimized Logical Plan ==[0m
[31m  Aggregate [sum(HOURS#18281) AS c0#18278][0m
[31m   Project [HOURS#18281][0m
[31m    Filter (PNUM#18280 = P2)[0m
[31m     MetastoreRelation HU, works, None[0m
  
[31m  == Physical Plan ==[0m
[31m  TungstenAggregate(key=[], functions=[(sum(HOURS#18281),mode=Final,isDistinct=false)], output=[c0#18278])[0m
[31m   TungstenExchange SinglePartition[0m
[31m    TungstenAggregate(key=[], functions=[(sum(HOURS#18281),mode=Partial,isDistinct=false)], output=[currentSum#18284])[0m
[31m     Project [HOURS#18281][0m
[31m      Filter (PNUM#18280 = P2)[0m
[31m       HiveTableScan [HOURS#18281,PNUM#18280], (MetastoreRelation HU, works, None)[0m
  
[31m  Code Generation: true[0m
[31m  c0[0m
[31m  !== HIVE - 1 row(s) ==   == CATALYST - 1 row(s) ==[0m
[31m  !120                     120.0 (HiveComparisonTest.scala:433)[0m
Calcite parsing passed, start to transform. SELECT SUM(DISTINCT HOURS) FROM WORKS WHERE PNUM = 'P2'
Calcite parsing passed, start to transform. SELECT SUM(DISTINCT HOURS) FROM WORKS WHERE PNUM = 'P2'
Calcite parsing passed, start to transform. SELECT SUM(DISTINCT HOURS) FROM WORKS WHERE PNUM = 'P2'
[31m- 0132 *** FAILED ***[0m
[31m  Results do not match for 0132:[0m
[31m  == Parsed Logical Plan ==[0m
[31m  'Project [SUM(DISTINCT 'HOURS) AS c0#18627][0m
[31m   'Filter ('PNUM = P2)[0m
[31m    'UnresolvedRelation [WORKS], None[0m
  
[31m  == Analyzed Logical Plan ==[0m
[31m  c0: double[0m
[31m  Aggregate [SUM(DISTINCT HOURS#18630) AS c0#18627][0m
[31m   Filter (PNUM#18629 = P2)[0m
[31m    MetastoreRelation HU, works, None[0m
  
[31m  == Optimized Logical Plan ==[0m
[31m  Aggregate [SUM(DISTINCT HOURS#18630) AS c0#18627][0m
[31m   Project [HOURS#18630][0m
[31m    Filter (PNUM#18629 = P2)[0m
[31m     MetastoreRelation HU, works, None[0m
  
[31m  == Physical Plan ==[0m
[31m  TungstenAggregate(key=[], functions=[(sum(HOURS#18630),mode=Complete,isDistinct=true)], output=[c0#18627])[0m
[31m   TungstenAggregate(key=[HOURS#18630], functions=[], output=[HOURS#18630])[0m
[31m    TungstenExchange SinglePartition[0m
[31m     TungstenAggregate(key=[HOURS#18630], functions=[], output=[HOURS#18630])[0m
[31m      Project [HOURS#18630][0m
[31m       Filter (PNUM#18629 = P2)[0m
[31m        HiveTableScan [HOURS#18630,PNUM#18629], (MetastoreRelation HU, works, None)[0m
  
[31m  Code Generation: true[0m
[31m  c0[0m
[31m  !== HIVE - 1 row(s) ==   == CATALYST - 1 row(s) ==[0m
[31m  !100                     100.0 (HiveComparisonTest.scala:433)[0m
Calcite parsing passed, start to transform. SELECT SUM(HOURS)+10 FROM WORKS WHERE PNUM = 'P2'
Calcite parsing passed, start to transform. SELECT SUM(HOURS)+10 FROM WORKS WHERE PNUM = 'P2'
Calcite parsing passed, start to transform. SELECT SUM(HOURS)+10 FROM WORKS WHERE PNUM = 'P2'
[31m- 0133 *** FAILED ***[0m
[31m  Results do not match for 0133:[0m
[31m  == Parsed Logical Plan ==[0m
[31m  'Project [('SUM('HOURS) + 10) AS c0#18976][0m
[31m   'Filter ('PNUM = P2)[0m
[31m    'UnresolvedRelation [WORKS], None[0m
  
[31m  == Analyzed Logical Plan ==[0m
[31m  c0: double[0m
[31m  Aggregate [(sum(HOURS#18979) + cast(10 as double)) AS c0#18976][0m
[31m   Filter (PNUM#18978 = P2)[0m
[31m    MetastoreRelation HU, works, None[0m
  
[31m  == Optimized Logical Plan ==[0m
[31m  Aggregate [(sum(HOURS#18979) + 10.0) AS c0#18976][0m
[31m   Project [HOURS#18979][0m
[31m    Filter (PNUM#18978 = P2)[0m
[31m     MetastoreRelation HU, works, None[0m
  
[31m  == Physical Plan ==[0m
[31m  TungstenAggregate(key=[], functions=[(sum(HOURS#18979),mode=Final,isDistinct=false)], output=[c0#18976])[0m
[31m   TungstenExchange SinglePartition[0m
[31m    TungstenAggregate(key=[], functions=[(sum(HOURS#18979),mode=Partial,isDistinct=false)], output=[currentSum#18982])[0m
[31m     Project [HOURS#18979][0m
[31m      Filter (PNUM#18978 = P2)[0m
[31m       HiveTableScan [HOURS#18979,PNUM#18978], (MetastoreRelation HU, works, None)[0m
  
[31m  Code Generation: true[0m
[31m  c0[0m
[31m  !== HIVE - 1 row(s) ==   == CATALYST - 1 row(s) ==[0m
[31m  !130                     130.0 (HiveComparisonTest.scala:433)[0m
Calcite parsing passed, start to transform. SELECT EMPNUM FROM STAFF WHERE GRADE = (SELECT MAX(GRADE) FROM STAFF) ORDER BY EMPNUM
error SELECT EMPNUM FROM STAFF WHERE GRADE = (SELECT MAX(GRADE) FROM STAFF) ORDER BY EMPNUM[31m- 0134 ***  ***[0m
[31m  java.lang.RuntimeException: Parse failed.[0m
[31m  at scala.sys.package$.error(package.scala:27)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect$$anonfun$parse$1.apply(CalciteDialect.scala:33)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect$$anonfun$parse$1.apply(CalciteDialect.scala:32)[0m
[31m  at scala.Option.getOrElse(Option.scala:120)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect.parse(CalciteDialect.scala:31)[0m
[31m  at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)[0m
[31m  at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)[0m
[31m  at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:115)[0m
[31m  at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:114)[0m
[31m  at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)[0m
[31m  ...[0m
Calcite parsing passed, start to transform. SELECT EMPNUM FROM STAFF WHERE GRADE = (SELECT MIN(GRADE) FROM STAFF)
error SELECT EMPNUM FROM STAFF WHERE GRADE = (SELECT MIN(GRADE) FROM STAFF)[31m- 0135 ***  ***[0m
[31m  java.lang.RuntimeException: Parse failed.[0m
[31m  at scala.sys.package$.error(package.scala:27)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect$$anonfun$parse$1.apply(CalciteDialect.scala:33)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect$$anonfun$parse$1.apply(CalciteDialect.scala:32)[0m
[31m  at scala.Option.getOrElse(Option.scala:120)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect.parse(CalciteDialect.scala:31)[0m
[31m  at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)[0m
[31m  at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)[0m
[31m  at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:115)[0m
[31m  at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:114)[0m
[31m  at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)[0m
[31m  ...[0m
Calcite parsing passed, start to transform. SELECT AVG(GRADE) FROM STAFF
[32m- 0136[0m
Calcite parsing passed, start to transform. SELECT AVG(GRADE) FROM   TEMP_S
[32m- 0137[0m
Calcite parsing passed, start to transform. SELECT PNUM FROM PROJ WHERE BUDGET BETWEEN 40000 AND 60000
[32m- 0138[0m
Calcite parsing passed, start to transform. SELECT PNUM FROM PROJ WHERE BUDGET >= 40000 AND BUDGET <= 60000
[32m- 0139[0m
Calcite parsing passed, start to transform. SELECT CITY FROM STAFF WHERE GRADE NOT BETWEEN 12 AND 13
[32m- 0140[0m
Calcite parsing passed, start to transform. SELECT CITY FROM STAFF WHERE NOT(GRADE BETWEEN 12 AND 13)
[32m- 0141[0m
Calcite parsing passed, start to transform. SELECT STAFF.EMPNAME FROM STAFF WHERE STAFF.EMPNUM IN (SELECT WORKS.EMPNUM FROM WORKS WHERE WORKS.PNUM IN (SELECT PROJ.PNUM FROM PROJ WHERE PROJ.CITY='Tampa'))
error SELECT STAFF.EMPNAME FROM STAFF WHERE STAFF.EMPNUM IN (SELECT WORKS.EMPNUM FROM WORKS WHERE WORKS.PNUM IN (SELECT PROJ.PNUM FROM PROJ WHERE PROJ.CITY='Tampa'))[31m- 0142 ***  ***[0m
[31m  java.lang.RuntimeException: Parse failed.[0m
[31m  at scala.sys.package$.error(package.scala:27)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect$$anonfun$parse$1.apply(CalciteDialect.scala:33)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect$$anonfun$parse$1.apply(CalciteDialect.scala:32)[0m
[31m  at scala.Option.getOrElse(Option.scala:120)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect.parse(CalciteDialect.scala:31)[0m
[31m  at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)[0m
[31m  at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)[0m
[31m  at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:115)[0m
[31m  at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:114)[0m
[31m  at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)[0m
[31m  ...[0m
NoViableAltException(231@[])
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.function(HiveParser_IdentifiersParser.java:3544)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.atomExpression(HiveParser_IdentifiersParser.java:6280)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceFieldExpression(HiveParser_IdentifiersParser.java:6383)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceUnaryPrefixExpression(HiveParser_IdentifiersParser.java:6768)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceUnarySuffixExpression(HiveParser_IdentifiersParser.java:6828)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceBitwiseXorExpression(HiveParser_IdentifiersParser.java:7012)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceStarExpression(HiveParser_IdentifiersParser.java:7172)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedencePlusExpression(HiveParser_IdentifiersParser.java:7332)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceAmpersandExpression(HiveParser_IdentifiersParser.java:7483)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceBitwiseOrExpression(HiveParser_IdentifiersParser.java:7634)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceEqualExpression(HiveParser_IdentifiersParser.java:8290)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceNotExpression(HiveParser_IdentifiersParser.java:9177)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceAndExpression(HiveParser_IdentifiersParser.java:9296)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceOrExpression(HiveParser_IdentifiersParser.java:9455)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.expression(HiveParser_IdentifiersParser.java:6105)
	at org.apache.hadoop.hive.ql.parse.HiveParser.expression(HiveParser.java:45846)
	at org.apache.hadoop.hive.ql.parse.HiveParser_FromClauseParser.searchCondition(HiveParser_FromClauseParser.java:6637)
	at org.apache.hadoop.hive.ql.parse.HiveParser_FromClauseParser.whereClause(HiveParser_FromClauseParser.java:6545)
	at org.apache.hadoop.hive.ql.parse.HiveParser.whereClause(HiveParser.java:45849)
	at org.apache.hadoop.hive.ql.parse.HiveParser.selectStatement(HiveParser.java:41543)
	at org.apache.hadoop.hive.ql.parse.HiveParser.regularBody(HiveParser.java:41402)
	at org.apache.hadoop.hive.ql.parse.HiveParser.queryStatementExpressionBody(HiveParser.java:40413)
	at org.apache.hadoop.hive.ql.parse.HiveParser.queryStatementExpression(HiveParser.java:40283)
	at org.apache.hadoop.hive.ql.parse.HiveParser.execStatement(HiveParser.java:1590)
	at org.apache.hadoop.hive.ql.parse.HiveParser.statement(HiveParser.java:1109)
	at org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:202)
	at org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:166)
	at org.apache.spark.sql.hive.HiveQl$.getAst(HiveQl.scala:258)
	at org.apache.spark.sql.hive.HiveQl$.createPlan(HiveQl.scala:283)
	at org.apache.spark.sql.hive.ExtendedHiveQlParser$$anonfun$hiveQl$1.apply(ExtendedHiveQlParser.scala:41)
	at org.apache.spark.sql.hive.ExtendedHiveQlParser$$anonfun$hiveQl$1.apply(ExtendedHiveQlParser.scala:40)
	at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)
	at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:135)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)
	at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Failure.append(Parsers.scala:202)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)
	at scala.util.parsing.combinator.Parsers$$anon$2$$anonfun$apply$14.apply(Parsers.scala:891)
	at scala.util.parsing.combinator.Parsers$$anon$2$$anonfun$apply$14.apply(Parsers.scala:891)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)
	at scala.util.parsing.combinator.Parsers$$anon$2.apply(Parsers.scala:890)
	at scala.util.parsing.combinator.PackratParsers$$anon$1.apply(PackratParsers.scala:110)
	at org.apache.spark.sql.catalyst.AbstractSparkSQLParser.parse(AbstractSparkSQLParser.scala:34)
	at org.apache.spark.sql.hive.HiveQl$.parseSql(HiveQl.scala:276)
	at org.apache.spark.sql.hive.HiveQLDialect.parse(HiveContext.scala:62)
	at com.intel.ssg.bdt.spark.sql.CalciteDialect.getLogicalPlan(CalciteDialect.scala:54)
	at com.intel.ssg.bdt.spark.sql.CalciteDialect.parse(CalciteDialect.scala:31)
	at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)
	at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)
	at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:115)
	at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:114)
	at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)
	at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:135)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)
	at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Failure.append(Parsers.scala:202)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)
	at scala.util.parsing.combinator.Parsers$$anon$2$$anonfun$apply$14.apply(Parsers.scala:891)
	at scala.util.parsing.combinator.Parsers$$anon$2$$anonfun$apply$14.apply(Parsers.scala:891)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)
	at scala.util.parsing.combinator.Parsers$$anon$2.apply(Parsers.scala:890)
	at scala.util.parsing.combinator.PackratParsers$$anon$1.apply(PackratParsers.scala:110)
	at org.apache.spark.sql.catalyst.AbstractSparkSQLParser.parse(AbstractSparkSQLParser.scala:34)
	at org.apache.spark.sql.SQLContext$$anonfun$2.apply(SQLContext.scala:166)
	at org.apache.spark.sql.SQLContext$$anonfun$2.apply(SQLContext.scala:166)
	at org.apache.spark.sql.execution.datasources.DDLParser.parse(DDLParser.scala:42)
	at org.apache.spark.sql.SQLContext.parseSql(SQLContext.scala:189)
	at org.apache.spark.sql.hive.HiveContext.parseSql(HiveContext.scala:280)
	at org.apache.spark.sql.hive.test.TestHiveContext$QueryExecution.<init>(TestHive.scala:179)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1$$anonfun$30.apply(HiveComparisonTest.scala:303)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1$$anonfun$30.apply(HiveComparisonTest.scala:303)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:34)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:244)
	at scala.collection.AbstractTraversable.map(Traversable.scala:105)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1.apply$mcV$sp(HiveComparisonTest.scala:303)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1.apply(HiveComparisonTest.scala:240)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1.apply(HiveComparisonTest.scala:240)
	at org.scalatest.Transformer$$anonfun$apply$1.apply$mcV$sp(Transformer.scala:22)
	at org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)
	at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
	at org.scalatest.Transformer.apply(Transformer.scala:22)
	at org.scalatest.Transformer.apply(Transformer.scala:20)
	at org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:166)
	at org.apache.spark.SparkFunSuite.withFixture(SparkFunSuite.scala:42)
	at org.scalatest.FunSuiteLike$class.invokeWithFixture$1(FunSuiteLike.scala:163)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)
	at org.scalatest.FunSuiteLike$class.runTest(FunSuiteLike.scala:175)
	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.org$scalatest$BeforeAndAfter$$super$runTest(HiveCompatibilitySuite.scala:32)
	at org.scalatest.BeforeAndAfter$class.runTest(BeforeAndAfter.scala:200)
	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.runTest(HiveCompatibilitySuite.scala:32)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:413)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:401)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)
	at org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:396)
	at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:483)
	at org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:208)
	at org.scalatest.FunSuite.runTests(FunSuite.scala:1555)
	at org.scalatest.Suite$class.run(Suite.scala:1424)
	at org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.SuperEngine.runImpl(Engine.scala:545)
	at org.scalatest.FunSuiteLike$class.run(FunSuiteLike.scala:212)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest.org$scalatest$BeforeAndAfterAll$$super$run(HiveComparisonTest.scala:44)
	at org.scalatest.BeforeAndAfterAll$class.liftedTree1$1(BeforeAndAfterAll.scala:257)
	at org.scalatest.BeforeAndAfterAll$class.run(BeforeAndAfterAll.scala:256)
	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.org$scalatest$BeforeAndAfter$$super$run(HiveCompatibilitySuite.scala:32)
	at org.scalatest.BeforeAndAfter$class.run(BeforeAndAfter.scala:241)
	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.run(HiveCompatibilitySuite.scala:32)
	at org.scalatest.Suite$class.callExecuteOnSuite$1(Suite.scala:1492)
	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1528)
	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1526)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.scalatest.Suite$class.runNestedSuites(Suite.scala:1526)
	at org.scalatest.tools.DiscoverySuite.runNestedSuites(DiscoverySuite.scala:29)
	at org.scalatest.Suite$class.run(Suite.scala:1421)
	at org.scalatest.tools.DiscoverySuite.run(DiscoverySuite.scala:29)
	at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:55)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2563)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2557)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:2557)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1044)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1043)
	at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:2722)
	at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1043)
	at org.scalatest.tools.Runner$.main(Runner.scala:860)
	at org.scalatest.tools.Runner.main(Runner.scala)
[31m- 0143 *** FAILED ***[0m
[31m  org.apache.spark.sql.AnalysisException: cannot recognize input near 'SELECT' 'WORKS' '.' in function specification; line 1 pos 58[0m
[31m  at org.apache.spark.sql.hive.HiveQl$.createPlan(HiveQl.scala:296)[0m
[31m  at org.apache.spark.sql.hive.ExtendedHiveQlParser$$anonfun$hiveQl$1.apply(ExtendedHiveQlParser.scala:41)[0m
[31m  at org.apache.spark.sql.hive.ExtendedHiveQlParser$$anonfun$hiveQl$1.apply(ExtendedHiveQlParser.scala:40)[0m
[31m  at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)[0m
[31m  at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:135)[0m
[31m  at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)[0m
[31m  at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)[0m
[31m  at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)[0m
[31m  at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)[0m
[31m  at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)[0m
[31m  ...[0m
Calcite parsing passed, start to transform. SELECT WORKS.HOURS FROM WORKS WHERE WORKS.PNUM NOT IN (SELECT PROJ.PNUM FROM PROJ WHERE PROJ.BUDGET BETWEEN 5000 AND 40000)
error SELECT WORKS.HOURS FROM WORKS WHERE WORKS.PNUM NOT IN (SELECT PROJ.PNUM FROM PROJ WHERE PROJ.BUDGET BETWEEN 5000 AND 40000)[31m- 0144 ***  ***[0m
[31m  java.lang.RuntimeException: Parse failed.[0m
[31m  at scala.sys.package$.error(package.scala:27)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect$$anonfun$parse$1.apply(CalciteDialect.scala:33)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect$$anonfun$parse$1.apply(CalciteDialect.scala:32)[0m
[31m  at scala.Option.getOrElse(Option.scala:120)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect.parse(CalciteDialect.scala:31)[0m
[31m  at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)[0m
[31m  at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)[0m
[31m  at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:115)[0m
[31m  at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:114)[0m
[31m  at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)[0m
[31m  ...[0m
Calcite parsing passed, start to transform. SELECT WORKS.HOURS FROM WORKS WHERE NOT (WORKS.PNUM IN (SELECT PROJ.PNUM FROM PROJ WHERE PROJ.BUDGET BETWEEN 5000 AND 40000))
error SELECT WORKS.HOURS FROM WORKS WHERE NOT (WORKS.PNUM IN (SELECT PROJ.PNUM FROM PROJ WHERE PROJ.BUDGET BETWEEN 5000 AND 40000))[31m- 0145 ***  ***[0m
[31m  java.lang.RuntimeException: Parse failed.[0m
[31m  at scala.sys.package$.error(package.scala:27)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect$$anonfun$parse$1.apply(CalciteDialect.scala:33)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect$$anonfun$parse$1.apply(CalciteDialect.scala:32)[0m
[31m  at scala.Option.getOrElse(Option.scala:120)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect.parse(CalciteDialect.scala:31)[0m
[31m  at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)[0m
[31m  at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)[0m
[31m  at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:115)[0m
[31m  at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:114)[0m
[31m  at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)[0m
[31m  ...[0m
Calcite parsing passed, start to transform. SELECT HOURS FROM WORKS WHERE PNUM NOT IN (SELECT PNUM FROM WORKS WHERE PNUM IN ('P1','P2','P4','P5','P6'))
error SELECT HOURS FROM WORKS WHERE PNUM NOT IN (SELECT PNUM FROM WORKS WHERE PNUM IN ('P1','P2','P4','P5','P6'))[31m- 0146 ***  ***[0m
[31m  java.lang.RuntimeException: Parse failed.[0m
[31m  at scala.sys.package$.error(package.scala:27)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect$$anonfun$parse$1.apply(CalciteDialect.scala:33)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect$$anonfun$parse$1.apply(CalciteDialect.scala:32)[0m
[31m  at scala.Option.getOrElse(Option.scala:120)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect.parse(CalciteDialect.scala:31)[0m
[31m  at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)[0m
[31m  at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)[0m
[31m  at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:115)[0m
[31m  at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:114)[0m
[31m  at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)[0m
[31m  ...[0m
Calcite parsing passed, start to transform. SELECT HOURS FROM WORKS WHERE NOT (PNUM IN (SELECT PNUM FROM WORKS WHERE PNUM IN ('P1','P2','P4','P5','P6')))
error SELECT HOURS FROM WORKS WHERE NOT (PNUM IN (SELECT PNUM FROM WORKS WHERE PNUM IN ('P1','P2','P4','P5','P6')))[31m- 0147 ***  ***[0m
[31m  java.lang.RuntimeException: Parse failed.[0m
[31m  at scala.sys.package$.error(package.scala:27)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect$$anonfun$parse$1.apply(CalciteDialect.scala:33)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect$$anonfun$parse$1.apply(CalciteDialect.scala:32)[0m
[31m  at scala.Option.getOrElse(Option.scala:120)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect.parse(CalciteDialect.scala:31)[0m
[31m  at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)[0m
[31m  at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)[0m
[31m  at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:115)[0m
[31m  at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:114)[0m
[31m  at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)[0m
[31m  ...[0m
Calcite parsing passed, start to transform. SELECT EMPNAME FROM STAFF WHERE EMPNAME LIKE 'Al%'
[32m- 0148[0m
Calcite parsing passed, start to transform. SELECT CITY FROM STAFF WHERE EMPNAME LIKE 'B__t%'
[32m- 0149[0m
Calcite parsing passed, start to transform. SELECT CITY FROM STAFF WHERE CITY LIKE 'XiS___S%%' ESCAPE 'S'
Calcite parsing passed, start to transform. SELECT CITY FROM STAFF WHERE CITY LIKE 'XiS___S%%' ESCAPE 'S'
Calcite parsing passed, start to transform. SELECT CITY FROM STAFF WHERE CITY LIKE 'XiS___S%%' ESCAPE 'S'
[31m- 0150 *** FAILED ***[0m
[31m  Results do not match for 0150:[0m
[31m  == Parsed Logical Plan ==[0m
[31m  'Project ['CITY][0m
[31m   'Filter 'CITY LIKE XiS___S%%[0m
[31m    'UnresolvedRelation [STAFF], None[0m
  
[31m  == Analyzed Logical Plan ==[0m
[31m  CITY: string[0m
[31m  Project [CITY#21199][0m
[31m   Filter CITY#21199 LIKE XiS___S%%[0m
[31m    MetastoreRelation HU, staff, None[0m
  
[31m  == Optimized Logical Plan ==[0m
[31m  Project [CITY#21199][0m
[31m   Filter CITY#21199 LIKE XiS___S%%[0m
[31m    MetastoreRelation HU, staff, None[0m
  
[31m  == Physical Plan ==[0m
[31m  Filter CITY#21199 LIKE XiS___S%%[0m
[31m   HiveTableScan [CITY#21199], (MetastoreRelation HU, staff, None)[0m
  
[31m  Code Generation: true[0m
[31m  CITY[0m
[31m  !== HIVE - 1 row(s) ==   == CATALYST - 0 row(s) ==[0m
[31m  !Xi_an% (HiveComparisonTest.scala:433)[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM STAFF WHERE EMPNUM  NOT LIKE '_36'
[32m- 0151[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM STAFF WHERE NOT(EMPNUM  LIKE '_36')
[32m- 0152[0m
Calcite parsing passed, start to transform. SELECT EMPNAME FROM STAFF WHERE CITY IS NULL
[32m- 0153[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM STAFF
[32m- 0154[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM STAFF WHERE CITY IS NOT NULL
[32m- 0155[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM STAFF WHERE NOT (CITY IS NULL)
[32m- 0156[0m
Calcite parsing passed, start to transform. SELECT STAFF.EMPNAME FROM STAFF WHERE NOT EXISTS (SELECT * FROM PROJ WHERE NOT EXISTS (SELECT * FROM WORKS WHERE STAFF.EMPNUM = WORKS.EMPNUM AND WORKS.PNUM=PROJ.PNUM))
error SELECT STAFF.EMPNAME FROM STAFF WHERE NOT EXISTS (SELECT * FROM PROJ WHERE NOT EXISTS (SELECT * FROM WORKS WHERE STAFF.EMPNUM = WORKS.EMPNUM AND WORKS.PNUM=PROJ.PNUM))[31m- 0157 ***  ***[0m
[31m  java.lang.RuntimeException: Parse failed.[0m
[31m  at scala.sys.package$.error(package.scala:27)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect$$anonfun$parse$1.apply(CalciteDialect.scala:33)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect$$anonfun$parse$1.apply(CalciteDialect.scala:32)[0m
[31m  at scala.Option.getOrElse(Option.scala:120)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect.parse(CalciteDialect.scala:31)[0m
[31m  at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)[0m
[31m  at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)[0m
[31m  at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:115)[0m
[31m  at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:114)[0m
[31m  at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)[0m
[31m  ...[0m
NoViableAltException(231@[])
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.function(HiveParser_IdentifiersParser.java:3544)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.atomExpression(HiveParser_IdentifiersParser.java:6280)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceFieldExpression(HiveParser_IdentifiersParser.java:6383)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceUnaryPrefixExpression(HiveParser_IdentifiersParser.java:6768)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceUnarySuffixExpression(HiveParser_IdentifiersParser.java:6828)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceBitwiseXorExpression(HiveParser_IdentifiersParser.java:7012)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceStarExpression(HiveParser_IdentifiersParser.java:7172)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedencePlusExpression(HiveParser_IdentifiersParser.java:7332)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceAmpersandExpression(HiveParser_IdentifiersParser.java:7483)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceBitwiseOrExpression(HiveParser_IdentifiersParser.java:7634)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceEqualExpression(HiveParser_IdentifiersParser.java:8290)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceNotExpression(HiveParser_IdentifiersParser.java:9177)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceAndExpression(HiveParser_IdentifiersParser.java:9296)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceOrExpression(HiveParser_IdentifiersParser.java:9455)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.expression(HiveParser_IdentifiersParser.java:6105)
	at org.apache.hadoop.hive.ql.parse.HiveParser.expression(HiveParser.java:45846)
	at org.apache.hadoop.hive.ql.parse.HiveParser_FromClauseParser.searchCondition(HiveParser_FromClauseParser.java:6637)
	at org.apache.hadoop.hive.ql.parse.HiveParser_FromClauseParser.whereClause(HiveParser_FromClauseParser.java:6545)
	at org.apache.hadoop.hive.ql.parse.HiveParser.whereClause(HiveParser.java:45849)
	at org.apache.hadoop.hive.ql.parse.HiveParser.selectStatement(HiveParser.java:41543)
	at org.apache.hadoop.hive.ql.parse.HiveParser.regularBody(HiveParser.java:41402)
	at org.apache.hadoop.hive.ql.parse.HiveParser.queryStatementExpressionBody(HiveParser.java:40413)
	at org.apache.hadoop.hive.ql.parse.HiveParser.queryStatementExpression(HiveParser.java:40283)
	at org.apache.hadoop.hive.ql.parse.HiveParser.execStatement(HiveParser.java:1590)
	at org.apache.hadoop.hive.ql.parse.HiveParser.statement(HiveParser.java:1109)
	at org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:202)
	at org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:166)
	at org.apache.spark.sql.hive.HiveQl$.getAst(HiveQl.scala:258)
	at org.apache.spark.sql.hive.HiveQl$.createPlan(HiveQl.scala:283)
	at org.apache.spark.sql.hive.ExtendedHiveQlParser$$anonfun$hiveQl$1.apply(ExtendedHiveQlParser.scala:41)
	at org.apache.spark.sql.hive.ExtendedHiveQlParser$$anonfun$hiveQl$1.apply(ExtendedHiveQlParser.scala:40)
	at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)
	at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:135)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)
	at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Failure.append(Parsers.scala:202)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)
	at scala.util.parsing.combinator.Parsers$$anon$2$$anonfun$apply$14.apply(Parsers.scala:891)
	at scala.util.parsing.combinator.Parsers$$anon$2$$anonfun$apply$14.apply(Parsers.scala:891)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)
	at scala.util.parsing.combinator.Parsers$$anon$2.apply(Parsers.scala:890)
	at scala.util.parsing.combinator.PackratParsers$$anon$1.apply(PackratParsers.scala:110)
	at org.apache.spark.sql.catalyst.AbstractSparkSQLParser.parse(AbstractSparkSQLParser.scala:34)
	at org.apache.spark.sql.hive.HiveQl$.parseSql(HiveQl.scala:276)
	at org.apache.spark.sql.hive.HiveQLDialect.parse(HiveContext.scala:62)
	at com.intel.ssg.bdt.spark.sql.CalciteDialect.getLogicalPlan(CalciteDialect.scala:54)
	at com.intel.ssg.bdt.spark.sql.CalciteDialect.parse(CalciteDialect.scala:31)
	at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)
	at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)
	at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:115)
	at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:114)
	at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)
	at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:135)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)
	at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Failure.append(Parsers.scala:202)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)
	at scala.util.parsing.combinator.Parsers$$anon$2$$anonfun$apply$14.apply(Parsers.scala:891)
	at scala.util.parsing.combinator.Parsers$$anon$2$$anonfun$apply$14.apply(Parsers.scala:891)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)
	at scala.util.parsing.combinator.Parsers$$anon$2.apply(Parsers.scala:890)
	at scala.util.parsing.combinator.PackratParsers$$anon$1.apply(PackratParsers.scala:110)
	at org.apache.spark.sql.catalyst.AbstractSparkSQLParser.parse(AbstractSparkSQLParser.scala:34)
	at org.apache.spark.sql.SQLContext$$anonfun$2.apply(SQLContext.scala:166)
	at org.apache.spark.sql.SQLContext$$anonfun$2.apply(SQLContext.scala:166)
	at org.apache.spark.sql.execution.datasources.DDLParser.parse(DDLParser.scala:42)
	at org.apache.spark.sql.SQLContext.parseSql(SQLContext.scala:189)
	at org.apache.spark.sql.hive.HiveContext.parseSql(HiveContext.scala:280)
	at org.apache.spark.sql.hive.test.TestHiveContext$QueryExecution.<init>(TestHive.scala:179)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1$$anonfun$30.apply(HiveComparisonTest.scala:303)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1$$anonfun$30.apply(HiveComparisonTest.scala:303)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:34)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:244)
	at scala.collection.AbstractTraversable.map(Traversable.scala:105)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1.apply$mcV$sp(HiveComparisonTest.scala:303)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1.apply(HiveComparisonTest.scala:240)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1.apply(HiveComparisonTest.scala:240)
	at org.scalatest.Transformer$$anonfun$apply$1.apply$mcV$sp(Transformer.scala:22)
	at org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)
	at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
	at org.scalatest.Transformer.apply(Transformer.scala:22)
	at org.scalatest.Transformer.apply(Transformer.scala:20)
	at org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:166)
	at org.apache.spark.SparkFunSuite.withFixture(SparkFunSuite.scala:42)
	at org.scalatest.FunSuiteLike$class.invokeWithFixture$1(FunSuiteLike.scala:163)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)
	at org.scalatest.FunSuiteLike$class.runTest(FunSuiteLike.scala:175)
	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.org$scalatest$BeforeAndAfter$$super$runTest(HiveCompatibilitySuite.scala:32)
	at org.scalatest.BeforeAndAfter$class.runTest(BeforeAndAfter.scala:200)
	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.runTest(HiveCompatibilitySuite.scala:32)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:413)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:401)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)
	at org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:396)
	at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:483)
	at org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:208)
	at org.scalatest.FunSuite.runTests(FunSuite.scala:1555)
	at org.scalatest.Suite$class.run(Suite.scala:1424)
	at org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.SuperEngine.runImpl(Engine.scala:545)
	at org.scalatest.FunSuiteLike$class.run(FunSuiteLike.scala:212)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest.org$scalatest$BeforeAndAfterAll$$super$run(HiveComparisonTest.scala:44)
	at org.scalatest.BeforeAndAfterAll$class.liftedTree1$1(BeforeAndAfterAll.scala:257)
	at org.scalatest.BeforeAndAfterAll$class.run(BeforeAndAfterAll.scala:256)
	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.org$scalatest$BeforeAndAfter$$super$run(HiveCompatibilitySuite.scala:32)
	at org.scalatest.BeforeAndAfter$class.run(BeforeAndAfter.scala:241)
	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.run(HiveCompatibilitySuite.scala:32)
	at org.scalatest.Suite$class.callExecuteOnSuite$1(Suite.scala:1492)
	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1528)
	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1526)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.scalatest.Suite$class.runNestedSuites(Suite.scala:1526)
	at org.scalatest.tools.DiscoverySuite.runNestedSuites(DiscoverySuite.scala:29)
	at org.scalatest.Suite$class.run(Suite.scala:1421)
	at org.scalatest.tools.DiscoverySuite.run(DiscoverySuite.scala:29)
	at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:55)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2563)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2557)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:2557)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1044)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1043)
	at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:2722)
	at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1043)
	at org.scalatest.tools.Runner$.main(Runner.scala:860)
	at org.scalatest.tools.Runner.main(Runner.scala)
[31m- 0158 *** FAILED ***[0m
[31m  org.apache.spark.sql.AnalysisException: cannot recognize input near 'SELECT' 'BUDGET' 'FROM' in function specification; line 1 pos 42[0m
[31m  at org.apache.spark.sql.hive.HiveQl$.createPlan(HiveQl.scala:296)[0m
[31m  at org.apache.spark.sql.hive.ExtendedHiveQlParser$$anonfun$hiveQl$1.apply(ExtendedHiveQlParser.scala:41)[0m
[31m  at org.apache.spark.sql.hive.ExtendedHiveQlParser$$anonfun$hiveQl$1.apply(ExtendedHiveQlParser.scala:40)[0m
[31m  at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)[0m
[31m  at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:135)[0m
[31m  at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)[0m
[31m  at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)[0m
[31m  at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)[0m
[31m  at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)[0m
[31m  at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)[0m
[31m  ...[0m
NoViableAltException(231@[])
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.function(HiveParser_IdentifiersParser.java:3544)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.atomExpression(HiveParser_IdentifiersParser.java:6280)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceFieldExpression(HiveParser_IdentifiersParser.java:6383)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceUnaryPrefixExpression(HiveParser_IdentifiersParser.java:6768)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceUnarySuffixExpression(HiveParser_IdentifiersParser.java:6828)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceBitwiseXorExpression(HiveParser_IdentifiersParser.java:7012)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceStarExpression(HiveParser_IdentifiersParser.java:7172)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedencePlusExpression(HiveParser_IdentifiersParser.java:7332)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceAmpersandExpression(HiveParser_IdentifiersParser.java:7483)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceBitwiseOrExpression(HiveParser_IdentifiersParser.java:7634)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceEqualExpression(HiveParser_IdentifiersParser.java:8290)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceNotExpression(HiveParser_IdentifiersParser.java:9177)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceAndExpression(HiveParser_IdentifiersParser.java:9296)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceOrExpression(HiveParser_IdentifiersParser.java:9455)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.expression(HiveParser_IdentifiersParser.java:6105)
	at org.apache.hadoop.hive.ql.parse.HiveParser.expression(HiveParser.java:45846)
	at org.apache.hadoop.hive.ql.parse.HiveParser_FromClauseParser.searchCondition(HiveParser_FromClauseParser.java:6637)
	at org.apache.hadoop.hive.ql.parse.HiveParser_FromClauseParser.whereClause(HiveParser_FromClauseParser.java:6545)
	at org.apache.hadoop.hive.ql.parse.HiveParser.whereClause(HiveParser.java:45849)
	at org.apache.hadoop.hive.ql.parse.HiveParser.selectStatement(HiveParser.java:41543)
	at org.apache.hadoop.hive.ql.parse.HiveParser.regularBody(HiveParser.java:41402)
	at org.apache.hadoop.hive.ql.parse.HiveParser.queryStatementExpressionBody(HiveParser.java:40413)
	at org.apache.hadoop.hive.ql.parse.HiveParser.queryStatementExpression(HiveParser.java:40283)
	at org.apache.hadoop.hive.ql.parse.HiveParser.execStatement(HiveParser.java:1590)
	at org.apache.hadoop.hive.ql.parse.HiveParser.statement(HiveParser.java:1109)
	at org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:202)
	at org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:166)
	at org.apache.spark.sql.hive.HiveQl$.getAst(HiveQl.scala:258)
	at org.apache.spark.sql.hive.HiveQl$.createPlan(HiveQl.scala:283)
	at org.apache.spark.sql.hive.ExtendedHiveQlParser$$anonfun$hiveQl$1.apply(ExtendedHiveQlParser.scala:41)
	at org.apache.spark.sql.hive.ExtendedHiveQlParser$$anonfun$hiveQl$1.apply(ExtendedHiveQlParser.scala:40)
	at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)
	at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:135)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)
	at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Failure.append(Parsers.scala:202)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)
	at scala.util.parsing.combinator.Parsers$$anon$2$$anonfun$apply$14.apply(Parsers.scala:891)
	at scala.util.parsing.combinator.Parsers$$anon$2$$anonfun$apply$14.apply(Parsers.scala:891)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)
	at scala.util.parsing.combinator.Parsers$$anon$2.apply(Parsers.scala:890)
	at scala.util.parsing.combinator.PackratParsers$$anon$1.apply(PackratParsers.scala:110)
	at org.apache.spark.sql.catalyst.AbstractSparkSQLParser.parse(AbstractSparkSQLParser.scala:34)
	at org.apache.spark.sql.hive.HiveQl$.parseSql(HiveQl.scala:276)
	at org.apache.spark.sql.hive.HiveQLDialect.parse(HiveContext.scala:62)
	at com.intel.ssg.bdt.spark.sql.CalciteDialect.getLogicalPlan(CalciteDialect.scala:54)
	at com.intel.ssg.bdt.spark.sql.CalciteDialect.parse(CalciteDialect.scala:31)
	at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)
	at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)
	at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:115)
	at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:114)
	at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)
	at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:135)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)
	at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Failure.append(Parsers.scala:202)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)
	at scala.util.parsing.combinator.Parsers$$anon$2$$anonfun$apply$14.apply(Parsers.scala:891)
	at scala.util.parsing.combinator.Parsers$$anon$2$$anonfun$apply$14.apply(Parsers.scala:891)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)
	at scala.util.parsing.combinator.Parsers$$anon$2.apply(Parsers.scala:890)
	at scala.util.parsing.combinator.PackratParsers$$anon$1.apply(PackratParsers.scala:110)
	at org.apache.spark.sql.catalyst.AbstractSparkSQLParser.parse(AbstractSparkSQLParser.scala:34)
	at org.apache.spark.sql.SQLContext$$anonfun$2.apply(SQLContext.scala:166)
	at org.apache.spark.sql.SQLContext$$anonfun$2.apply(SQLContext.scala:166)
	at org.apache.spark.sql.execution.datasources.DDLParser.parse(DDLParser.scala:42)
	at org.apache.spark.sql.SQLContext.parseSql(SQLContext.scala:189)
	at org.apache.spark.sql.hive.HiveContext.parseSql(HiveContext.scala:280)
	at org.apache.spark.sql.hive.test.TestHiveContext$QueryExecution.<init>(TestHive.scala:179)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1$$anonfun$30.apply(HiveComparisonTest.scala:303)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1$$anonfun$30.apply(HiveComparisonTest.scala:303)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:34)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:244)
	at scala.collection.AbstractTraversable.map(Traversable.scala:105)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1.apply$mcV$sp(HiveComparisonTest.scala:303)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1.apply(HiveComparisonTest.scala:240)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1.apply(HiveComparisonTest.scala:240)
	at org.scalatest.Transformer$$anonfun$apply$1.apply$mcV$sp(Transformer.scala:22)
	at org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)
	at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
	at org.scalatest.Transformer.apply(Transformer.scala:22)
	at org.scalatest.Transformer.apply(Transformer.scala:20)
	at org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:166)
	at org.apache.spark.SparkFunSuite.withFixture(SparkFunSuite.scala:42)
	at org.scalatest.FunSuiteLike$class.invokeWithFixture$1(FunSuiteLike.scala:163)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)
	at org.scalatest.FunSuiteLike$class.runTest(FunSuiteLike.scala:175)
	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.org$scalatest$BeforeAndAfter$$super$runTest(HiveCompatibilitySuite.scala:32)
	at org.scalatest.BeforeAndAfter$class.runTest(BeforeAndAfter.scala:200)
	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.runTest(HiveCompatibilitySuite.scala:32)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:413)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:401)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)
	at org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:396)
	at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:483)
	at org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:208)
	at org.scalatest.FunSuite.runTests(FunSuite.scala:1555)
	at org.scalatest.Suite$class.run(Suite.scala:1424)
	at org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.SuperEngine.runImpl(Engine.scala:545)
	at org.scalatest.FunSuiteLike$class.run(FunSuiteLike.scala:212)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest.org$scalatest$BeforeAndAfterAll$$super$run(HiveComparisonTest.scala:44)
	at org.scalatest.BeforeAndAfterAll$class.liftedTree1$1(BeforeAndAfterAll.scala:257)
	at org.scalatest.BeforeAndAfterAll$class.run(BeforeAndAfterAll.scala:256)
	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.org$scalatest$BeforeAndAfter$$super$run(HiveCompatibilitySuite.scala:32)
	at org.scalatest.BeforeAndAfter$class.run(BeforeAndAfter.scala:241)
	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.run(HiveCompatibilitySuite.scala:32)
	at org.scalatest.Suite$class.callExecuteOnSuite$1(Suite.scala:1492)
	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1528)
	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1526)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.scalatest.Suite$class.runNestedSuites(Suite.scala:1526)
	at org.scalatest.tools.DiscoverySuite.runNestedSuites(DiscoverySuite.scala:29)
	at org.scalatest.Suite$class.run(Suite.scala:1421)
	at org.scalatest.tools.DiscoverySuite.run(DiscoverySuite.scala:29)
	at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:55)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2563)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2557)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:2557)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1044)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1043)
	at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:2722)
	at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1043)
	at org.scalatest.tools.Runner$.main(Runner.scala:860)
	at org.scalatest.tools.Runner.main(Runner.scala)
[31m- 0159 *** FAILED ***[0m
[31m  org.apache.spark.sql.AnalysisException: cannot recognize input near 'SELECT' 'BUDGET' '/' in function specification; line 1 pos 46[0m
[31m  at org.apache.spark.sql.hive.HiveQl$.createPlan(HiveQl.scala:296)[0m
[31m  at org.apache.spark.sql.hive.ExtendedHiveQlParser$$anonfun$hiveQl$1.apply(ExtendedHiveQlParser.scala:41)[0m
[31m  at org.apache.spark.sql.hive.ExtendedHiveQlParser$$anonfun$hiveQl$1.apply(ExtendedHiveQlParser.scala:40)[0m
[31m  at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)[0m
[31m  at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:135)[0m
[31m  at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)[0m
[31m  at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)[0m
[31m  at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)[0m
[31m  at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)[0m
[31m  at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)[0m
[31m  ...[0m
NoViableAltException(231@[])
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.function(HiveParser_IdentifiersParser.java:3544)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.atomExpression(HiveParser_IdentifiersParser.java:6280)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceFieldExpression(HiveParser_IdentifiersParser.java:6383)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceUnaryPrefixExpression(HiveParser_IdentifiersParser.java:6768)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceUnarySuffixExpression(HiveParser_IdentifiersParser.java:6828)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceBitwiseXorExpression(HiveParser_IdentifiersParser.java:7012)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceStarExpression(HiveParser_IdentifiersParser.java:7172)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedencePlusExpression(HiveParser_IdentifiersParser.java:7332)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceAmpersandExpression(HiveParser_IdentifiersParser.java:7483)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceBitwiseOrExpression(HiveParser_IdentifiersParser.java:7634)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceEqualExpression(HiveParser_IdentifiersParser.java:8290)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceNotExpression(HiveParser_IdentifiersParser.java:9177)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceAndExpression(HiveParser_IdentifiersParser.java:9296)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceOrExpression(HiveParser_IdentifiersParser.java:9455)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.expression(HiveParser_IdentifiersParser.java:6105)
	at org.apache.hadoop.hive.ql.parse.HiveParser.expression(HiveParser.java:45846)
	at org.apache.hadoop.hive.ql.parse.HiveParser_FromClauseParser.searchCondition(HiveParser_FromClauseParser.java:6637)
	at org.apache.hadoop.hive.ql.parse.HiveParser_FromClauseParser.whereClause(HiveParser_FromClauseParser.java:6545)
	at org.apache.hadoop.hive.ql.parse.HiveParser.whereClause(HiveParser.java:45849)
	at org.apache.hadoop.hive.ql.parse.HiveParser.selectStatement(HiveParser.java:41543)
	at org.apache.hadoop.hive.ql.parse.HiveParser.regularBody(HiveParser.java:41402)
	at org.apache.hadoop.hive.ql.parse.HiveParser.queryStatementExpressionBody(HiveParser.java:40413)
	at org.apache.hadoop.hive.ql.parse.HiveParser.queryStatementExpression(HiveParser.java:40283)
	at org.apache.hadoop.hive.ql.parse.HiveParser.execStatement(HiveParser.java:1590)
	at org.apache.hadoop.hive.ql.parse.HiveParser.statement(HiveParser.java:1109)
	at org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:202)
	at org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:166)
	at org.apache.spark.sql.hive.HiveQl$.getAst(HiveQl.scala:258)
	at org.apache.spark.sql.hive.HiveQl$.createPlan(HiveQl.scala:283)
	at org.apache.spark.sql.hive.ExtendedHiveQlParser$$anonfun$hiveQl$1.apply(ExtendedHiveQlParser.scala:41)
	at org.apache.spark.sql.hive.ExtendedHiveQlParser$$anonfun$hiveQl$1.apply(ExtendedHiveQlParser.scala:40)
	at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)
	at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:135)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)
	at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Failure.append(Parsers.scala:202)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)
	at scala.util.parsing.combinator.Parsers$$anon$2$$anonfun$apply$14.apply(Parsers.scala:891)
	at scala.util.parsing.combinator.Parsers$$anon$2$$anonfun$apply$14.apply(Parsers.scala:891)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)
	at scala.util.parsing.combinator.Parsers$$anon$2.apply(Parsers.scala:890)
	at scala.util.parsing.combinator.PackratParsers$$anon$1.apply(PackratParsers.scala:110)
	at org.apache.spark.sql.catalyst.AbstractSparkSQLParser.parse(AbstractSparkSQLParser.scala:34)
	at org.apache.spark.sql.hive.HiveQl$.parseSql(HiveQl.scala:276)
	at org.apache.spark.sql.hive.HiveQLDialect.parse(HiveContext.scala:62)
	at com.intel.ssg.bdt.spark.sql.CalciteDialect.getLogicalPlan(CalciteDialect.scala:54)
	at com.intel.ssg.bdt.spark.sql.CalciteDialect.parse(CalciteDialect.scala:31)
	at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)
	at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)
	at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:115)
	at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:114)
	at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)
	at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:135)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)
	at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Failure.append(Parsers.scala:202)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)
	at scala.util.parsing.combinator.Parsers$$anon$2$$anonfun$apply$14.apply(Parsers.scala:891)
	at scala.util.parsing.combinator.Parsers$$anon$2$$anonfun$apply$14.apply(Parsers.scala:891)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)
	at scala.util.parsing.combinator.Parsers$$anon$2.apply(Parsers.scala:890)
	at scala.util.parsing.combinator.PackratParsers$$anon$1.apply(PackratParsers.scala:110)
	at org.apache.spark.sql.catalyst.AbstractSparkSQLParser.parse(AbstractSparkSQLParser.scala:34)
	at org.apache.spark.sql.SQLContext$$anonfun$2.apply(SQLContext.scala:166)
	at org.apache.spark.sql.SQLContext$$anonfun$2.apply(SQLContext.scala:166)
	at org.apache.spark.sql.execution.datasources.DDLParser.parse(DDLParser.scala:42)
	at org.apache.spark.sql.SQLContext.parseSql(SQLContext.scala:189)
	at org.apache.spark.sql.hive.HiveContext.parseSql(HiveContext.scala:280)
	at org.apache.spark.sql.hive.test.TestHiveContext$QueryExecution.<init>(TestHive.scala:179)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1$$anonfun$30.apply(HiveComparisonTest.scala:303)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1$$anonfun$30.apply(HiveComparisonTest.scala:303)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:34)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:244)
	at scala.collection.AbstractTraversable.map(Traversable.scala:105)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1.apply$mcV$sp(HiveComparisonTest.scala:303)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1.apply(HiveComparisonTest.scala:240)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1.apply(HiveComparisonTest.scala:240)
	at org.scalatest.Transformer$$anonfun$apply$1.apply$mcV$sp(Transformer.scala:22)
	at org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)
	at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
	at org.scalatest.Transformer.apply(Transformer.scala:22)
	at org.scalatest.Transformer.apply(Transformer.scala:20)
	at org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:166)
	at org.apache.spark.SparkFunSuite.withFixture(SparkFunSuite.scala:42)
	at org.scalatest.FunSuiteLike$class.invokeWithFixture$1(FunSuiteLike.scala:163)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)
	at org.scalatest.FunSuiteLike$class.runTest(FunSuiteLike.scala:175)
	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.org$scalatest$BeforeAndAfter$$super$runTest(HiveCompatibilitySuite.scala:32)
	at org.scalatest.BeforeAndAfter$class.runTest(BeforeAndAfter.scala:200)
	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.runTest(HiveCompatibilitySuite.scala:32)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:413)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:401)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)
	at org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:396)
	at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:483)
	at org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:208)
	at org.scalatest.FunSuite.runTests(FunSuite.scala:1555)
	at org.scalatest.Suite$class.run(Suite.scala:1424)
	at org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.SuperEngine.runImpl(Engine.scala:545)
	at org.scalatest.FunSuiteLike$class.run(FunSuiteLike.scala:212)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest.org$scalatest$BeforeAndAfterAll$$super$run(HiveComparisonTest.scala:44)
	at org.scalatest.BeforeAndAfterAll$class.liftedTree1$1(BeforeAndAfterAll.scala:257)
	at org.scalatest.BeforeAndAfterAll$class.run(BeforeAndAfterAll.scala:256)
	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.org$scalatest$BeforeAndAfter$$super$run(HiveCompatibilitySuite.scala:32)
	at org.scalatest.BeforeAndAfter$class.run(BeforeAndAfter.scala:241)
	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.run(HiveCompatibilitySuite.scala:32)
	at org.scalatest.Suite$class.callExecuteOnSuite$1(Suite.scala:1492)
	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1528)
	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1526)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.scalatest.Suite$class.runNestedSuites(Suite.scala:1526)
	at org.scalatest.tools.DiscoverySuite.runNestedSuites(DiscoverySuite.scala:29)
	at org.scalatest.Suite$class.run(Suite.scala:1421)
	at org.scalatest.tools.DiscoverySuite.run(DiscoverySuite.scala:29)
	at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:55)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2563)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2557)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:2557)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1044)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1043)
	at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:2722)
	at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1043)
	at org.scalatest.tools.Runner$.main(Runner.scala:860)
	at org.scalatest.tools.Runner.main(Runner.scala)
[31m- 0160 *** FAILED ***[0m
[31m  org.apache.spark.sql.AnalysisException: cannot recognize input near 'SELECT' 'BUDGET' '/' in function specification; line 1 pos 45[0m
[31m  at org.apache.spark.sql.hive.HiveQl$.createPlan(HiveQl.scala:296)[0m
[31m  at org.apache.spark.sql.hive.ExtendedHiveQlParser$$anonfun$hiveQl$1.apply(ExtendedHiveQlParser.scala:41)[0m
[31m  at org.apache.spark.sql.hive.ExtendedHiveQlParser$$anonfun$hiveQl$1.apply(ExtendedHiveQlParser.scala:40)[0m
[31m  at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)[0m
[31m  at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:135)[0m
[31m  at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)[0m
[31m  at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)[0m
[31m  at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)[0m
[31m  at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)[0m
[31m  at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)[0m
[31m  ...[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM TEMP_S
[32m- 0161[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM TEMP_S
[32m- 0162[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM TEMP_S
[32m- 0163[0m
Calcite parsing passed, start to transform. SELECT PNUM FROM WORKS WHERE PNUM > 'P1' GROUP BY PNUM HAVING COUNT(*) > 1
[32m- 0164[0m
Calcite parsing passed, start to transform. SELECT PNUM FROM WORKS GROUP BY PNUM HAVING COUNT(*) > 2
[32m- 0165[0m
Calcite parsing passed, start to transform. SELECT EMPNUM, PNUM, HOURS FROM WORKS GROUP BY PNUM, EMPNUM, HOURS HAVING MIN(HOURS) > 12 AND MAX(HOURS) < 80
Calcite parsing passed, start to transform. SELECT EMPNUM, PNUM, HOURS FROM WORKS GROUP BY PNUM, EMPNUM, HOURS HAVING MIN(HOURS) > 12 AND MAX(HOURS) < 80
Calcite parsing passed, start to transform. SELECT EMPNUM, PNUM, HOURS FROM WORKS GROUP BY PNUM, EMPNUM, HOURS HAVING MIN(HOURS) > 12 AND MAX(HOURS) < 80
[31m- 0166 *** FAILED ***[0m
[31m  Results do not match for 0166:[0m
[31m  == Parsed Logical Plan ==[0m
[31m  'Filter (('MIN('HOURS) > 12) && ('MAX('HOURS) < 80))[0m
[31m   'Aggregate ['PNUM,'EMPNUM,'HOURS], ['EMPNUM,'PNUM,'HOURS][0m
[31m    'UnresolvedRelation [WORKS], None[0m
  
[31m  == Analyzed Logical Plan ==[0m
[31m  EMPNUM: string, PNUM: string, HOURS: double[0m
[31m  Project [EMPNUM#23759,PNUM#23760,HOURS#23761][0m
[31m   Filter havingCondition#23762[0m
[31m    Aggregate [PNUM#23760,EMPNUM#23759,HOURS#23761], [((min(HOURS#23761) > cast(12 as double)) && (max(HOURS#23761) < cast(80 as double))) AS havingCondition#23762,EMPNUM#23759,PNUM#23760,HOURS#23761][0m
[31m     MetastoreRelation HU, works, None[0m
  
[31m  == Optimized Logical Plan ==[0m
[31m  Project [EMPNUM#23759,PNUM#23760,HOURS#23761][0m
[31m   Filter havingCondition#23762[0m
[31m    Aggregate [PNUM#23760,EMPNUM#23759,HOURS#23761], [((min(HOURS#23761) > 12.0) && (max(HOURS#23761) < 80.0)) AS havingCondition#23762,EMPNUM#23759,PNUM#23760,HOURS#23761][0m
[31m     MetastoreRelation HU, works, None[0m
  
[31m  == Physical Plan ==[0m
[31m  TungstenProject [EMPNUM#23759,PNUM#23760,HOURS#23761][0m
[31m   Filter havingCondition#23762[0m
[31m    TungstenAggregate(key=[PNUM#23760,EMPNUM#23759,HOURS#23761], functions=[(min(HOURS#23761),mode=Final,isDistinct=false),(max(HOURS#23761),mode=Final,isDistinct=false)], output=[havingCondition#23762,EMPNUM#23759,PNUM#23760,HOURS#23761])[0m
[31m     TungstenExchange hashpartitioning(PNUM#23760,EMPNUM#23759,HOURS#23761)[0m
[31m      TungstenAggregate(key=[PNUM#23760,EMPNUM#23759,HOURS#23761], functions=[(min(HOURS#23761),mode=Partial,isDistinct=false),(max(HOURS#23761),mode=Partial,isDistinct=false)], output=[PNUM#23760,EMPNUM#23759,HOURS#23761,min#23766,max#23768])[0m
[31m       HiveTableScan [empnum#23759,pnum#23760,hours#23761], (MetastoreRelation HU, works, None)[0m
  
[31m  Code Generation: true[0m
[31m  EMPNUM	PNUM	HOURS[0m
[31m  !== HIVE - 7 row(s) ==   == CATALYST - 7 row(s) ==[0m
[31m  !E1	P1	40                E1	P1	40.0[0m
[31m  !E1	P2	20                E1	P2	20.0[0m
[31m  !E1	P4	20                E1	P4	20.0[0m
[31m  !E2	P1	40                E2	P1	40.0[0m
[31m  !E4	P2	20                E4	P2	20.0[0m
[31m  !E4	P4	40                E4	P4	40.0[0m
[31m  !E8	P8	20                E8	P8	20.0 (HiveComparisonTest.scala:433)[0m
Calcite parsing passed, start to transform. SELECT WORKS.PNUM FROM WORKS GROUP BY WORKS.PNUM HAVING WORKS.PNUM IN (SELECT PROJ.PNUM FROM PROJ GROUP BY PROJ.PNUM HAVING SUM(PROJ.BUDGET) > 25000)
error SELECT WORKS.PNUM FROM WORKS GROUP BY WORKS.PNUM HAVING WORKS.PNUM IN (SELECT PROJ.PNUM FROM PROJ GROUP BY PROJ.PNUM HAVING SUM(PROJ.BUDGET) > 25000)[31m- 0167 ***  ***[0m
[31m  java.lang.RuntimeException: Parse failed.[0m
[31m  at scala.sys.package$.error(package.scala:27)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect$$anonfun$parse$1.apply(CalciteDialect.scala:33)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect$$anonfun$parse$1.apply(CalciteDialect.scala:32)[0m
[31m  at scala.Option.getOrElse(Option.scala:120)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect.parse(CalciteDialect.scala:31)[0m
[31m  at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)[0m
[31m  at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)[0m
[31m  at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:115)[0m
[31m  at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:114)[0m
[31m  at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)[0m
[31m  ...[0m
Calcite parsing passed, start to transform. SELECT SUM(HOURS) FROM WORKS HAVING MIN(PNUM) > 'P0'
Calcite parsing passed, start to transform. SELECT SUM(HOURS) FROM WORKS HAVING MIN(PNUM) > 'P0'
Calcite parsing passed, start to transform. SELECT SUM(HOURS) FROM WORKS HAVING MIN(PNUM) > 'P0'
[31m- 0168 *** FAILED ***[0m
[31m  Results do not match for 0168:[0m
[31m  == Parsed Logical Plan ==[0m
[31m  'Filter ('MIN('PNUM) > P0)[0m
[31m   'Project ['SUM('HOURS) AS c0#25388][0m
[31m    'UnresolvedRelation [WORKS], None[0m
  
[31m  == Analyzed Logical Plan ==[0m
[31m  c0: double[0m
[31m  Project [c0#25388][0m
[31m   Filter havingCondition#25392[0m
[31m    Aggregate [(min(PNUM#25390) > P0) AS havingCondition#25392,sum(HOURS#25391) AS c0#25388][0m
[31m     MetastoreRelation HU, works, None[0m
  
[31m  == Optimized Logical Plan ==[0m
[31m  Project [c0#25388][0m
[31m   Filter havingCondition#25392[0m
[31m    Aggregate [(min(PNUM#25390) > P0) AS havingCondition#25392,sum(HOURS#25391) AS c0#25388][0m
[31m     Project [PNUM#25390,HOURS#25391][0m
[31m      MetastoreRelation HU, works, None[0m
  
[31m  == Physical Plan ==[0m
[31m  TungstenProject [c0#25388][0m
[31m   Filter havingCondition#25392[0m
[31m    SortBasedAggregate(key=[], functions=[(min(PNUM#25390),mode=Final,isDistinct=false),(sum(HOURS#25391),mode=Final,isDistinct=false)], output=[havingCondition#25392,c0#25388])[0m
[31m     ConvertToSafe[0m
[31m      TungstenExchange SinglePartition[0m
[31m       ConvertToUnsafe[0m
[31m        SortBasedAggregate(key=[], functions=[(min(PNUM#25390),mode=Partial,isDistinct=false),(sum(HOURS#25391),mode=Partial,isDistinct=false)], output=[min#25396,currentSum#25398])[0m
[31m         HiveTableScan [PNUM#25390,HOURS#25391], (MetastoreRelation HU, works, None)[0m
  
[31m  Code Generation: true[0m
[31m  c0[0m
[31m  !== HIVE - 1 row(s) ==   == CATALYST - 1 row(s) ==[0m
[31m  !384                     384.0 (HiveComparisonTest.scala:433)[0m
Calcite parsing passed, start to transform. SELECT PNUM, SUM(HOURS) FROM WORKS GROUP BY PNUM
Calcite parsing passed, start to transform. SELECT PNUM, SUM(HOURS) FROM WORKS GROUP BY PNUM
Calcite parsing passed, start to transform. SELECT PNUM, SUM(HOURS) FROM WORKS GROUP BY PNUM
[31m- 0169 *** FAILED ***[0m
[31m  Results do not match for 0169:[0m
[31m  == Parsed Logical Plan ==[0m
[31m  'Aggregate ['PNUM], ['PNUM,'SUM('HOURS) AS c1#27144][0m
[31m   'UnresolvedRelation [WORKS], None[0m
  
[31m  == Analyzed Logical Plan ==[0m
[31m  PNUM: string, c1: double[0m
[31m  Aggregate [PNUM#27146], [PNUM#27146,sum(HOURS#27147) AS c1#27144][0m
[31m   MetastoreRelation HU, works, None[0m
  
[31m  == Optimized Logical Plan ==[0m
[31m  Aggregate [PNUM#27146], [PNUM#27146,sum(HOURS#27147) AS c1#27144][0m
[31m   Project [PNUM#27146,HOURS#27147][0m
[31m    MetastoreRelation HU, works, None[0m
  
[31m  == Physical Plan ==[0m
[31m  TungstenAggregate(key=[PNUM#27146], functions=[(sum(HOURS#27147),mode=Final,isDistinct=false)], output=[PNUM#27146,c1#27144])[0m
[31m   TungstenExchange hashpartitioning(PNUM#27146)[0m
[31m    TungstenAggregate(key=[PNUM#27146], functions=[(sum(HOURS#27147),mode=Partial,isDistinct=false)], output=[PNUM#27146,currentSum#27150])[0m
[31m     HiveTableScan [PNUM#27146,HOURS#27147], (MetastoreRelation HU, works, None)[0m
  
[31m  Code Generation: true[0m
[31m  PNUM	c1[0m
[31m  !== HIVE - 9 row(s) ==   == CATALYST - 9 row(s) ==[0m
[31m  !P1	80                   P1	80.0[0m
[31m   P18	NULL                P18	NULL[0m
[31m  !P2	120                  P2	120.0[0m
[31m   P22	NULL                P22	NULL[0m
[31m  !P4	60                   P4	60.0[0m
[31m  !P5	92                   P5	92.0[0m
[31m  !P6	12                   P6	12.0[0m
[31m  !P8	20                   P8	20.0[0m
[31m   P9	NULL                 P9	NULL (HiveComparisonTest.scala:433)[0m
Calcite parsing passed, start to transform. SELECT EMPNUM FROM WORKS GROUP BY EMPNUM
[32m- 0170[0m
Calcite parsing passed, start to transform. SELECT EMPNUM,HOURS FROM WORKS GROUP BY EMPNUM,HOURS
Calcite parsing passed, start to transform. SELECT EMPNUM,HOURS FROM WORKS GROUP BY EMPNUM,HOURS
Calcite parsing passed, start to transform. SELECT EMPNUM,HOURS FROM WORKS GROUP BY EMPNUM,HOURS
[31m- 0171 *** FAILED ***[0m
[31m  Results do not match for 0171:[0m
[31m  == Parsed Logical Plan ==[0m
[31m  'Aggregate ['EMPNUM,'HOURS], ['EMPNUM,'HOURS][0m
[31m   'UnresolvedRelation [WORKS], None[0m
  
[31m  == Analyzed Logical Plan ==[0m
[31m  EMPNUM: string, HOURS: double[0m
[31m  Aggregate [EMPNUM#27651,HOURS#27653], [EMPNUM#27651,HOURS#27653][0m
[31m   MetastoreRelation HU, works, None[0m
  
[31m  == Optimized Logical Plan ==[0m
[31m  Aggregate [EMPNUM#27651,HOURS#27653], [EMPNUM#27651,HOURS#27653][0m
[31m   Project [EMPNUM#27651,HOURS#27653][0m
[31m    MetastoreRelation HU, works, None[0m
  
[31m  == Physical Plan ==[0m
[31m  TungstenAggregate(key=[EMPNUM#27651,HOURS#27653], functions=[], output=[EMPNUM#27651,HOURS#27653])[0m
[31m   TungstenExchange hashpartitioning(EMPNUM#27651,HOURS#27653)[0m
[31m    TungstenAggregate(key=[EMPNUM#27651,HOURS#27653], functions=[], output=[EMPNUM#27651,HOURS#27653])[0m
[31m     HiveTableScan [EMPNUM#27651,HOURS#27653], (MetastoreRelation HU, works, None)[0m
  
[31m  Code Generation: true[0m
[31m  EMPNUM	HOURS[0m
[31m  !== HIVE - 13 row(s) ==   == CATALYST - 13 row(s) ==[0m
[31m  !E1	12                    E1	12.0[0m
[31m  !E1	20                    E1	20.0[0m
[31m  !E1	40                    E1	40.0[0m
[31m   E18	NULL                 E18	NULL[0m
[31m  !E2	40                    E2	40.0[0m
[31m  !E2	80                    E2	80.0[0m
[31m   E22	NULL                 E22	NULL[0m
[31m  !E4	20                    E4	20.0[0m
[31m  !E4	40                    E4	40.0[0m
[31m  !E4	80                    E4	80.0[0m
[31m   E5	NULL                  E5	NULL[0m
[31m  !E8	20                    E8	20.0[0m
[31m   E9	NULL                  E9	NULL (HiveComparisonTest.scala:433)[0m
Calcite parsing passed, start to transform. SELECT * FROM WORKS GROUP BY PNUM,EMPNUM,HOURS
Calcite parsing passed, start to transform. SELECT * FROM WORKS GROUP BY PNUM,EMPNUM,HOURS
Calcite parsing passed, start to transform. SELECT * FROM WORKS GROUP BY PNUM,EMPNUM,HOURS
[31m- 0172 *** FAILED ***[0m
[31m  Results do not match for 0172:[0m
[31m  == Parsed Logical Plan ==[0m
[31m  'Aggregate ['PNUM,'EMPNUM,'HOURS], [*][0m
[31m   'UnresolvedRelation [WORKS], None[0m
  
[31m  == Analyzed Logical Plan ==[0m
[31m  empnum: string, pnum: string, hours: double[0m
[31m  Aggregate [PNUM#27986,EMPNUM#27985,HOURS#27987], [empnum#27985,pnum#27986,hours#27987][0m
[31m   MetastoreRelation HU, works, None[0m
  
[31m  == Optimized Logical Plan ==[0m
[31m  Aggregate [PNUM#27986,EMPNUM#27985,HOURS#27987], [empnum#27985,pnum#27986,hours#27987][0m
[31m   MetastoreRelation HU, works, None[0m
  
[31m  == Physical Plan ==[0m
[31m  TungstenAggregate(key=[PNUM#27986,EMPNUM#27985,HOURS#27987], functions=[], output=[EMPNUM#27985,PNUM#27986,HOURS#27987])[0m
[31m   TungstenExchange hashpartitioning(PNUM#27986,EMPNUM#27985,HOURS#27987)[0m
[31m    TungstenAggregate(key=[PNUM#27986,EMPNUM#27985,HOURS#27987], functions=[], output=[PNUM#27986,EMPNUM#27985,HOURS#27987])[0m
[31m     HiveTableScan [empnum#27985,pnum#27986,hours#27987], (MetastoreRelation HU, works, None)[0m
  
[31m  Code Generation: true[0m
[31m  empnum	pnum	hours[0m
[31m  !== HIVE - 15 row(s) ==   == CATALYST - 15 row(s) ==[0m
[31m  !E1	P1	40                 E1	P1	40.0[0m
[31m  !E1	P2	20                 E1	P2	20.0[0m
[31m  !E1	P4	20                 E1	P4	20.0[0m
[31m  !E1	P5	12                 E1	P5	12.0[0m
[31m  !E1	P6	12                 E1	P6	12.0[0m
[31m   E18	P18	NULL             E18	P18	NULL[0m
[31m  !E2	P1	40                 E2	P1	40.0[0m
[31m  !E2	P2	80                 E2	P2	80.0[0m
[31m   E22	P22	NULL             E22	P22	NULL[0m
[31m  !E4	P2	20                 E4	P2	20.0[0m
[31m  !E4	P4	40                 E4	P4	40.0[0m
[31m  !E4	P5	80                 E4	P5	80.0[0m
[31m   E5	P5	NULL               E5	P5	NULL[0m
[31m  !E8	P8	20                 E8	P8	20.0[0m
[31m   E9	P9	NULL               E9	P9	NULL (HiveComparisonTest.scala:433)[0m
Calcite parsing passed, start to transform. SELECT PNUM,EMPNUM FROM WORKS GROUP BY EMPNUM,PNUM,HOURS
[32m- 0173[0m
Calcite parsing passed, start to transform. SELECT SUM(GRADE) FROM STAFF WHERE CITY IS NULL GROUP BY CITY
Calcite parsing passed, start to transform. SELECT SUM(GRADE) FROM STAFF WHERE CITY IS NULL GROUP BY CITY
Calcite parsing passed, start to transform. SELECT SUM(GRADE) FROM STAFF WHERE CITY IS NULL GROUP BY CITY
[31m- 0174 *** FAILED ***[0m
[31m  Results do not match for 0174:[0m
[31m  == Parsed Logical Plan ==[0m
[31m  'Aggregate ['CITY], ['SUM('GRADE) AS c0#28533][0m
[31m   'Filter isnull('CITY)[0m
[31m    'UnresolvedRelation [STAFF], None[0m
  
[31m  == Analyzed Logical Plan ==[0m
[31m  c0: double[0m
[31m  Aggregate [CITY#28537], [sum(GRADE#28536) AS c0#28533][0m
[31m   Filter isnull(CITY#28537)[0m
[31m    MetastoreRelation HU, staff, None[0m
  
[31m  == Optimized Logical Plan ==[0m
[31m  Aggregate [CITY#28537], [sum(GRADE#28536) AS c0#28533][0m
[31m   Project [CITY#28537,GRADE#28536][0m
[31m    Filter isnull(CITY#28537)[0m
[31m     MetastoreRelation HU, staff, None[0m
  
[31m  == Physical Plan ==[0m
[31m  TungstenAggregate(key=[CITY#28537], functions=[(sum(GRADE#28536),mode=Final,isDistinct=false)], output=[c0#28533])[0m
[31m   TungstenExchange hashpartitioning(CITY#28537)[0m
[31m    TungstenAggregate(key=[CITY#28537], functions=[(sum(GRADE#28536),mode=Partial,isDistinct=false)], output=[CITY#28537,currentSum#28540])[0m
[31m     Filter isnull(CITY#28537)[0m
[31m      HiveTableScan [CITY#28537,GRADE#28536], (MetastoreRelation HU, staff, None)[0m
  
[31m  Code Generation: true[0m
[31m  c0[0m
[31m  !== HIVE - 1 row(s) ==   == CATALYST - 1 row(s) ==[0m
[31m  !90                      90.0 (HiveComparisonTest.scala:433)[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM STAFF
[32m- 0175[0m
Calcite parsing passed, start to transform. SELECT EMPNUM,EMPNAME,GRADE,STAFF.CITY, PNAME, PROJ.CITY FROM STAFF, PROJ WHERE STAFF.CITY = PROJ.CITY
[32m- 0176[0m
Calcite parsing passed, start to transform. SELECT EMPNUM,EMPNAME,GRADE,STAFF.CITY,PNUM,PNAME, PTYPE,BUDGET,PROJ.CITY FROM STAFF, PROJ WHERE STAFF.CITY = PROJ.CITY AND GRADE <> 12
[32m- 0177[0m
Calcite parsing passed, start to transform. SELECT DISTINCT STAFF.CITY, PROJ.CITY FROM STAFF, WORKS, PROJ WHERE STAFF.EMPNUM = WORKS.EMPNUM AND WORKS.PNUM = PROJ.PNUM
[32m- 0178[0m
Calcite parsing passed, start to transform. SELECT FIRST1.EMPNUM, SECOND2.EMPNUM FROM STAFF FIRST1, STAFF SECOND2 WHERE FIRST1.CITY = SECOND2.CITY AND FIRST1.EMPNUM < SECOND2.EMPNUM
[32m- 0179[0m
Calcite parsing passed, start to transform. SELECT CHARTEST FROM  AA
[32m- 0180[0m
Calcite parsing passed, start to transform. SELECT CHARTEST FROM BB
[32m- 0181[0m
Calcite parsing passed, start to transform. SELECT CHARTEST FROM CC
[32m- 0182[0m
Calcite parsing passed, start to transform. SELECT CHARTEST FROM DD
[32m- 0183[0m
Calcite parsing passed, start to transform. SELECT INTTEST FROM EE
Calcite parsing passed, start to transform. SELECT INTTEST FROM EE
Calcite parsing passed, start to transform. SELECT INTTEST FROM EE
[31m- 0184 *** FAILED ***[0m
[31m  Results do not match for 0184:[0m
[31m  == Parsed Logical Plan ==[0m
[31m  'Project ['INTTEST][0m
[31m   'UnresolvedRelation [EE], None[0m
  
[31m  == Analyzed Logical Plan ==[0m
[31m  INTTEST: double[0m
[31m  Project [INTTEST#30493][0m
[31m   MetastoreRelation HU, ee, None[0m
  
[31m  == Optimized Logical Plan ==[0m
[31m  Project [INTTEST#30493][0m
[31m   MetastoreRelation HU, ee, None[0m
  
[31m  == Physical Plan ==[0m
[31m  HiveTableScan [INTTEST#30493], (MetastoreRelation HU, ee, None)[0m
  
[31m  Code Generation: true[0m
[31m  INTTEST[0m
[31m  !== HIVE - 3 row(s) ==   == CATALYST - 3 row(s) ==[0m
[31m  !-999999999              -9.99999999E8[0m
[31m  !123456                  123456.0[0m
[31m  !999999999               9.99999999E8 (HiveComparisonTest.scala:433)[0m
Calcite parsing passed, start to transform. SELECT INTTEST FROM FF
Calcite parsing passed, start to transform. SELECT INTTEST FROM FF
Calcite parsing passed, start to transform. SELECT INTTEST FROM FF
[31m- 0185 *** FAILED ***[0m
[31m  Results do not match for 0185:[0m
[31m  == Parsed Logical Plan ==[0m
[31m  'Project ['INTTEST][0m
[31m   'UnresolvedRelation [FF], None[0m
  
[31m  == Analyzed Logical Plan ==[0m
[31m  INTTEST: double[0m
[31m  Project [INTTEST#30811][0m
[31m   MetastoreRelation HU, ff, None[0m
  
[31m  == Optimized Logical Plan ==[0m
[31m  Project [INTTEST#30811][0m
[31m   MetastoreRelation HU, ff, None[0m
  
[31m  == Physical Plan ==[0m
[31m  HiveTableScan [INTTEST#30811], (MetastoreRelation HU, ff, None)[0m
  
[31m  Code Generation: true[0m
[31m  INTTEST[0m
[31m  !== HIVE - 19 row(s) ==   == CATALYST - 19 row(s) ==[0m
[31m  !123456                   123456.0[0m
[31m  !123456                   123456.0[0m
[31m  !123456                   123456.0[0m
[31m  !123456                   123456.0[0m
[31m  !123456                   123456.0[0m
[31m  !123456                   123456.0[0m
[31m  !123456                   123456.0[0m
[31m  !123456                   123456.0[0m
[31m  !123456                   123456.0[0m
[31m  !123456                   123456.0[0m
[31m  !123456                   123456.0[0m
[31m  !123456                   123456.0[0m
[31m  !123456                   123456.0[0m
[31m  !123456                   123456.0[0m
[31m  !123456                   123456.0[0m
[31m  !123456                   123456.0[0m
[31m  !123456                   123456.0[0m
[31m  !123456                   123456.0[0m
[31m  !123456                   123456.0 (HiveComparisonTest.scala:433)[0m
Calcite parsing passed, start to transform. SELECT * FROM HH
Calcite parsing passed, start to transform. SELECT * FROM HH
Calcite parsing passed, start to transform. SELECT * FROM HH
[31m- 0186 *** FAILED ***[0m
[31m  Results do not match for 0186:[0m
[31m  == Parsed Logical Plan ==[0m
[31m  'Project [*][0m
[31m   'UnresolvedRelation [HH], None[0m
  
[31m  == Analyzed Logical Plan ==[0m
[31m  smalltest: double[0m
[31m  Project [smalltest#31149][0m
[31m   MetastoreRelation HU, hh, None[0m
  
[31m  == Optimized Logical Plan ==[0m
[31m  MetastoreRelation HU, hh, None[0m
  
[31m  == Physical Plan ==[0m
[31m  HiveTableScan [smalltest#31149], (MetastoreRelation HU, hh, None)[0m
  
[31m  Code Generation: true[0m
[31m  smalltest[0m
[31m  !== HIVE - 3 row(s) ==   == CATALYST - 3 row(s) ==[0m
[31m  !-9999                   -9999.0[0m
[31m  !123                     123.0[0m
[31m  !9999                    9999.0 (HiveComparisonTest.scala:433)[0m
Calcite parsing passed, start to transform. SELECT * FROM MM
Calcite parsing passed, start to transform. SELECT * FROM MM
Calcite parsing passed, start to transform. SELECT * FROM MM
[31m- 0187 *** FAILED ***[0m
[31m  Results do not match for 0187:[0m
[31m  == Parsed Logical Plan ==[0m
[31m  'Project [*][0m
[31m   'UnresolvedRelation [MM], None[0m
  
[31m  == Analyzed Logical Plan ==[0m
[31m  numtest: double[0m
[31m  Project [numtest#31341][0m
[31m   MetastoreRelation HU, mm, None[0m
  
[31m  == Optimized Logical Plan ==[0m
[31m  MetastoreRelation HU, mm, None[0m
  
[31m  == Physical Plan ==[0m
[31m  HiveTableScan [numtest#31341], (MetastoreRelation HU, mm, None)[0m
  
[31m  Code Generation: true[0m
[31m  numtest[0m
[31m  !== HIVE - 37 row(s) ==   == CATALYST - 37 row(s) ==[0m
[31m  !7                        7.0[0m
[31m  !7                        7.0[0m
[31m  !7                        7.0[0m
[31m  !7                        7.0[0m
[31m  !7                        7.0[0m
[31m  !7                        7.0[0m
[31m  !7                        7.0[0m
[31m  !7                        7.0[0m
[31m  !7                        7.0[0m
[31m  !7                        7.0[0m
[31m  !7                        7.0[0m
[31m  !7                        7.0[0m
[31m  !7                        7.0[0m
[31m  !7                        7.0[0m
[31m  !7                        7.0[0m
[31m  !7                        7.0[0m
[31m  !7                        7.0[0m
[31m  !7                        7.0[0m
[31m  !7                        7.0[0m
[31m   NULL                     NULL[0m
[31m   NULL                     NULL[0m
[31m   NULL                     NULL[0m
[31m   NULL                     NULL[0m
[31m   NULL                     NULL[0m
[31m   NULL                     NULL[0m
[31m   NULL                     NULL[0m
[31m   NULL                     NULL[0m
[31m   NULL                     NULL[0m
[31m   NULL                     NULL[0m
[31m   NULL                     NULL[0m
[31m   NULL                     NULL[0m
[31m   NULL                     NULL[0m
[31m   NULL                     NULL[0m
[31m   NULL                     NULL[0m
[31m   NULL                     NULL[0m
[31m   NULL                     NULL[0m
[31m   NULL                     NULL (HiveComparisonTest.scala:433)[0m
Calcite parsing passed, start to transform. SELECT * FROM NN
Calcite parsing passed, start to transform. SELECT * FROM NN
Calcite parsing passed, start to transform. SELECT * FROM NN
[31m- 0188 *** FAILED ***[0m
[31m  Results do not match for 0188:[0m
[31m  == Parsed Logical Plan ==[0m
[31m  'Project [*][0m
[31m   'UnresolvedRelation [NN], None[0m
  
[31m  == Analyzed Logical Plan ==[0m
[31m  numtest: double[0m
[31m  Project [numtest#31535][0m
[31m   MetastoreRelation HU, nn, None[0m
  
[31m  == Optimized Logical Plan ==[0m
[31m  MetastoreRelation HU, nn, None[0m
  
[31m  == Physical Plan ==[0m
[31m  HiveTableScan [numtest#31535], (MetastoreRelation HU, nn, None)[0m
  
[31m  Code Generation: true[0m
[31m  numtest[0m
[31m  !== HIVE - 1 row(s) ==   == CATALYST - 1 row(s) ==[0m
[31m  !123456789               1.23456789E8 (HiveComparisonTest.scala:433)[0m
Calcite parsing passed, start to transform. SELECT NUMTEST FROM OO
Calcite parsing passed, start to transform. SELECT NUMTEST FROM OO
Calcite parsing passed, start to transform. SELECT NUMTEST FROM OO
[31m- 0189 *** FAILED ***[0m
[31m  Results do not match for 0189:[0m
[31m  == Parsed Logical Plan ==[0m
[31m  'Project ['NUMTEST][0m
[31m   'UnresolvedRelation [OO], None[0m
  
[31m  == Analyzed Logical Plan ==[0m
[31m  NUMTEST: double[0m
[31m  Project [NUMTEST#31713][0m
[31m   MetastoreRelation HU, oo, None[0m
  
[31m  == Optimized Logical Plan ==[0m
[31m  Project [NUMTEST#31713][0m
[31m   MetastoreRelation HU, oo, None[0m
  
[31m  == Physical Plan ==[0m
[31m  HiveTableScan [NUMTEST#31713], (MetastoreRelation HU, oo, None)[0m
  
[31m  Code Generation: true[0m
[31m  NUMTEST[0m
[31m  !== HIVE - 19 row(s) ==   == CATALYST - 19 row(s) ==[0m
[31m  !123456789                1.23456789E8[0m
[31m  !123456789                1.23456789E8[0m
[31m  !123456789                1.23456789E8[0m
[31m  !123456789                1.23456789E8[0m
[31m  !123456789                1.23456789E8[0m
[31m  !123456789                1.23456789E8[0m
[31m  !123456789                1.23456789E8[0m
[31m  !123456789                1.23456789E8[0m
[31m  !123456789                1.23456789E8[0m
[31m  !123456789                1.23456789E8[0m
[31m  !123456789                1.23456789E8[0m
[31m  !123456789                1.23456789E8[0m
[31m  !123456789                1.23456789E8[0m
[31m  !123456789                1.23456789E8[0m
[31m  !123456789                1.23456789E8[0m
[31m  !123456789                1.23456789E8[0m
[31m  !123456789                1.23456789E8[0m
[31m  !123456789                1.23456789E8[0m
[31m  !123456789                1.23456789E8 (HiveComparisonTest.scala:433)[0m
Calcite parsing passed, start to transform. SELECT * FROM QQ
Calcite parsing passed, start to transform. SELECT * FROM QQ
Calcite parsing passed, start to transform. SELECT * FROM QQ
[31m- 0190 *** FAILED ***[0m
[31m  Results do not match for 0190:[0m
[31m  == Parsed Logical Plan ==[0m
[31m  'Project [*][0m
[31m   'UnresolvedRelation [QQ], None[0m
  
[31m  == Analyzed Logical Plan ==[0m
[31m  numtest: double[0m
[31m  Project [numtest#31891][0m
[31m   MetastoreRelation HU, qq, None[0m
  
[31m  == Optimized Logical Plan ==[0m
[31m  MetastoreRelation HU, qq, None[0m
  
[31m  == Physical Plan ==[0m
[31m  HiveTableScan [numtest#31891], (MetastoreRelation HU, qq, None)[0m
  
[31m  Code Generation: true[0m
[31m  numtest[0m
[31m  !== HIVE - 19 row(s) ==   == CATALYST - 19 row(s) ==[0m
[31m  !56                       56.0[0m
[31m  !56                       56.0[0m
[31m  !56                       56.0[0m
[31m  !56                       56.0[0m
[31m  !56                       56.0[0m
[31m  !56                       56.0[0m
[31m  !56                       56.0[0m
[31m  !56                       56.0[0m
[31m  !56                       56.0[0m
[31m  !56                       56.0[0m
[31m  !56                       56.0[0m
[31m  !56                       56.0[0m
[31m  !56                       56.0[0m
[31m  !56                       56.0[0m
[31m  !56                       56.0[0m
[31m  !56                       56.0[0m
[31m  !56                       56.0[0m
[31m  !56                       56.0[0m
[31m  !56                       56.0 (HiveComparisonTest.scala:433)[0m
Calcite parsing passed, start to transform. SELECT * FROM RR
Calcite parsing passed, start to transform. SELECT * FROM RR
Calcite parsing passed, start to transform. SELECT * FROM RR
[31m- 0191 *** FAILED ***[0m
[31m  Results do not match for 0191:[0m
[31m  == Parsed Logical Plan ==[0m
[31m  'Project [*][0m
[31m   'UnresolvedRelation [RR], None[0m
  
[31m  == Analyzed Logical Plan ==[0m
[31m  numtest: double[0m
[31m  Project [numtest#32069][0m
[31m   MetastoreRelation HU, rr, None[0m
  
[31m  == Optimized Logical Plan ==[0m
[31m  MetastoreRelation HU, rr, None[0m
  
[31m  == Physical Plan ==[0m
[31m  HiveTableScan [numtest#32069], (MetastoreRelation HU, rr, None)[0m
  
[31m  Code Generation: true[0m
[31m  numtest[0m
[31m  !== HIVE - 19 row(s) ==   == CATALYST - 19 row(s) ==[0m
[31m  !12345678                 1.2345678E7[0m
[31m  !12345678                 1.2345678E7[0m
[31m  !12345678                 1.2345678E7[0m
[31m  !12345678                 1.2345678E7[0m
[31m  !12345678                 1.2345678E7[0m
[31m  !12345678                 1.2345678E7[0m
[31m  !12345678                 1.2345678E7[0m
[31m  !12345678                 1.2345678E7[0m
[31m  !12345678                 1.2345678E7[0m
[31m  !12345678                 1.2345678E7[0m
[31m  !12345678                 1.2345678E7[0m
[31m  !12345678                 1.2345678E7[0m
[31m  !12345678                 1.2345678E7[0m
[31m  !12345678                 1.2345678E7[0m
[31m  !12345678                 1.2345678E7[0m
[31m  !12345678                 1.2345678E7[0m
[31m  !12345678                 1.2345678E7[0m
[31m  !12345678                 1.2345678E7[0m
[31m  !12345678                 1.2345678E7 (HiveComparisonTest.scala:433)[0m
Calcite parsing passed, start to transform. SELECT EMPNUM FROM STAFF WHERE GRADE < (SELECT MAX(GRADE) FROM STAFF)
error SELECT EMPNUM FROM STAFF WHERE GRADE < (SELECT MAX(GRADE) FROM STAFF)[31m- 0192 ***  ***[0m
[31m  java.lang.RuntimeException: Parse failed.[0m
[31m  at scala.sys.package$.error(package.scala:27)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect$$anonfun$parse$1.apply(CalciteDialect.scala:33)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect$$anonfun$parse$1.apply(CalciteDialect.scala:32)[0m
[31m  at scala.Option.getOrElse(Option.scala:120)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect.parse(CalciteDialect.scala:31)[0m
[31m  at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)[0m
[31m  at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)[0m
[31m  at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:115)[0m
[31m  at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:114)[0m
[31m  at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)[0m
[31m  ...[0m
Calcite parsing passed, start to transform. SELECT * FROM STAFF WHERE GRADE <= (SELECT AVG(GRADE)-1 FROM STAFF)
error SELECT * FROM STAFF WHERE GRADE <= (SELECT AVG(GRADE)-1 FROM STAFF)[31m- 0193 ***  ***[0m
[31m  java.lang.RuntimeException: Parse failed.[0m
[31m  at scala.sys.package$.error(package.scala:27)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect$$anonfun$parse$1.apply(CalciteDialect.scala:33)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect$$anonfun$parse$1.apply(CalciteDialect.scala:32)[0m
[31m  at scala.Option.getOrElse(Option.scala:120)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect.parse(CalciteDialect.scala:31)[0m
[31m  at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)[0m
[31m  at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)[0m
[31m  at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:115)[0m
[31m  at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:114)[0m
[31m  at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)[0m
[31m  ...[0m
Calcite parsing passed, start to transform. SELECT EMPNAME FROM STAFF WHERE EMPNUM IN (SELECT EMPNUM FROM WORKS WHERE PNUM = 'P2') ORDER BY EMPNAME
error SELECT EMPNAME FROM STAFF WHERE EMPNUM IN (SELECT EMPNUM FROM WORKS WHERE PNUM = 'P2') ORDER BY EMPNAME[31m- 0194 ***  ***[0m
[31m  java.lang.RuntimeException: Parse failed.[0m
[31m  at scala.sys.package$.error(package.scala:27)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect$$anonfun$parse$1.apply(CalciteDialect.scala:33)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect$$anonfun$parse$1.apply(CalciteDialect.scala:32)[0m
[31m  at scala.Option.getOrElse(Option.scala:120)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect.parse(CalciteDialect.scala:31)[0m
[31m  at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)[0m
[31m  at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)[0m
[31m  at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:115)[0m
[31m  at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:114)[0m
[31m  at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)[0m
[31m  ...[0m
Calcite parsing passed, start to transform. SELECT EMPNAME FROM STAFF WHERE EMPNUM IN (SELECT EMPNUM FROM WORKS WHERE PNUM IN (SELECT PNUM FROM PROJ WHERE PTYPE = 'Design'))
error SELECT EMPNAME FROM STAFF WHERE EMPNUM IN (SELECT EMPNUM FROM WORKS WHERE PNUM IN (SELECT PNUM FROM PROJ WHERE PTYPE = 'Design'))[31m- 0195 ***  ***[0m
[31m  java.lang.RuntimeException: Parse failed.[0m
[31m  at scala.sys.package$.error(package.scala:27)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect$$anonfun$parse$1.apply(CalciteDialect.scala:33)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect$$anonfun$parse$1.apply(CalciteDialect.scala:32)[0m
[31m  at scala.Option.getOrElse(Option.scala:120)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect.parse(CalciteDialect.scala:31)[0m
[31m  at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)[0m
[31m  at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)[0m
[31m  at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:115)[0m
[31m  at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:114)[0m
[31m  at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)[0m
[31m  ...[0m
Calcite parsing passed, start to transform. SELECT EMPNUM, EMPNAME FROM STAFF WHERE EMPNUM IN (SELECT EMPNUM FROM WORKS WHERE PNUM IN (SELECT PNUM FROM PROJ WHERE PTYPE IN (SELECT PTYPE FROM PROJ WHERE PNUM IN (SELECT PNUM FROM WORKS WHERE EMPNUM IN (SELECT EMPNUM FROM WORKS WHERE PNUM IN (SELECT PNUM FROM PROJ WHERE PTYPE = 'Design')))))) ORDER BY EMPNUM
error SELECT EMPNUM, EMPNAME FROM STAFF WHERE EMPNUM IN (SELECT EMPNUM FROM WORKS WHERE PNUM IN (SELECT PNUM FROM PROJ WHERE PTYPE IN (SELECT PTYPE FROM PROJ WHERE PNUM IN (SELECT PNUM FROM WORKS WHERE EMPNUM IN (SELECT EMPNUM FROM WORKS WHERE PNUM IN (SELECT PNUM FROM PROJ WHERE PTYPE = 'Design')))))) ORDER BY EMPNUM[31m- 0196 ***  ***[0m
[31m  java.lang.RuntimeException: Parse failed.[0m
[31m  at scala.sys.package$.error(package.scala:27)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect$$anonfun$parse$1.apply(CalciteDialect.scala:33)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect$$anonfun$parse$1.apply(CalciteDialect.scala:32)[0m
[31m  at scala.Option.getOrElse(Option.scala:120)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect.parse(CalciteDialect.scala:31)[0m
[31m  at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)[0m
[31m  at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)[0m
[31m  at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:115)[0m
[31m  at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:114)[0m
[31m  at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)[0m
[31m  ...[0m
NoViableAltException(231@[])
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.function(HiveParser_IdentifiersParser.java:3544)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.atomExpression(HiveParser_IdentifiersParser.java:6280)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceFieldExpression(HiveParser_IdentifiersParser.java:6383)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceUnaryPrefixExpression(HiveParser_IdentifiersParser.java:6768)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceUnarySuffixExpression(HiveParser_IdentifiersParser.java:6828)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceBitwiseXorExpression(HiveParser_IdentifiersParser.java:7012)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceStarExpression(HiveParser_IdentifiersParser.java:7172)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedencePlusExpression(HiveParser_IdentifiersParser.java:7332)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceAmpersandExpression(HiveParser_IdentifiersParser.java:7483)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceBitwiseOrExpression(HiveParser_IdentifiersParser.java:7634)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceEqualExpression(HiveParser_IdentifiersParser.java:8290)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceNotExpression(HiveParser_IdentifiersParser.java:9177)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceAndExpression(HiveParser_IdentifiersParser.java:9296)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceOrExpression(HiveParser_IdentifiersParser.java:9455)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.expression(HiveParser_IdentifiersParser.java:6105)
	at org.apache.hadoop.hive.ql.parse.HiveParser.expression(HiveParser.java:45846)
	at org.apache.hadoop.hive.ql.parse.HiveParser_FromClauseParser.searchCondition(HiveParser_FromClauseParser.java:6637)
	at org.apache.hadoop.hive.ql.parse.HiveParser_FromClauseParser.whereClause(HiveParser_FromClauseParser.java:6545)
	at org.apache.hadoop.hive.ql.parse.HiveParser.whereClause(HiveParser.java:45849)
	at org.apache.hadoop.hive.ql.parse.HiveParser.selectStatement(HiveParser.java:41543)
	at org.apache.hadoop.hive.ql.parse.HiveParser.regularBody(HiveParser.java:41402)
	at org.apache.hadoop.hive.ql.parse.HiveParser.queryStatementExpressionBody(HiveParser.java:40413)
	at org.apache.hadoop.hive.ql.parse.HiveParser.queryStatementExpression(HiveParser.java:40283)
	at org.apache.hadoop.hive.ql.parse.HiveParser.execStatement(HiveParser.java:1590)
	at org.apache.hadoop.hive.ql.parse.HiveParser.statement(HiveParser.java:1109)
	at org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:202)
	at org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:166)
	at org.apache.spark.sql.hive.HiveQl$.getAst(HiveQl.scala:258)
	at org.apache.spark.sql.hive.HiveQl$.createPlan(HiveQl.scala:283)
	at org.apache.spark.sql.hive.ExtendedHiveQlParser$$anonfun$hiveQl$1.apply(ExtendedHiveQlParser.scala:41)
	at org.apache.spark.sql.hive.ExtendedHiveQlParser$$anonfun$hiveQl$1.apply(ExtendedHiveQlParser.scala:40)
	at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)
	at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:135)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)
	at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Failure.append(Parsers.scala:202)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)
	at scala.util.parsing.combinator.Parsers$$anon$2$$anonfun$apply$14.apply(Parsers.scala:891)
	at scala.util.parsing.combinator.Parsers$$anon$2$$anonfun$apply$14.apply(Parsers.scala:891)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)
	at scala.util.parsing.combinator.Parsers$$anon$2.apply(Parsers.scala:890)
	at scala.util.parsing.combinator.PackratParsers$$anon$1.apply(PackratParsers.scala:110)
	at org.apache.spark.sql.catalyst.AbstractSparkSQLParser.parse(AbstractSparkSQLParser.scala:34)
	at org.apache.spark.sql.hive.HiveQl$.parseSql(HiveQl.scala:276)
	at org.apache.spark.sql.hive.HiveQLDialect.parse(HiveContext.scala:62)
	at com.intel.ssg.bdt.spark.sql.CalciteDialect.getLogicalPlan(CalciteDialect.scala:54)
	at com.intel.ssg.bdt.spark.sql.CalciteDialect.parse(CalciteDialect.scala:31)
	at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)
	at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)
	at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:115)
	at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:114)
	at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)
	at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:135)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)
	at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Failure.append(Parsers.scala:202)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)
	at scala.util.parsing.combinator.Parsers$$anon$2$$anonfun$apply$14.apply(Parsers.scala:891)
	at scala.util.parsing.combinator.Parsers$$anon$2$$anonfun$apply$14.apply(Parsers.scala:891)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)
	at scala.util.parsing.combinator.Parsers$$anon$2.apply(Parsers.scala:890)
	at scala.util.parsing.combinator.PackratParsers$$anon$1.apply(PackratParsers.scala:110)
	at org.apache.spark.sql.catalyst.AbstractSparkSQLParser.parse(AbstractSparkSQLParser.scala:34)
	at org.apache.spark.sql.SQLContext$$anonfun$2.apply(SQLContext.scala:166)
	at org.apache.spark.sql.SQLContext$$anonfun$2.apply(SQLContext.scala:166)
	at org.apache.spark.sql.execution.datasources.DDLParser.parse(DDLParser.scala:42)
	at org.apache.spark.sql.SQLContext.parseSql(SQLContext.scala:189)
	at org.apache.spark.sql.hive.HiveContext.parseSql(HiveContext.scala:280)
	at org.apache.spark.sql.hive.test.TestHiveContext$QueryExecution.<init>(TestHive.scala:179)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1$$anonfun$30.apply(HiveComparisonTest.scala:303)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1$$anonfun$30.apply(HiveComparisonTest.scala:303)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:34)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:244)
	at scala.collection.AbstractTraversable.map(Traversable.scala:105)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1.apply$mcV$sp(HiveComparisonTest.scala:303)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1.apply(HiveComparisonTest.scala:240)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1.apply(HiveComparisonTest.scala:240)
	at org.scalatest.Transformer$$anonfun$apply$1.apply$mcV$sp(Transformer.scala:22)
	at org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)
	at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
	at org.scalatest.Transformer.apply(Transformer.scala:22)
	at org.scalatest.Transformer.apply(Transformer.scala:20)
	at org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:166)
	at org.apache.spark.SparkFunSuite.withFixture(SparkFunSuite.scala:42)
	at org.scalatest.FunSuiteLike$class.invokeWithFixture$1(FunSuiteLike.scala:163)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)
	at org.scalatest.FunSuiteLike$class.runTest(FunSuiteLike.scala:175)
	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.org$scalatest$BeforeAndAfter$$super$runTest(HiveCompatibilitySuite.scala:32)
	at org.scalatest.BeforeAndAfter$class.runTest(BeforeAndAfter.scala:200)
	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.runTest(HiveCompatibilitySuite.scala:32)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:413)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:401)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)
	at org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:396)
	at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:483)
	at org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:208)
	at org.scalatest.FunSuite.runTests(FunSuite.scala:1555)
	at org.scalatest.Suite$class.run(Suite.scala:1424)
	at org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.SuperEngine.runImpl(Engine.scala:545)
	at org.scalatest.FunSuiteLike$class.run(FunSuiteLike.scala:212)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest.org$scalatest$BeforeAndAfterAll$$super$run(HiveComparisonTest.scala:44)
	at org.scalatest.BeforeAndAfterAll$class.liftedTree1$1(BeforeAndAfterAll.scala:257)
	at org.scalatest.BeforeAndAfterAll$class.run(BeforeAndAfterAll.scala:256)
	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.org$scalatest$BeforeAndAfter$$super$run(HiveCompatibilitySuite.scala:32)
	at org.scalatest.BeforeAndAfter$class.run(BeforeAndAfter.scala:241)
	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.run(HiveCompatibilitySuite.scala:32)
	at org.scalatest.Suite$class.callExecuteOnSuite$1(Suite.scala:1492)
	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1528)
	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1526)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.scalatest.Suite$class.runNestedSuites(Suite.scala:1526)
	at org.scalatest.tools.DiscoverySuite.runNestedSuites(DiscoverySuite.scala:29)
	at org.scalatest.Suite$class.run(Suite.scala:1421)
	at org.scalatest.tools.DiscoverySuite.run(DiscoverySuite.scala:29)
	at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:55)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2563)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2557)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:2557)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1044)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1043)
	at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:2722)
	at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1043)
	at org.scalatest.tools.Runner$.main(Runner.scala:860)
	at org.scalatest.tools.Runner.main(Runner.scala)
[31m- 0197 *** FAILED ***[0m
[31m  org.apache.spark.sql.AnalysisException: cannot recognize input near 'SELECT' 'AVG' '(' in function specification; line 1 pos 53[0m
[31m  at org.apache.spark.sql.hive.HiveQl$.createPlan(HiveQl.scala:296)[0m
[31m  at org.apache.spark.sql.hive.ExtendedHiveQlParser$$anonfun$hiveQl$1.apply(ExtendedHiveQlParser.scala:41)[0m
[31m  at org.apache.spark.sql.hive.ExtendedHiveQlParser$$anonfun$hiveQl$1.apply(ExtendedHiveQlParser.scala:40)[0m
[31m  at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)[0m
[31m  at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:135)[0m
[31m  at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)[0m
[31m  at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)[0m
[31m  at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)[0m
[31m  at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)[0m
[31m  at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)[0m
[31m  ...[0m
Calcite parsing passed, start to transform. SELECT DISTINCT EMPNUM FROM WORKS WORKSX WHERE NOT EXISTS (SELECT * FROM WORKS WORKSY WHERE EMPNUM = 'E2' AND NOT EXISTS (SELECT * FROM WORKS WORKSZ WHERE WORKSZ.EMPNUM = WORKSX.EMPNUM AND WORKSZ.PNUM = WORKSY.PNUM))
error SELECT DISTINCT EMPNUM FROM WORKS WORKSX WHERE NOT EXISTS (SELECT * FROM WORKS WORKSY WHERE EMPNUM = 'E2' AND NOT EXISTS (SELECT * FROM WORKS WORKSZ WHERE WORKSZ.EMPNUM = WORKSX.EMPNUM AND WORKSZ.PNUM = WORKSY.PNUM))[31m- 0198 ***  ***[0m
[31m  java.lang.RuntimeException: Parse failed.[0m
[31m  at scala.sys.package$.error(package.scala:27)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect$$anonfun$parse$1.apply(CalciteDialect.scala:33)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect$$anonfun$parse$1.apply(CalciteDialect.scala:32)[0m
[31m  at scala.Option.getOrElse(Option.scala:120)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect.parse(CalciteDialect.scala:31)[0m
[31m  at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)[0m
[31m  at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)[0m
[31m  at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:115)[0m
[31m  at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:114)[0m
[31m  at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)[0m
[31m  ...[0m
Calcite parsing passed, start to transform. SELECT PNUM FROM PROJ WHERE PROJ.CITY = (SELECT STAFF.CITY FROM STAFF WHERE EMPNUM = 'E1')
error SELECT PNUM FROM PROJ WHERE PROJ.CITY = (SELECT STAFF.CITY FROM STAFF WHERE EMPNUM = 'E1')[31m- 0199 ***  ***[0m
[31m  java.lang.RuntimeException: Parse failed.[0m
[31m  at scala.sys.package$.error(package.scala:27)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect$$anonfun$parse$1.apply(CalciteDialect.scala:33)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect$$anonfun$parse$1.apply(CalciteDialect.scala:32)[0m
[31m  at scala.Option.getOrElse(Option.scala:120)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect.parse(CalciteDialect.scala:31)[0m
[31m  at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)[0m
[31m  at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)[0m
[31m  at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:115)[0m
[31m  at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:114)[0m
[31m  at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)[0m
[31m  ...[0m
Calcite parsing passed, start to transform. SELECT PNUM FROM PROJ WHERE PROJ.CITY = (SELECT STAFF.CITY FROM STAFF WHERE EMPNUM > 'E1' )
error SELECT PNUM FROM PROJ WHERE PROJ.CITY = (SELECT STAFF.CITY FROM STAFF WHERE EMPNUM > 'E1' )[31m- 0200 ***  ***[0m
[31m  java.lang.RuntimeException: Parse failed.[0m
[31m  at scala.sys.package$.error(package.scala:27)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect$$anonfun$parse$1.apply(CalciteDialect.scala:33)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect$$anonfun$parse$1.apply(CalciteDialect.scala:32)[0m
[31m  at scala.Option.getOrElse(Option.scala:120)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect.parse(CalciteDialect.scala:31)[0m
[31m  at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)[0m
[31m  at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)[0m
[31m  at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:115)[0m
[31m  at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:114)[0m
[31m  at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)[0m
[31m  ...[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM STAFF WHERE STAFF.CITY = (SELECT PROJ.CITY FROM PROJ WHERE PNUM > 'P7')
error SELECT COUNT(*) FROM STAFF WHERE STAFF.CITY = (SELECT PROJ.CITY FROM PROJ WHERE PNUM > 'P7')[31m- 0201 ***  ***[0m
[31m  java.lang.RuntimeException: Parse failed.[0m
[31m  at scala.sys.package$.error(package.scala:27)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect$$anonfun$parse$1.apply(CalciteDialect.scala:33)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect$$anonfun$parse$1.apply(CalciteDialect.scala:32)[0m
[31m  at scala.Option.getOrElse(Option.scala:120)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect.parse(CalciteDialect.scala:31)[0m
[31m  at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)[0m
[31m  at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)[0m
[31m  at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:115)[0m
[31m  at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:114)[0m
[31m  at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)[0m
[31m  ...[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM STAFF WHERE NOT (STAFF.CITY = (SELECT PROJ.CITY FROM PROJ WHERE PNUM > 'P7' ))
error SELECT COUNT(*) FROM STAFF WHERE NOT (STAFF.CITY = (SELECT PROJ.CITY FROM PROJ WHERE PNUM > 'P7' ))[31m- 0202 ***  ***[0m
[31m  java.lang.RuntimeException: Parse failed.[0m
[31m  at scala.sys.package$.error(package.scala:27)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect$$anonfun$parse$1.apply(CalciteDialect.scala:33)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect$$anonfun$parse$1.apply(CalciteDialect.scala:32)[0m
[31m  at scala.Option.getOrElse(Option.scala:120)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect.parse(CalciteDialect.scala:31)[0m
[31m  at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)[0m
[31m  at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)[0m
[31m  at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:115)[0m
[31m  at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:114)[0m
[31m  at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)[0m
[31m  ...[0m
Calcite parsing passed, start to transform. SELECT PNUM FROM PROJ WHERE CITY <> 'Deale'
[32m- 0203[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM WORKS WHERE EMPNUM = 'E1'
[32m- 0204[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM WORKS WHERE EMPNUM = 'E1' AND EMPNUM = 'E1'
[32m- 0205[0m
Calcite parsing passed, start to transform. SELECT EMPNUM,GRADE FROM   STAFF ORDER  BY GRADE,EMPNUM
Calcite parsing passed, start to transform. SELECT EMPNUM,GRADE FROM   STAFF ORDER  BY GRADE,EMPNUM
Calcite parsing passed, start to transform. SELECT EMPNUM,GRADE FROM   STAFF ORDER  BY GRADE,EMPNUM
[31m- 0206 *** FAILED ***[0m
[31m  Results do not match for 0206:[0m
[31m  == Parsed Logical Plan ==[0m
[31m  'Sort ['GRADE ASC,'EMPNUM ASC], true[0m
[31m   'Project ['EMPNUM,'GRADE][0m
[31m    'UnresolvedRelation [STAFF], None[0m
  
[31m  == Analyzed Logical Plan ==[0m
[31m  EMPNUM: string, GRADE: double[0m
[31m  Sort [GRADE#33362 ASC,EMPNUM#33360 ASC], true[0m
[31m   Project [EMPNUM#33360,GRADE#33362][0m
[31m    MetastoreRelation HU, staff, None[0m
  
[31m  == Optimized Logical Plan ==[0m
[31m  Sort [GRADE#33362 ASC,EMPNUM#33360 ASC], true[0m
[31m   Project [EMPNUM#33360,GRADE#33362][0m
[31m    MetastoreRelation HU, staff, None[0m
  
[31m  == Physical Plan ==[0m
[31m  TungstenSort [GRADE#33362 ASC,EMPNUM#33360 ASC], true, 0[0m
[31m   ConvertToUnsafe[0m
[31m    Exchange rangepartitioning(GRADE#33362 ASC,EMPNUM#33360 ASC)[0m
[31m     HiveTableScan [EMPNUM#33360,GRADE#33362], (MetastoreRelation HU, staff, None)[0m
  
[31m  Code Generation: true[0m
[31m  EMPNUM	GRADE[0m
[31m  !== HIVE - 1 row(s) ==   == CATALYST - 1 row(s) ==[0m
[31m  !E36	36                  E36	36.0 (HiveComparisonTest.scala:433)[0m
Calcite parsing passed, start to transform. SELECT EMPNUM,CITY FROM   STAFF WHERE  EMPNUM='E1' OR NOT(EMPNUM='E1')
[32m- 0208[0m
Calcite parsing passed, start to transform. SELECT EMPNUM,CITY FROM   STAFF WHERE  EMPNUM='E1' AND NOT(EMPNUM='E1')
[32m- 0209[0m
Calcite parsing passed, start to transform. SELECT EMPNUM,PNUM FROM   WORKS WHERE HOURS < (SELECT HOURS FROM WORKS WHERE EMPNUM = 'E8') OR NOT(HOURS < (SELECT HOURS FROM WORKS WHERE EMPNUM = 'E8'))
error SELECT EMPNUM,PNUM FROM   WORKS WHERE HOURS < (SELECT HOURS FROM WORKS WHERE EMPNUM = 'E8') OR NOT(HOURS < (SELECT HOURS FROM WORKS WHERE EMPNUM = 'E8'))[31m- 0210 ***  ***[0m
[31m  java.lang.RuntimeException: Parse failed.[0m
[31m  at scala.sys.package$.error(package.scala:27)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect$$anonfun$parse$1.apply(CalciteDialect.scala:33)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect$$anonfun$parse$1.apply(CalciteDialect.scala:32)[0m
[31m  at scala.Option.getOrElse(Option.scala:120)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect.parse(CalciteDialect.scala:31)[0m
[31m  at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)[0m
[31m  at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)[0m
[31m  at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:115)[0m
[31m  at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:114)[0m
[31m  at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)[0m
[31m  ...[0m
Calcite parsing passed, start to transform. SELECT EMPNUM,PNUM FROM   WORKS WHERE HOURS < (SELECT HOURS FROM WORKS WHERE EMPNUM = 'E8') AND NOT(HOURS< (SELECT HOURS FROM WORKS WHERE EMPNUM = 'E8'))
error SELECT EMPNUM,PNUM FROM   WORKS WHERE HOURS < (SELECT HOURS FROM WORKS WHERE EMPNUM = 'E8') AND NOT(HOURS< (SELECT HOURS FROM WORKS WHERE EMPNUM = 'E8'))[31m- 0211 ***  ***[0m
[31m  java.lang.RuntimeException: Parse failed.[0m
[31m  at scala.sys.package$.error(package.scala:27)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect$$anonfun$parse$1.apply(CalciteDialect.scala:33)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect$$anonfun$parse$1.apply(CalciteDialect.scala:32)[0m
[31m  at scala.Option.getOrElse(Option.scala:120)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect.parse(CalciteDialect.scala:31)[0m
[31m  at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)[0m
[31m  at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)[0m
[31m  at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:115)[0m
[31m  at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:114)[0m
[31m  at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)[0m
[31m  ...[0m
Calcite parsing passed, start to transform. SELECT EMPNUM,PNUM FROM   WORKS WHERE HOURS < (SELECT HOURS FROM WORKS WHERE EMPNUM = 'E8') AND   HOURS IN (SELECT HOURS FROM WORKS)
error SELECT EMPNUM,PNUM FROM   WORKS WHERE HOURS < (SELECT HOURS FROM WORKS WHERE EMPNUM = 'E8') AND   HOURS IN (SELECT HOURS FROM WORKS)[31m- 0212 ***  ***[0m
[31m  java.lang.RuntimeException: Parse failed.[0m
[31m  at scala.sys.package$.error(package.scala:27)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect$$anonfun$parse$1.apply(CalciteDialect.scala:33)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect$$anonfun$parse$1.apply(CalciteDialect.scala:32)[0m
[31m  at scala.Option.getOrElse(Option.scala:120)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect.parse(CalciteDialect.scala:31)[0m
[31m  at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)[0m
[31m  at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)[0m
[31m  at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:115)[0m
[31m  at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:114)[0m
[31m  at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)[0m
[31m  ...[0m
Calcite parsing passed, start to transform. SELECT EMPNUM,PNUM FROM   WORKS WHERE HOURS < (SELECT HOURS FROM WORKS WHERE EMPNUM = 'E8') OR    HOURS IN (SELECT HOURS FROM WORKS) ORDER BY EMPNUM
error SELECT EMPNUM,PNUM FROM   WORKS WHERE HOURS < (SELECT HOURS FROM WORKS WHERE EMPNUM = 'E8') OR    HOURS IN (SELECT HOURS FROM WORKS) ORDER BY EMPNUM[31m- 0213 ***  ***[0m
[31m  java.lang.RuntimeException: Parse failed.[0m
[31m  at scala.sys.package$.error(package.scala:27)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect$$anonfun$parse$1.apply(CalciteDialect.scala:33)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect$$anonfun$parse$1.apply(CalciteDialect.scala:32)[0m
[31m  at scala.Option.getOrElse(Option.scala:120)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect.parse(CalciteDialect.scala:31)[0m
[31m  at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)[0m
[31m  at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)[0m
[31m  at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:115)[0m
[31m  at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:114)[0m
[31m  at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)[0m
[31m  ...[0m
Calcite parsing passed, start to transform. SELECT SUM(HOURS),AVG(HOURS),MIN(HOURS),MAX(HOURS) FROM    WORKS WHERE   EMPNUM='E1'
Calcite parsing passed, start to transform. SELECT SUM(HOURS),AVG(HOURS),MIN(HOURS),MAX(HOURS) FROM    WORKS WHERE   EMPNUM='E1'
Calcite parsing passed, start to transform. SELECT SUM(HOURS),AVG(HOURS),MIN(HOURS),MAX(HOURS) FROM    WORKS WHERE   EMPNUM='E1'
[31m- 0214 *** FAILED ***[0m
[31m  Results do not match for 0214:[0m
[31m  == Parsed Logical Plan ==[0m
[31m  'Project ['SUM('HOURS) AS c0#34391,'AVG('HOURS) AS c1#34392,'MIN('HOURS) AS c2#34393,'MAX('HOURS) AS c3#34394][0m
[31m   'Filter ('EMPNUM = E1)[0m
[31m    'UnresolvedRelation [WORKS], None[0m
  
[31m  == Analyzed Logical Plan ==[0m
[31m  c0: double, c1: double, c2: double, c3: double[0m
[31m  Aggregate [sum(HOURS#34397) AS c0#34391,avg(HOURS#34397) AS c1#34392,min(HOURS#34397) AS c2#34393,max(HOURS#34397) AS c3#34394][0m
[31m   Filter (EMPNUM#34395 = E1)[0m
[31m    MetastoreRelation HU, works, None[0m
  
[31m  == Optimized Logical Plan ==[0m
[31m  Aggregate [sum(HOURS#34397) AS c0#34391,avg(HOURS#34397) AS c1#34392,min(HOURS#34397) AS c2#34393,max(HOURS#34397) AS c3#34394][0m
[31m   Project [HOURS#34397][0m
[31m    Filter (EMPNUM#34395 = E1)[0m
[31m     MetastoreRelation HU, works, None[0m
  
[31m  == Physical Plan ==[0m
[31m  TungstenAggregate(key=[], functions=[(sum(HOURS#34397),mode=Final,isDistinct=false),(average(HOURS#34397),mode=Final,isDistinct=false),(min(HOURS#34397),mode=Final,isDistinct=false),(max(HOURS#34397),mode=Final,isDistinct=false)], output=[c0#34391,c1#34392,c2#34393,c3#34394])[0m
[31m   TungstenExchange SinglePartition[0m
[31m    TungstenAggregate(key=[], functions=[(sum(HOURS#34397),mode=Partial,isDistinct=false),(average(HOURS#34397),mode=Partial,isDistinct=false),(min(HOURS#34397),mode=Partial,isDistinct=false),(max(HOURS#34397),mode=Partial,isDistinct=false)], output=[currentSum#34404,currentSum#34407,currentCount#34408L,min#34410,max#34412])[0m
[31m     Project [HOURS#34397][0m
[31m      Filter (EMPNUM#34395 = E1)[0m
[31m       HiveTableScan [HOURS#34397,EMPNUM#34395], (MetastoreRelation HU, works, None)[0m
  
[31m  Code Generation: true[0m
[31m  c0	c1	c2	c3[0m
[31m  !== HIVE - 1 row(s) ==   == CATALYST - 1 row(s) ==[0m
[31m  !104	20.8	12	40          104.0	20.8	12.0	40.0 (HiveComparisonTest.scala:433)[0m
Calcite parsing passed, start to transform. SELECT PNUM,AVG(HOURS),MIN(HOURS),MAX(HOURS) FROM    WORKS WHERE   EMPNUM='E8' GROUP BY PNUM
Calcite parsing passed, start to transform. SELECT PNUM,AVG(HOURS),MIN(HOURS),MAX(HOURS) FROM    WORKS WHERE   EMPNUM='E8' GROUP BY PNUM
Calcite parsing passed, start to transform. SELECT PNUM,AVG(HOURS),MIN(HOURS),MAX(HOURS) FROM    WORKS WHERE   EMPNUM='E8' GROUP BY PNUM
[31m- 0215 *** FAILED ***[0m
[31m  Results do not match for 0215:[0m
[31m  == Parsed Logical Plan ==[0m
[31m  'Aggregate ['PNUM], ['PNUM,'AVG('HOURS) AS c1#34794,'MIN('HOURS) AS c2#34795,'MAX('HOURS) AS c3#34796][0m
[31m   'Filter ('EMPNUM = E8)[0m
[31m    'UnresolvedRelation [WORKS], None[0m
  
[31m  == Analyzed Logical Plan ==[0m
[31m  PNUM: string, c1: double, c2: double, c3: double[0m
[31m  Aggregate [PNUM#34798], [PNUM#34798,avg(HOURS#34799) AS c1#34794,min(HOURS#34799) AS c2#34795,max(HOURS#34799) AS c3#34796][0m
[31m   Filter (EMPNUM#34797 = E8)[0m
[31m    MetastoreRelation HU, works, None[0m
  
[31m  == Optimized Logical Plan ==[0m
[31m  Aggregate [PNUM#34798], [PNUM#34798,avg(HOURS#34799) AS c1#34794,min(HOURS#34799) AS c2#34795,max(HOURS#34799) AS c3#34796][0m
[31m   Project [PNUM#34798,HOURS#34799][0m
[31m    Filter (EMPNUM#34797 = E8)[0m
[31m     MetastoreRelation HU, works, None[0m
  
[31m  == Physical Plan ==[0m
[31m  TungstenAggregate(key=[PNUM#34798], functions=[(average(HOURS#34799),mode=Final,isDistinct=false),(min(HOURS#34799),mode=Final,isDistinct=false),(max(HOURS#34799),mode=Final,isDistinct=false)], output=[PNUM#34798,c1#34794,c2#34795,c3#34796])[0m
[31m   TungstenExchange hashpartitioning(PNUM#34798)[0m
[31m    TungstenAggregate(key=[PNUM#34798], functions=[(average(HOURS#34799),mode=Partial,isDistinct=false),(min(HOURS#34799),mode=Partial,isDistinct=false),(max(HOURS#34799),mode=Partial,isDistinct=false)], output=[PNUM#34798,currentSum#34806,currentCount#34807L,min#34809,max#34811])[0m
[31m     Project [PNUM#34798,HOURS#34799][0m
[31m      Filter (EMPNUM#34797 = E8)[0m
[31m       HiveTableScan [PNUM#34798,HOURS#34799,EMPNUM#34797], (MetastoreRelation HU, works, None)[0m
  
[31m  Code Generation: true[0m
[31m  PNUM	c1	c2	c3[0m
[31m  !== HIVE - 1 row(s) ==   == CATALYST - 1 row(s) ==[0m
[31m  !P8	20	20	20             P8	20.0	20.0	20.0 (HiveComparisonTest.scala:433)[0m
Calcite parsing passed, start to transform. SELECT SUM(HOURS),AVG(HOURS),MIN(HOURS),MAX(HOURS) FROM    WORKS WHERE   EMPNUM='E8' GROUP BY PNUM
Calcite parsing passed, start to transform. SELECT SUM(HOURS),AVG(HOURS),MIN(HOURS),MAX(HOURS) FROM    WORKS WHERE   EMPNUM='E8' GROUP BY PNUM
Calcite parsing passed, start to transform. SELECT SUM(HOURS),AVG(HOURS),MIN(HOURS),MAX(HOURS) FROM    WORKS WHERE   EMPNUM='E8' GROUP BY PNUM
[31m- 0216 *** FAILED ***[0m
[31m  Results do not match for 0216:[0m
[31m  == Parsed Logical Plan ==[0m
[31m  'Aggregate ['PNUM], ['SUM('HOURS) AS c0#35182,'AVG('HOURS) AS c1#35183,'MIN('HOURS) AS c2#35184,'MAX('HOURS) AS c3#35185][0m
[31m   'Filter ('EMPNUM = E8)[0m
[31m    'UnresolvedRelation [WORKS], None[0m
  
[31m  == Analyzed Logical Plan ==[0m
[31m  c0: double, c1: double, c2: double, c3: double[0m
[31m  Aggregate [PNUM#35187], [sum(HOURS#35188) AS c0#35182,avg(HOURS#35188) AS c1#35183,min(HOURS#35188) AS c2#35184,max(HOURS#35188) AS c3#35185][0m
[31m   Filter (EMPNUM#35186 = E8)[0m
[31m    MetastoreRelation HU, works, None[0m
  
[31m  == Optimized Logical Plan ==[0m
[31m  Aggregate [PNUM#35187], [sum(HOURS#35188) AS c0#35182,avg(HOURS#35188) AS c1#35183,min(HOURS#35188) AS c2#35184,max(HOURS#35188) AS c3#35185][0m
[31m   Project [PNUM#35187,HOURS#35188][0m
[31m    Filter (EMPNUM#35186 = E8)[0m
[31m     MetastoreRelation HU, works, None[0m
  
[31m  == Physical Plan ==[0m
[31m  TungstenAggregate(key=[PNUM#35187], functions=[(sum(HOURS#35188),mode=Final,isDistinct=false),(average(HOURS#35188),mode=Final,isDistinct=false),(min(HOURS#35188),mode=Final,isDistinct=false),(max(HOURS#35188),mode=Final,isDistinct=false)], output=[c0#35182,c1#35183,c2#35184,c3#35185])[0m
[31m   TungstenExchange hashpartitioning(PNUM#35187)[0m
[31m    TungstenAggregate(key=[PNUM#35187], functions=[(sum(HOURS#35188),mode=Partial,isDistinct=false),(average(HOURS#35188),mode=Partial,isDistinct=false),(min(HOURS#35188),mode=Partial,isDistinct=false),(max(HOURS#35188),mode=Partial,isDistinct=false)], output=[PNUM#35187,currentSum#35195,currentSum#35198,currentCount#35199L,min#35201,max#35203])[0m
[31m     Project [PNUM#35187,HOURS#35188][0m
[31m      Filter (EMPNUM#35186 = E8)[0m
[31m       HiveTableScan [PNUM#35187,HOURS#35188,EMPNUM#35186], (MetastoreRelation HU, works, None)[0m
  
[31m  Code Generation: true[0m
[31m  c0	c1	c2	c3[0m
[31m  !== HIVE - 1 row(s) ==   == CATALYST - 1 row(s) ==[0m
[31m  !20	20	20	20             20.0	20.0	20.0	20.0 (HiveComparisonTest.scala:433)[0m
Calcite parsing passed, start to transform. SELECT PNUM,AVG(HOURS),MIN(HOURS),MAX(HOURS) FROM    WORKS GROUP BY PNUM ORDER BY PNUM
Calcite parsing passed, start to transform. SELECT PNUM,AVG(HOURS),MIN(HOURS),MAX(HOURS) FROM    WORKS GROUP BY PNUM ORDER BY PNUM
Calcite parsing passed, start to transform. SELECT PNUM,AVG(HOURS),MIN(HOURS),MAX(HOURS) FROM    WORKS GROUP BY PNUM ORDER BY PNUM
[31m- 0217 *** FAILED ***[0m
[31m  Results do not match for 0217:[0m
[31m  == Parsed Logical Plan ==[0m
[31m  'Sort ['PNUM ASC], true[0m
[31m   'Aggregate ['PNUM], ['PNUM,'AVG('HOURS) AS c1#35585,'MIN('HOURS) AS c2#35586,'MAX('HOURS) AS c3#35587][0m
[31m    'UnresolvedRelation [WORKS], None[0m
  
[31m  == Analyzed Logical Plan ==[0m
[31m  PNUM: string, c1: double, c2: double, c3: double[0m
[31m  Sort [PNUM#35589 ASC], true[0m
[31m   Aggregate [PNUM#35589], [PNUM#35589,avg(HOURS#35590) AS c1#35585,min(HOURS#35590) AS c2#35586,max(HOURS#35590) AS c3#35587][0m
[31m    MetastoreRelation HU, works, None[0m
  
[31m  == Optimized Logical Plan ==[0m
[31m  Sort [PNUM#35589 ASC], true[0m
[31m   Aggregate [PNUM#35589], [PNUM#35589,avg(HOURS#35590) AS c1#35585,min(HOURS#35590) AS c2#35586,max(HOURS#35590) AS c3#35587][0m
[31m    Project [PNUM#35589,HOURS#35590][0m
[31m     MetastoreRelation HU, works, None[0m
  
[31m  == Physical Plan ==[0m
[31m  TungstenSort [PNUM#35589 ASC], true, 0[0m
[31m   ConvertToUnsafe[0m
[31m    Exchange rangepartitioning(PNUM#35589 ASC)[0m
[31m     ConvertToSafe[0m
[31m      TungstenAggregate(key=[PNUM#35589], functions=[(average(HOURS#35590),mode=Final,isDistinct=false),(min(HOURS#35590),mode=Final,isDistinct=false),(max(HOURS#35590),mode=Final,isDistinct=false)], output=[PNUM#35589,c1#35585,c2#35586,c3#35587])[0m
[31m       TungstenExchange hashpartitioning(PNUM#35589)[0m
[31m        TungstenAggregate(key=[PNUM#35589], functions=[(average(HOURS#35590),mode=Partial,isDistinct=false),(min(HOURS#35590),mode=Partial,isDistinct=false),(max(HOURS#35590),mode=Partial,isDistinct=false)], output=[PNUM#35589,currentSum#35598,currentCount#35599L,min#35601,max#35603])[0m
[31m         HiveTableScan [PNUM#35589,HOURS#35590], (MetastoreRelation HU, works, None)[0m
  
[31m  Code Generation: true[0m
[31m  PNUM	c1	c2	c3[0m
[31m  !== HIVE - 9 row(s) ==   == CATALYST - 9 row(s) ==[0m
[31m  !P1	40	40	40             P1	40.0	40.0	40.0[0m
[31m   P18	NULL	NULL	NULL      P18	NULL	NULL	NULL[0m
[31m  !P2	40	20	80             P2	40.0	20.0	80.0[0m
[31m   P22	NULL	NULL	NULL      P22	NULL	NULL	NULL[0m
[31m  !P4	30	20	40             P4	30.0	20.0	40.0[0m
[31m  !P5	46	12	80             P5	46.0	12.0	80.0[0m
[31m  !P6	12	12	12             P6	12.0	12.0	12.0[0m
[31m  !P8	20	20	20             P8	20.0	20.0	20.0[0m
[31m   P9	NULL	NULL	NULL       P9	NULL	NULL	NULL (HiveComparisonTest.scala:433)[0m
Calcite parsing passed, start to transform. SELECT +MAX(DISTINCT HOURS) FROM WORKS
Calcite parsing passed, start to transform. SELECT +MAX(DISTINCT HOURS) FROM WORKS
Calcite parsing passed, start to transform. SELECT +MAX(DISTINCT HOURS) FROM WORKS
[31m- 0218 *** FAILED ***[0m
[31m  Results do not match for 0218:[0m
[31m  == Parsed Logical Plan ==[0m
[31m  'Project ['MAX('HOURS) AS c0#35976][0m
[31m   'UnresolvedRelation [WORKS], None[0m
  
[31m  == Analyzed Logical Plan ==[0m
[31m  c0: double[0m
[31m  Aggregate [max(HOURS#35979) AS c0#35976][0m
[31m   MetastoreRelation HU, works, None[0m
  
[31m  == Optimized Logical Plan ==[0m
[31m  Aggregate [max(HOURS#35979) AS c0#35976][0m
[31m   Project [HOURS#35979][0m
[31m    MetastoreRelation HU, works, None[0m
  
[31m  == Physical Plan ==[0m
[31m  TungstenAggregate(key=[], functions=[(max(HOURS#35979),mode=Final,isDistinct=false)], output=[c0#35976])[0m
[31m   TungstenExchange SinglePartition[0m
[31m    TungstenAggregate(key=[], functions=[(max(HOURS#35979),mode=Partial,isDistinct=false)], output=[max#35982])[0m
[31m     HiveTableScan [HOURS#35979], (MetastoreRelation HU, works, None)[0m
  
[31m  Code Generation: true[0m
[31m  c0[0m
[31m  !== HIVE - 1 row(s) ==   == CATALYST - 1 row(s) ==[0m
[31m  !80                      80.0 (HiveComparisonTest.scala:433)[0m
Calcite parsing passed, start to transform. SELECT -MAX(DISTINCT HOURS) FROM WORKS
Calcite parsing passed, start to transform. SELECT -MAX(DISTINCT HOURS) FROM WORKS
Calcite parsing passed, start to transform. SELECT -MAX(DISTINCT HOURS) FROM WORKS
[31m- 0219 *** FAILED ***[0m
[31m  Results do not match for 0219:[0m
[31m  == Parsed Logical Plan ==[0m
[31m  'Project [-'MAX('HOURS) AS c0#36325][0m
[31m   'UnresolvedRelation [WORKS], None[0m
  
[31m  == Analyzed Logical Plan ==[0m
[31m  c0: double[0m
[31m  Aggregate [-max(HOURS#36328) AS c0#36325][0m
[31m   MetastoreRelation HU, works, None[0m
  
[31m  == Optimized Logical Plan ==[0m
[31m  Aggregate [-max(HOURS#36328) AS c0#36325][0m
[31m   Project [HOURS#36328][0m
[31m    MetastoreRelation HU, works, None[0m
  
[31m  == Physical Plan ==[0m
[31m  TungstenAggregate(key=[], functions=[(max(HOURS#36328),mode=Final,isDistinct=false)], output=[c0#36325])[0m
[31m   TungstenExchange SinglePartition[0m
[31m    TungstenAggregate(key=[], functions=[(max(HOURS#36328),mode=Partial,isDistinct=false)], output=[max#36331])[0m
[31m     HiveTableScan [HOURS#36328], (MetastoreRelation HU, works, None)[0m
  
[31m  Code Generation: true[0m
[31m  c0[0m
[31m  !== HIVE - 1 row(s) ==   == CATALYST - 1 row(s) ==[0m
[31m  !-80                     -80.0 (HiveComparisonTest.scala:433)[0m
Calcite parsing passed, start to transform. SELECT EMPNUM FROM WORKS1 WHERE HOURS IS NULL
[32m- 0220[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM WORKS WHERE EMPNUM='E9'
[32m- 0221[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM WORKS WHERE HOURS IS NULL
[32m- 0222[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM VTABLE
[32m- 0223[0m
Calcite parsing passed, start to transform. SELECT +COL1+COL2 - COL3*COL4/COL1 FROM VTABLE WHERE COL1=10
Calcite parsing passed, start to transform. SELECT +COL1+COL2 - COL3*COL4/COL1 FROM VTABLE WHERE COL1=10
Calcite parsing passed, start to transform. SELECT +COL1+COL2 - COL3*COL4/COL1 FROM VTABLE WHERE COL1=10
[31m- 0224 *** FAILED ***[0m
[31m  Results do not match for 0224:[0m
[31m  == Parsed Logical Plan ==[0m
[31m  'Project [(('COL1 + 'COL2) - (('COL3 * 'COL4) / 'COL1)) AS c0#37127][0m
[31m   'Filter ('COL1 = 10)[0m
[31m    'UnresolvedRelation [VTABLE], None[0m
  
[31m  == Analyzed Logical Plan ==[0m
[31m  c0: double[0m
[31m  Project [((COL1#37128 + COL2#37129) - ((COL3#37130 * COL4#37131) / COL1#37128)) AS c0#37127][0m
[31m   Filter (COL1#37128 = cast(10 as double))[0m
[31m    MetastoreRelation HU, vtable, None[0m
  
[31m  == Optimized Logical Plan ==[0m
[31m  Project [((COL1#37128 + COL2#37129) - ((COL3#37130 * COL4#37131) / COL1#37128)) AS c0#37127][0m
[31m   Filter (COL1#37128 = 10.0)[0m
[31m    MetastoreRelation HU, vtable, None[0m
  
[31m  == Physical Plan ==[0m
[31m  Project [((COL1#37128 + COL2#37129) - ((COL3#37130 * COL4#37131) / COL1#37128)) AS c0#37127][0m
[31m   Filter (COL1#37128 = 10.0)[0m
[31m    HiveTableScan [COL1#37128,COL2#37129,COL3#37130,COL4#37131], (MetastoreRelation HU, vtable, None)[0m
  
[31m  Code Generation: true[0m
[31m  c0[0m
[31m  !== HIVE - 1 row(s) ==   == CATALYST - 1 row(s) ==[0m
[31m  !-90                     -90.0 (HiveComparisonTest.scala:433)[0m
Calcite parsing passed, start to transform. SELECT (-COL2+COL1)*COL3 - COL3/COL1 FROM VTABLE WHERE COL4 IS NULL
Calcite parsing passed, start to transform. SELECT (-COL2+COL1)*COL3 - COL3/COL1 FROM VTABLE WHERE COL4 IS NULL
Calcite parsing passed, start to transform. SELECT (-COL2+COL1)*COL3 - COL3/COL1 FROM VTABLE WHERE COL4 IS NULL
[31m- 0225 *** FAILED ***[0m
[31m  Results do not match for 0225:[0m
[31m  == Parsed Logical Plan ==[0m
[31m  'Project [(((-'COL2 + 'COL1) * 'COL3) - ('COL3 / 'COL1)) AS c0#37320][0m
[31m   'Filter isnull('COL4)[0m
[31m    'UnresolvedRelation [VTABLE], None[0m
  
[31m  == Analyzed Logical Plan ==[0m
[31m  c0: double[0m
[31m  Project [(((-COL2#37322 + COL1#37321) * COL3#37323) - (COL3#37323 / COL1#37321)) AS c0#37320][0m
[31m   Filter isnull(COL4#37324)[0m
[31m    MetastoreRelation HU, vtable, None[0m
  
[31m  == Optimized Logical Plan ==[0m
[31m  Project [(((-COL2#37322 + COL1#37321) * COL3#37323) - (COL3#37323 / COL1#37321)) AS c0#37320][0m
[31m   Filter isnull(COL4#37324)[0m
[31m    MetastoreRelation HU, vtable, None[0m
  
[31m  == Physical Plan ==[0m
[31m  Project [(((-COL2#37322 + COL1#37321) * COL3#37323) - (COL3#37323 / COL1#37321)) AS c0#37320][0m
[31m   Filter isnull(COL4#37324)[0m
[31m    HiveTableScan [COL2#37322,COL1#37321,COL3#37323,COL4#37324], (MetastoreRelation HU, vtable, None)[0m
  
[31m  Code Generation: true[0m
[31m  c0[0m
[31m  !== HIVE - 1 row(s) ==   == CATALYST - 1 row(s) ==[0m
[31m  !8999997                 8999997.0 (HiveComparisonTest.scala:433)[0m
Calcite parsing passed, start to transform. SELECT COUNT(*),SUM(NUMKEY) FROM UPUNIQ
Calcite parsing passed, start to transform. SELECT COUNT(*),SUM(NUMKEY) FROM UPUNIQ
Calcite parsing passed, start to transform. SELECT COUNT(*),SUM(NUMKEY) FROM UPUNIQ
[31m- 0226 *** FAILED ***[0m
[31m  Results do not match for 0226:[0m
[31m  == Parsed Logical Plan ==[0m
[31m  'Project [count(1) AS c0#37513L,'SUM('NUMKEY) AS c1#37514][0m
[31m   'UnresolvedRelation [UPUNIQ], None[0m
  
[31m  == Analyzed Logical Plan ==[0m
[31m  c0: bigint, c1: double[0m
[31m  Aggregate [count(1) AS c0#37513L,sum(NUMKEY#37515) AS c1#37514][0m
[31m   MetastoreRelation HU, upuniq, None[0m
  
[31m  == Optimized Logical Plan ==[0m
[31m  Aggregate [count(1) AS c0#37513L,sum(NUMKEY#37515) AS c1#37514][0m
[31m   Project [NUMKEY#37515][0m
[31m    MetastoreRelation HU, upuniq, None[0m
  
[31m  == Physical Plan ==[0m
[31m  TungstenAggregate(key=[], functions=[(count(1),mode=Final,isDistinct=false),(sum(NUMKEY#37515),mode=Final,isDistinct=false)], output=[c0#37513L,c1#37514])[0m
[31m   TungstenExchange SinglePartition[0m
[31m    TungstenAggregate(key=[], functions=[(count(1),mode=Partial,isDistinct=false),(sum(NUMKEY#37515),mode=Partial,isDistinct=false)], output=[currentCount#37520L,currentSum#37522])[0m
[31m     HiveTableScan [NUMKEY#37515], (MetastoreRelation HU, upuniq, None)[0m
  
[31m  Code Generation: true[0m
[31m  c0	c1[0m
[31m  !== HIVE - 1 row(s) ==   == CATALYST - 1 row(s) ==[0m
[31m  !6	30                    6	30.0 (HiveComparisonTest.scala:433)[0m
Calcite parsing passed, start to transform. SELECT COUNT(*),SUM(NUMKEY) FROM UPUNIQ
Calcite parsing passed, start to transform. SELECT COUNT(*),SUM(NUMKEY) FROM UPUNIQ
Calcite parsing passed, start to transform. SELECT COUNT(*),SUM(NUMKEY) FROM UPUNIQ
[31m- 0227 *** FAILED ***[0m
[31m  Results do not match for 0227:[0m
[31m  == Parsed Logical Plan ==[0m
[31m  'Project [count(1) AS c0#37724L,'SUM('NUMKEY) AS c1#37725][0m
[31m   'UnresolvedRelation [UPUNIQ], None[0m
  
[31m  == Analyzed Logical Plan ==[0m
[31m  c0: bigint, c1: double[0m
[31m  Aggregate [count(1) AS c0#37724L,sum(NUMKEY#37726) AS c1#37725][0m
[31m   MetastoreRelation HU, upuniq, None[0m
  
[31m  == Optimized Logical Plan ==[0m
[31m  Aggregate [count(1) AS c0#37724L,sum(NUMKEY#37726) AS c1#37725][0m
[31m   Project [NUMKEY#37726][0m
[31m    MetastoreRelation HU, upuniq, None[0m
  
[31m  == Physical Plan ==[0m
[31m  TungstenAggregate(key=[], functions=[(count(1),mode=Final,isDistinct=false),(sum(NUMKEY#37726),mode=Final,isDistinct=false)], output=[c0#37724L,c1#37725])[0m
[31m   TungstenExchange SinglePartition[0m
[31m    TungstenAggregate(key=[], functions=[(count(1),mode=Partial,isDistinct=false),(sum(NUMKEY#37726),mode=Partial,isDistinct=false)], output=[currentCount#37731L,currentSum#37733])[0m
[31m     HiveTableScan [NUMKEY#37726], (MetastoreRelation HU, upuniq, None)[0m
  
[31m  Code Generation: true[0m
[31m  c0	c1[0m
[31m  !== HIVE - 1 row(s) ==   == CATALYST - 1 row(s) ==[0m
[31m  !6	34                    6	34.0 (HiveComparisonTest.scala:433)[0m
Calcite parsing passed, start to transform. SELECT GRADE,CITY FROM STAFF WHERE EMPNUM = 'E8'
Calcite parsing passed, start to transform. SELECT GRADE,CITY FROM STAFF WHERE EMPNUM = 'E8'
Calcite parsing passed, start to transform. SELECT GRADE,CITY FROM STAFF WHERE EMPNUM = 'E8'
[31m- 0228 *** FAILED ***[0m
[31m  Results do not match for 0228:[0m
[31m  == Parsed Logical Plan ==[0m
[31m  'Project ['GRADE,'CITY][0m
[31m   'Filter ('EMPNUM = E8)[0m
[31m    'UnresolvedRelation [STAFF], None[0m
  
[31m  == Analyzed Logical Plan ==[0m
[31m  GRADE: double, CITY: string[0m
[31m  Project [GRADE#38063,CITY#38064][0m
[31m   Filter (EMPNUM#38061 = E8)[0m
[31m    MetastoreRelation HU, staff, None[0m
  
[31m  == Optimized Logical Plan ==[0m
[31m  Project [GRADE#38063,CITY#38064][0m
[31m   Filter (EMPNUM#38061 = E8)[0m
[31m    MetastoreRelation HU, staff, None[0m
  
[31m  == Physical Plan ==[0m
[31m  Project [GRADE#38063,CITY#38064][0m
[31m   Filter (EMPNUM#38061 = E8)[0m
[31m    HiveTableScan [GRADE#38063,CITY#38064,EMPNUM#38061], (MetastoreRelation HU, staff, None)[0m
  
[31m  Code Generation: true[0m
[31m  GRADE	CITY[0m
[31m  !== HIVE - 1 row(s) ==   == CATALYST - 1 row(s) ==[0m
[31m  !15	Xi'an                15.0	Xi'an (HiveComparisonTest.scala:433)[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM JJ WHERE FLOATTEST > 123455 AND FLOATTEST < 123457
[32m- 0229[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM JJ WHERE FLOATTEST > 122 AND FLOATTEST < 124
[32m- 0230[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM JJ WHERE FLOATTEST > -124 AND FLOATTEST < -122
[32m- 0231[0m
Calcite parsing passed, start to transform. SELECT EMPNUM,PNUM FROM WORKS WHERE EMPNUM='UPP' AND PNUM='low'
[32m- 0232[0m
Calcite parsing passed, start to transform. SELECT EMPNUM,PNUM FROM WORKS WHERE EMPNUM='upp' OR PNUM='LOW'
[32m- 0233[0m
Calcite parsing passed, start to transform. SELECT REALTEST FROM GG
[32m- 0234[0m
Calcite parsing passed, start to transform. SELECT * FROM GG WHERE REALTEST > 1.234561 and REALTEST < 1.234573
[32m- 0235[0m
Calcite parsing passed, start to transform. SELECT DOUBLETEST FROM II
Calcite parsing passed, start to transform. SELECT DOUBLETEST FROM II
Calcite parsing passed, start to transform. SELECT DOUBLETEST FROM II
[31m- 0236 *** FAILED ***[0m
[31m  Results do not match for 0236:[0m
[31m  == Parsed Logical Plan ==[0m
[31m  'Project ['DOUBLETEST][0m
[31m   'UnresolvedRelation [II], None[0m
  
[31m  == Analyzed Logical Plan ==[0m
[31m  DOUBLETEST: float[0m
[31m  Project [DOUBLETEST#39195][0m
[31m   MetastoreRelation HU, ii, None[0m
  
[31m  == Optimized Logical Plan ==[0m
[31m  Project [DOUBLETEST#39195][0m
[31m   MetastoreRelation HU, ii, None[0m
  
[31m  == Physical Plan ==[0m
[31m  HiveTableScan [DOUBLETEST#39195], (MetastoreRelation HU, ii, None)[0m
  
[31m  Code Generation: true[0m
[31m  DOUBLETEST[0m
[31m  !== HIVE - 2 row(s) ==   == CATALYST - 2 row(s) ==[0m
[31m  !-0.1073741823           -0.107374184[0m
[31m  !123456.123456           123456.125 (HiveComparisonTest.scala:433)[0m
Calcite parsing passed, start to transform. SELECT * FROM II WHERE DOUBLETEST > 123456.123450 and DOUBLETEST < 123456.123462
[32m- 0237[0m
Calcite parsing passed, start to transform. SELECT FLOATTEST FROM JJ
Calcite parsing passed, start to transform. SELECT FLOATTEST FROM JJ
Calcite parsing passed, start to transform. SELECT FLOATTEST FROM JJ
[31m- 0238 *** FAILED ***[0m
[31m  Results do not match for 0238:[0m
[31m  == Parsed Logical Plan ==[0m
[31m  'Project ['FLOATTEST][0m
[31m   'UnresolvedRelation [JJ], None[0m
  
[31m  == Analyzed Logical Plan ==[0m
[31m  FLOATTEST: float[0m
[31m  Project [FLOATTEST#39473][0m
[31m   MetastoreRelation HU, jj, None[0m
  
[31m  == Optimized Logical Plan ==[0m
[31m  Project [FLOATTEST#39473][0m
[31m   MetastoreRelation HU, jj, None[0m
  
[31m  == Physical Plan ==[0m
[31m  HiveTableScan [FLOATTEST#39473], (MetastoreRelation HU, jj, None)[0m
  
[31m  Code Generation: true[0m
[31m  FLOATTEST[0m
[31m  !== HIVE - 5 row(s) ==   == CATALYST - 5 row(s) ==[0m
[31m   -0.1048575              -0.1048575[0m
[31m   -123.456                -123.456[0m
[31m   12.345678               12.345678[0m
[31m   123.456                 123.456[0m
[31m  !123456                  123456.0 (HiveComparisonTest.scala:433)[0m
Calcite parsing passed, start to transform. SELECT * FROM JJ WHERE FLOATTEST > 12.345672 and FLOATTEST < 12.345684
[32m- 0239[0m
Calcite parsing passed, start to transform. SELECT FLOATTEST FROM KK
Calcite parsing passed, start to transform. SELECT FLOATTEST FROM KK
Calcite parsing passed, start to transform. SELECT FLOATTEST FROM KK
[31m- 0240 *** FAILED ***[0m
[31m  Results do not match for 0240:[0m
[31m  == Parsed Logical Plan ==[0m
[31m  'Project ['FLOATTEST][0m
[31m   'UnresolvedRelation [KK], None[0m
  
[31m  == Analyzed Logical Plan ==[0m
[31m  FLOATTEST: float[0m
[31m  Project [FLOATTEST#39767][0m
[31m   MetastoreRelation HU, kk, None[0m
  
[31m  == Optimized Logical Plan ==[0m
[31m  Project [FLOATTEST#39767][0m
[31m   MetastoreRelation HU, kk, None[0m
  
[31m  == Physical Plan ==[0m
[31m  HiveTableScan [FLOATTEST#39767], (MetastoreRelation HU, kk, None)[0m
  
[31m  Code Generation: true[0m
[31m  FLOATTEST[0m
[31m  !== HIVE - 19 row(s) ==   == CATALYST - 19 row(s) ==[0m
[31m  !123456.1235              123456.125[0m
[31m  !123456.1235              123456.125[0m
[31m  !123456.1235              123456.125[0m
[31m  !123456.1235              123456.125[0m
[31m  !123456.1235              123456.125[0m
[31m  !123456.1235              123456.125[0m
[31m  !123456.1235              123456.125[0m
[31m  !123456.1235              123456.125[0m
[31m  !123456.1235              123456.125[0m
[31m  !123456.1235              123456.125[0m
[31m  !123456.1235              123456.125[0m
[31m  !123456.1235              123456.125[0m
[31m  !123456.1235              123456.125[0m
[31m  !123456.1235              123456.125[0m
[31m  !123456.1235              123456.125[0m
[31m  !123456.1235              123456.125[0m
[31m  !123456.1235              123456.125[0m
[31m  !123456.1235              123456.125[0m
[31m  !123456.1235              123456.125 (HiveComparisonTest.scala:433)[0m
Calcite parsing passed, start to transform. SELECT * FROM KK WHERE FLOATTEST > 123456.123450 and FLOATTEST < 123456.123462
[32m- 0241[0m
Calcite parsing passed, start to transform. SELECT * FROM LL
[32m- 0242[0m
Calcite parsing passed, start to transform. SELECT * FROM LL WHERE NUMTEST > 123456.123450 and NUMTEST < 123456.123462
[32m- 0243[0m
Calcite parsing passed, start to transform. SELECT * FROM PP
[32m- 0244[0m
Calcite parsing passed, start to transform. SELECT * FROM SS
[32m- 0245[0m
Calcite parsing passed, start to transform. SELECT FLOATTEST FROM JJ ORDER BY FLOATTEST DESC
Calcite parsing passed, start to transform. SELECT FLOATTEST FROM JJ ORDER BY FLOATTEST DESC
Calcite parsing passed, start to transform. SELECT FLOATTEST FROM JJ ORDER BY FLOATTEST DESC
[31m- 0246 *** FAILED ***[0m
[31m  Results do not match for 0246:[0m
[31m  == Parsed Logical Plan ==[0m
[31m  'Sort ['FLOATTEST DESC], true[0m
[31m   'Project ['FLOATTEST][0m
[31m    'UnresolvedRelation [JJ], None[0m
  
[31m  == Analyzed Logical Plan ==[0m
[31m  FLOATTEST: float[0m
[31m  Sort [FLOATTEST#40459 DESC], true[0m
[31m   Project [FLOATTEST#40459][0m
[31m    MetastoreRelation HU, jj, None[0m
  
[31m  == Optimized Logical Plan ==[0m
[31m  Sort [FLOATTEST#40459 DESC], true[0m
[31m   Project [FLOATTEST#40459][0m
[31m    MetastoreRelation HU, jj, None[0m
  
[31m  == Physical Plan ==[0m
[31m  TungstenSort [FLOATTEST#40459 DESC], true, 0[0m
[31m   ConvertToUnsafe[0m
[31m    Exchange rangepartitioning(FLOATTEST#40459 DESC)[0m
[31m     HiveTableScan [FLOATTEST#40459], (MetastoreRelation HU, jj, None)[0m
  
[31m  Code Generation: true[0m
[31m  FLOATTEST[0m
[31m  !== HIVE - 11 row(s) ==   == CATALYST - 11 row(s) ==[0m
[31m  !123456                   123456.0[0m
[31m   123.456                  123.456[0m
[31m   66.3                     66.3[0m
[31m   66.2                     66.2[0m
[31m   12.345678                12.345678[0m
[31m   0.2222                   0.2222[0m
[31m   -0.1048575               -0.1048575[0m
[31m   -44.5                    -44.5[0m
[31m   -66.25                   -66.25[0m
[31m  !-87                      -87.0[0m
[31m   -123.456                 -123.456 (HiveComparisonTest.scala:433)[0m
Calcite parsing passed, start to transform. SELECT * FROM TEXT240
[32m- 0247[0m
Calcite parsing passed, start to transform. SELECT GRADE, HOURS, BUDGET FROM STAFF, WORKS, PROJ
Calcite parsing passed, start to transform. SELECT GRADE, HOURS, BUDGET FROM STAFF, WORKS, PROJ
Calcite parsing passed, start to transform. SELECT GRADE, HOURS, BUDGET FROM STAFF, WORKS, PROJ
[31m- 0248 *** FAILED ***[0m
[31m  Results do not match for 0248:[0m
[31m  == Parsed Logical Plan ==[0m
[31m  'Project ['GRADE,'HOURS,'BUDGET][0m
[31m   'Join Inner, None[0m
[31m    'Join Inner, None[0m
[31m     'UnresolvedRelation [STAFF], None[0m
[31m     'UnresolvedRelation [WORKS], None[0m
[31m    'UnresolvedRelation [PROJ], None[0m
  
[31m  == Analyzed Logical Plan ==[0m
[31m  GRADE: double, HOURS: double, BUDGET: double[0m
[31m  Project [GRADE#40965,HOURS#40969,BUDGET#40973][0m
[31m   Join Inner, None[0m
[31m    Join Inner, None[0m
[31m     MetastoreRelation HU, staff, None[0m
[31m     MetastoreRelation HU, works, None[0m
[31m    MetastoreRelation HU, proj, None[0m
  
[31m  == Optimized Logical Plan ==[0m
[31m  Project [GRADE#40965,HOURS#40969,BUDGET#40973][0m
[31m   Join Inner, None[0m
[31m    Project [GRADE#40965,HOURS#40969][0m
[31m     Join Inner, None[0m
[31m      Project [GRADE#40965][0m
[31m       MetastoreRelation HU, staff, None[0m
[31m      Project [HOURS#40969][0m
[31m       MetastoreRelation HU, works, None[0m
[31m    Project [BUDGET#40973][0m
[31m     MetastoreRelation HU, proj, None[0m
  
[31m  == Physical Plan ==[0m
[31m  TungstenProject [GRADE#40965,HOURS#40969,BUDGET#40973][0m
[31m   CartesianProduct[0m
[31m    ConvertToSafe[0m
[31m     TungstenProject [GRADE#40965,HOURS#40969][0m
[31m      CartesianProduct[0m
[31m       HiveTableScan [GRADE#40965], (MetastoreRelation HU, staff, None)[0m
[31m       HiveTableScan [HOURS#40969], (MetastoreRelation HU, works, None)[0m
[31m    HiveTableScan [BUDGET#40973], (MetastoreRelation HU, proj, None)[0m
  
[31m  Code Generation: true[0m
[31m  GRADE	HOURS	BUDGET[0m
[31m  !== HIVE - 192 row(s) ==   == CATALYST - 192 row(s) ==[0m
[31m  !15	100	10000              15.0	100.0	10000.0[0m
[31m  !15	100	10000              15.0	100.0	10000.0[0m
[31m  !15	100	20000              15.0	100.0	20000.0[0m
[31m  !15	100	30000              15.0	100.0	30000.0[0m
[31m  !15	100	30000              15.0	100.0	30000.0[0m
[31m  !15	100	50000              15.0	100.0	50000.0[0m
[31m  !15	12	10000               15.0	12.0	10000.0[0m
[31m  !15	12	10000               15.0	12.0	10000.0[0m
[31m  !15	12	10000               15.0	12.0	10000.0[0m
[31m  !15	12	10000               15.0	12.0	10000.0[0m
[31m  !15	12	20000               15.0	12.0	20000.0[0m
[31m  !15	12	20000               15.0	12.0	20000.0[0m
[31m  !15	12	30000               15.0	12.0	30000.0[0m
[31m  !15	12	30000               15.0	12.0	30000.0[0m
[31m  !15	12	30000               15.0	12.0	30000.0[0m
[31m  !15	12	30000               15.0	12.0	30000.0[0m
[31m  !15	12	50000               15.0	12.0	50000.0[0m
[31m  !15	12	50000               15.0	12.0	50000.0[0m
[31m  !15	20	10000               15.0	20.0	10000.0[0m
[31m  !15	20	10000               15.0	20.0	10000.0[0m
[31m  !15	20	10000               15.0	20.0	10000.0[0m
[31m  !15	20	10000               15.0	20.0	10000.0[0m
[31m  !15	20	10000               15.0	20.0	10000.0[0m
[31m  !15	20	10000               15.0	20.0	10000.0[0m
[31m  !15	20	10000               15.0	20.0	10000.0[0m
[31m  !15	20	10000               15.0	20.0	10000.0[0m
[31m  !15	20	20000               15.0	20.0	20000.0[0m
[31m  !15	20	20000               15.0	20.0	20000.0[0m
[31m  !15	20	20000               15.0	20.0	20000.0[0m
[31m  !15	20	20000               15.0	20.0	20000.0[0m
[31m  !15	20	30000               15.0	20.0	30000.0[0m
[31m  !15	20	30000               15.0	20.0	30000.0[0m
[31m  !15	20	30000               15.0	20.0	30000.0[0m
[31m  !15	20	30000               15.0	20.0	30000.0[0m
[31m  !15	20	30000               15.0	20.0	30000.0[0m
[31m  !15	20	30000               15.0	20.0	30000.0[0m
[31m  !15	20	30000               15.0	20.0	30000.0[0m
[31m  !15	20	30000               15.0	20.0	30000.0[0m
[31m  !15	20	50000               15.0	20.0	50000.0[0m
[31m  !15	20	50000               15.0	20.0	50000.0[0m
[31m  !15	20	50000               15.0	20.0	50000.0[0m
[31m  !15	20	50000               15.0	20.0	50000.0[0m
[31m  !15	40	10000               15.0	40.0	10000.0[0m
[31m  !15	40	10000               15.0	40.0	10000.0[0m
[31m  !15	40	10000               15.0	40.0	10000.0[0m
[31m  !15	40	10000               15.0	40.0	10000.0[0m
[31m  !15	40	10000               15.0	40.0	10000.0[0m
[31m  !15	40	10000               15.0	40.0	10000.0[0m
[31m  !15	40	20000               15.0	40.0	20000.0[0m
[31m  !15	40	20000               15.0	40.0	20000.0[0m
[31m  !15	40	20000               15.0	40.0	20000.0[0m
[31m  !15	40	30000               15.0	40.0	30000.0[0m
[31m  !15	40	30000               15.0	40.0	30000.0[0m
[31m  !15	40	30000               15.0	40.0	30000.0[0m
[31m  !15	40	30000               15.0	40.0	30000.0[0m
[31m  !15	40	30000               15.0	40.0	30000.0[0m
[31m  !15	40	30000               15.0	40.0	30000.0[0m
[31m  !15	40	50000               15.0	40.0	50000.0[0m
[31m  !15	40	50000               15.0	40.0	50000.0[0m
[31m  !15	40	50000               15.0	40.0	50000.0[0m
[31m  !15	80	10000               15.0	80.0	10000.0[0m
[31m  !15	80	10000               15.0	80.0	10000.0[0m
[31m  !15	80	10000               15.0	80.0	10000.0[0m
[31m  !15	80	10000               15.0	80.0	10000.0[0m
[31m  !15	80	20000               15.0	80.0	20000.0[0m
[31m  !15	80	20000               15.0	80.0	20000.0[0m
[31m  !15	80	30000               15.0	80.0	30000.0[0m
[31m  !15	80	30000               15.0	80.0	30000.0[0m
[31m  !15	80	30000               15.0	80.0	30000.0[0m
[31m  !15	80	30000               15.0	80.0	30000.0[0m
[31m  !15	80	50000               15.0	80.0	50000.0[0m
[31m  !15	80	50000               15.0	80.0	50000.0[0m
[31m  !15	NULL	10000             15.0	NULL	10000.0[0m
[31m  !15	NULL	10000             15.0	NULL	10000.0[0m
[31m  !15	NULL	10000             15.0	NULL	10000.0[0m
[31m  !15	NULL	10000             15.0	NULL	10000.0[0m
[31m  !15	NULL	10000             15.0	NULL	10000.0[0m
[31m  !15	NULL	10000             15.0	NULL	10000.0[0m
[31m  !15	NULL	10000             15.0	NULL	10000.0[0m
[31m  !15	NULL	10000             15.0	NULL	10000.0[0m
[31m  !15	NULL	20000             15.0	NULL	20000.0[0m
[31m  !15	NULL	20000             15.0	NULL	20000.0[0m
[31m  !15	NULL	20000             15.0	NULL	20000.0[0m
[31m  !15	NULL	20000             15.0	NULL	20000.0[0m
[31m  !15	NULL	30000             15.0	NULL	30000.0[0m
[31m  !15	NULL	30000             15.0	NULL	30000.0[0m
[31m  !15	NULL	30000             15.0	NULL	30000.0[0m
[31m  !15	NULL	30000             15.0	NULL	30000.0[0m
[31m  !15	NULL	30000             15.0	NULL	30000.0[0m
[31m  !15	NULL	30000             15.0	NULL	30000.0[0m
[31m  !15	NULL	30000             15.0	NULL	30000.0[0m
[31m  !15	NULL	30000             15.0	NULL	30000.0[0m
[31m  !15	NULL	50000             15.0	NULL	50000.0[0m
[31m  !15	NULL	50000             15.0	NULL	50000.0[0m
[31m  !15	NULL	50000             15.0	NULL	50000.0[0m
[31m  !15	NULL	50000             15.0	NULL	50000.0[0m
[31m  !36	100	10000              36.0	100.0	10000.0[0m
[31m  !36	100	10000              36.0	100.0	10000.0[0m
[31m  !36	100	20000              36.0	100.0	20000.0[0m
[31m  !36	100	30000              36.0	100.0	30000.0[0m
[31m  !36	100	30000              36.0	100.0	30000.0[0m
[31m  !36	100	50000              36.0	100.0	50000.0[0m
[31m  !36	12	10000               36.0	12.0	10000.0[0m
[31m  !36	12	10000               36.0	12.0	10000.0[0m
[31m  !36	12	10000               36.0	12.0	10000.0[0m
[31m  !36	12	10000               36.0	12.0	10000.0[0m
[31m  !36	12	20000               36.0	12.0	20000.0[0m
[31m  !36	12	20000               36.0	12.0	20000.0[0m
[31m  !36	12	30000               36.0	12.0	30000.0[0m
[31m  !36	12	30000               36.0	12.0	30000.0[0m
[31m  !36	12	30000               36.0	12.0	30000.0[0m
[31m  !36	12	30000               36.0	12.0	30000.0[0m
[31m  !36	12	50000               36.0	12.0	50000.0[0m
[31m  !36	12	50000               36.0	12.0	50000.0[0m
[31m  !36	20	10000               36.0	20.0	10000.0[0m
[31m  !36	20	10000               36.0	20.0	10000.0[0m
[31m  !36	20	10000               36.0	20.0	10000.0[0m
[31m  !36	20	10000               36.0	20.0	10000.0[0m
[31m  !36	20	10000               36.0	20.0	10000.0[0m
[31m  !36	20	10000               36.0	20.0	10000.0[0m
[31m  !36	20	10000               36.0	20.0	10000.0[0m
[31m  !36	20	10000               36.0	20.0	10000.0[0m
[31m  !36	20	20000               36.0	20.0	20000.0[0m
[31m  !36	20	20000               36.0	20.0	20000.0[0m
[31m  !36	20	20000               36.0	20.0	20000.0[0m
[31m  !36	20	20000               36.0	20.0	20000.0[0m
[31m  !36	20	30000               36.0	20.0	30000.0[0m
[31m  !36	20	30000               36.0	20.0	30000.0[0m
[31m  !36	20	30000               36.0	20.0	30000.0[0m
[31m  !36	20	30000               36.0	20.0	30000.0[0m
[31m  !36	20	30000               36.0	20.0	30000.0[0m
[31m  !36	20	30000               36.0	20.0	30000.0[0m
[31m  !36	20	30000               36.0	20.0	30000.0[0m
[31m  !36	20	30000               36.0	20.0	30000.0[0m
[31m  !36	20	50000               36.0	20.0	50000.0[0m
[31m  !36	20	50000               36.0	20.0	50000.0[0m
[31m  !36	20	50000               36.0	20.0	50000.0[0m
[31m  !36	20	50000               36.0	20.0	50000.0[0m
[31m  !36	40	10000               36.0	40.0	10000.0[0m
[31m  !36	40	10000               36.0	40.0	10000.0[0m
[31m  !36	40	10000               36.0	40.0	10000.0[0m
[31m  !36	40	10000               36.0	40.0	10000.0[0m
[31m  !36	40	10000               36.0	40.0	10000.0[0m
[31m  !36	40	10000               36.0	40.0	10000.0[0m
[31m  !36	40	20000               36.0	40.0	20000.0[0m
[31m  !36	40	20000               36.0	40.0	20000.0[0m
[31m  !36	40	20000               36.0	40.0	20000.0[0m
[31m  !36	40	30000               36.0	40.0	30000.0[0m
[31m  !36	40	30000               36.0	40.0	30000.0[0m
[31m  !36	40	30000               36.0	40.0	30000.0[0m
[31m  !36	40	30000               36.0	40.0	30000.0[0m
[31m  !36	40	30000               36.0	40.0	30000.0[0m
[31m  !36	40	30000               36.0	40.0	30000.0[0m
[31m  !36	40	50000               36.0	40.0	50000.0[0m
[31m  !36	40	50000               36.0	40.0	50000.0[0m
[31m  !36	40	50000               36.0	40.0	50000.0[0m
[31m  !36	80	10000               36.0	80.0	10000.0[0m
[31m  !36	80	10000               36.0	80.0	10000.0[0m
[31m  !36	80	10000               36.0	80.0	10000.0[0m
[31m  !36	80	10000               36.0	80.0	10000.0[0m
[31m  !36	80	20000               36.0	80.0	20000.0[0m
[31m  !36	80	20000               36.0	80.0	20000.0[0m
[31m  !36	80	30000               36.0	80.0	30000.0[0m
[31m  !36	80	30000               36.0	80.0	30000.0[0m
[31m  !36	80	30000               36.0	80.0	30000.0[0m
[31m  !36	80	30000               36.0	80.0	30000.0[0m
[31m  !36	80	50000               36.0	80.0	50000.0[0m
[31m  !36	80	50000               36.0	80.0	50000.0[0m
[31m  !36	NULL	10000             36.0	NULL	10000.0[0m
[31m  !36	NULL	10000             36.0	NULL	10000.0[0m
[31m  !36	NULL	10000             36.0	NULL	10000.0[0m
[31m  !36	NULL	10000             36.0	NULL	10000.0[0m
[31m  !36	NULL	10000             36.0	NULL	10000.0[0m
[31m  !36	NULL	10000             36.0	NULL	10000.0[0m
[31m  !36	NULL	10000             36.0	NULL	10000.0[0m
[31m  !36	NULL	10000             36.0	NULL	10000.0[0m
[31m  !36	NULL	20000             36.0	NULL	20000.0[0m
[31m  !36	NULL	20000             36.0	NULL	20000.0[0m
[31m  !36	NULL	20000             36.0	NULL	20000.0[0m
[31m  !36	NULL	20000             36.0	NULL	20000.0[0m
[31m  !36	NULL	30000             36.0	NULL	30000.0[0m
[31m  !36	NULL	30000             36.0	NULL	30000.0[0m
[31m  !36	NULL	30000             36.0	NULL	30000.0[0m
[31m  !36	NULL	30000             36.0	NULL	30000.0[0m
[31m  !36	NULL	30000             36.0	NULL	30000.0[0m
[31m  !36	NULL	30000             36.0	NULL	30000.0[0m
[31m  !36	NULL	30000             36.0	NULL	30000.0[0m
[31m  !36	NULL	30000             36.0	NULL	30000.0[0m
[31m  !36	NULL	50000             36.0	NULL	50000.0[0m
[31m  !36	NULL	50000             36.0	NULL	50000.0[0m
[31m  !36	NULL	50000             36.0	NULL	50000.0[0m
[31m  !36	NULL	50000             36.0	NULL	50000.0 (HiveComparisonTest.scala:433)[0m
Calcite parsing passed, start to transform. SELECT CITY FROM STAFF WHERE EMPNAME LIKE 'yan____%'
[32m- 0249[0m
Calcite parsing passed, start to transform. SELECT CITY FROM STAFF WHERE EMPNAME LIKE 'YAN____%'
[32m- 0250[0m
Calcite parsing passed, start to transform. SELECT COL1, EMPNUM, GRADE FROM CUGINI.VTABLE, STAFF WHERE COL1 < 200 AND GRADE > 12
Calcite parsing passed, start to transform. SELECT COL1, EMPNUM, GRADE FROM CUGINI.VTABLE, STAFF WHERE COL1 < 200 AND GRADE > 12
Calcite parsing passed, start to transform. SELECT COL1, EMPNUM, GRADE FROM CUGINI.VTABLE, STAFF WHERE COL1 < 200 AND GRADE > 12
[31m- 0251 *** FAILED ***[0m
[31m  Results do not match for 0251:[0m
[31m  == Parsed Logical Plan ==[0m
[31m  'Project ['COL1,'EMPNUM,'GRADE][0m
[31m   'Filter (('COL1 < 200) && ('GRADE > 12))[0m
[31m    'Join Inner, None[0m
[31m     'UnresolvedRelation [CUGINI,VTABLE], None[0m
[31m     'UnresolvedRelation [STAFF], None[0m
  
[31m  == Analyzed Logical Plan ==[0m
[31m  COL1: double, EMPNUM: string, GRADE: double[0m
[31m  Project [COL1#42049,EMPNUM#42054,GRADE#42056][0m
[31m   Filter ((COL1#42049 < cast(200 as double)) && (GRADE#42056 > cast(12 as double)))[0m
[31m    Join Inner, None[0m
[31m     MetastoreRelation cugini, vtable, None[0m
[31m     MetastoreRelation HU, staff, None[0m
  
[31m  == Optimized Logical Plan ==[0m
[31m  Project [COL1#42049,EMPNUM#42054,GRADE#42056][0m
[31m   Join Inner, None[0m
[31m    Project [COL1#42049][0m
[31m     Filter (COL1#42049 < 200.0)[0m
[31m      MetastoreRelation cugini, vtable, None[0m
[31m    Project [EMPNUM#42054,GRADE#42056][0m
[31m     Filter (GRADE#42056 > 12.0)[0m
[31m      MetastoreRelation HU, staff, None[0m
  
[31m  == Physical Plan ==[0m
[31m  TungstenProject [COL1#42049,EMPNUM#42054,GRADE#42056][0m
[31m   CartesianProduct[0m
[31m    Filter (COL1#42049 < 200.0)[0m
[31m     HiveTableScan [COL1#42049], (MetastoreRelation cugini, vtable, None)[0m
[31m    Filter (GRADE#42056 > 12.0)[0m
[31m     HiveTableScan [EMPNUM#42054,GRADE#42056], (MetastoreRelation HU, staff, None)[0m
  
[31m  Code Generation: true[0m
[31m  COL1	EMPNUM	GRADE[0m
[31m  !== HIVE - 12 row(s) ==   == CATALYST - 12 row(s) ==[0m
[31m  !0	E36	36                 0.0	E36	36.0[0m
[31m  !0	E36	36                 0.0	E36	36.0[0m
[31m  !0	E7	26                  0.0	E7	26.0[0m
[31m  !0	E7	26                  0.0	E7	26.0[0m
[31m  !0	E8	15                  0.0	E8	15.0[0m
[31m  !0	E8	15                  0.0	E8	15.0[0m
[31m  !10	E36	36                10.0	E36	36.0[0m
[31m  !10	E7	26                 10.0	E7	26.0[0m
[31m  !10	E8	15                 10.0	E8	15.0[0m
[31m  !100	E36	36               100.0	E36	36.0[0m
[31m  !100	E7	26                100.0	E7	26.0[0m
[31m  !100	E8	15                100.0	E8	15.0 (HiveComparisonTest.scala:433)[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM WORKS WHERE EMPNUM = 'E9'
[32m- 0252[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM WORKS WHERE HOURS > 85
[32m- 0253[0m
Calcite parsing passed, start to transform. SELECT PNUM FROM   PROJ WHERE  PNAME BETWEEN 'A' AND 'F'
[32m- 0254[0m
Calcite parsing passed, start to transform. SELECT PNUM FROM   PROJ WHERE PNAME >= 'A' AND PNAME <= 'F'
[32m- 0255[0m
Calcite parsing passed, start to transform. SELECT CITY FROM   STAFF WHERE  EMPNAME NOT BETWEEN 'A' AND 'E'
[32m- 0256[0m
Calcite parsing passed, start to transform. SELECT CITY FROM   STAFF WHERE  NOT( EMPNAME BETWEEN 'A' AND 'E' )
[32m- 0257[0m
Calcite parsing passed, start to transform. SELECT EMPNAME FROM   STAFF WHERE  EMPNAME LIKE 'Ali%'
[32m- 0258[0m
Calcite parsing passed, start to transform. SELECT EMPNAME FROM   STAFF WHERE  EMPNAME LIKE 'ALI%'
[32m- 0259[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM TEMP_S WHERE EMPNUM='E1' AND GRADE=11 AND CITY='Deale'
[32m- 0260[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM STAFF1
[32m- 0261[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM STAFF1 WHERE GRADE > 12
[32m- 0262[0m
Calcite parsing passed, start to transform. SELECT SUM(GRADE) FROM STAFF1
Calcite parsing passed, start to transform. SELECT SUM(GRADE) FROM STAFF1
Calcite parsing passed, start to transform. SELECT SUM(GRADE) FROM STAFF1
[31m- 0263 *** FAILED ***[0m
[31m  Results do not match for 0263:[0m
[31m  == Parsed Logical Plan ==[0m
[31m  'Project ['SUM('GRADE) AS c0#44170][0m
[31m   'UnresolvedRelation [STAFF1], None[0m
  
[31m  == Analyzed Logical Plan ==[0m
[31m  c0: double[0m
[31m  Aggregate [sum(GRADE#44173) AS c0#44170][0m
[31m   MetastoreRelation HU, staff1, None[0m
  
[31m  == Optimized Logical Plan ==[0m
[31m  Aggregate [sum(GRADE#44173) AS c0#44170][0m
[31m   Project [GRADE#44173][0m
[31m    MetastoreRelation HU, staff1, None[0m
  
[31m  == Physical Plan ==[0m
[31m  TungstenAggregate(key=[], functions=[(sum(GRADE#44173),mode=Final,isDistinct=false)], output=[c0#44170])[0m
[31m   TungstenExchange SinglePartition[0m
[31m    TungstenAggregate(key=[], functions=[(sum(GRADE#44173),mode=Partial,isDistinct=false)], output=[currentSum#44177])[0m
[31m     HiveTableScan [GRADE#44173], (MetastoreRelation HU, staff1, None)[0m
  
[31m  Code Generation: true[0m
[31m  c0[0m
[31m  !== HIVE - 1 row(s) ==   == CATALYST - 1 row(s) ==[0m
[31m  !138                     138.0 (HiveComparisonTest.scala:433)[0m
Calcite parsing passed, start to transform. SELECT NUMKEY FROM UPUNIQ ORDER BY NUMKEY DESC
Calcite parsing passed, start to transform. SELECT NUMKEY FROM UPUNIQ ORDER BY NUMKEY DESC
Calcite parsing passed, start to transform. SELECT NUMKEY FROM UPUNIQ ORDER BY NUMKEY DESC
[31m- 0264 *** FAILED ***[0m
[31m  Results do not match for 0264:[0m
[31m  == Parsed Logical Plan ==[0m
[31m  'Sort ['NUMKEY DESC], true[0m
[31m   'Project ['NUMKEY][0m
[31m    'UnresolvedRelation [UPUNIQ], None[0m
  
[31m  == Analyzed Logical Plan ==[0m
[31m  NUMKEY: double[0m
[31m  Sort [NUMKEY#44372 DESC], true[0m
[31m   Project [NUMKEY#44372][0m
[31m    MetastoreRelation HU, upuniq, None[0m
  
[31m  == Optimized Logical Plan ==[0m
[31m  Sort [NUMKEY#44372 DESC], true[0m
[31m   Project [NUMKEY#44372][0m
[31m    MetastoreRelation HU, upuniq, None[0m
  
[31m  == Physical Plan ==[0m
[31m  TungstenSort [NUMKEY#44372 DESC], true, 0[0m
[31m   ConvertToUnsafe[0m
[31m    Exchange rangepartitioning(NUMKEY#44372 DESC)[0m
[31m     HiveTableScan [NUMKEY#44372], (MetastoreRelation HU, upuniq, None)[0m
  
[31m  Code Generation: true[0m
[31m  NUMKEY[0m
[31m  !== HIVE - 6 row(s) ==   == CATALYST - 6 row(s) ==[0m
[31m  !10                      10.0[0m
[31m  !8                       8.0[0m
[31m  !6                       6.0[0m
[31m  !5                       5.0[0m
[31m  !3                       3.0[0m
[31m  !2                       2.0 (HiveComparisonTest.scala:433)[0m
Calcite parsing passed, start to transform. SELECT MAX(NUMKEY), MIN(NUMKEY) FROM UPUNIQ
Calcite parsing passed, start to transform. SELECT MAX(NUMKEY), MIN(NUMKEY) FROM UPUNIQ
Calcite parsing passed, start to transform. SELECT MAX(NUMKEY), MIN(NUMKEY) FROM UPUNIQ
[31m- 0265 *** FAILED ***[0m
[31m  Results do not match for 0265:[0m
[31m  == Parsed Logical Plan ==[0m
[31m  'Project ['MAX('NUMKEY) AS c0#44553,'MIN('NUMKEY) AS c1#44554][0m
[31m   'UnresolvedRelation [UPUNIQ], None[0m
  
[31m  == Analyzed Logical Plan ==[0m
[31m  c0: double, c1: double[0m
[31m  Aggregate [max(NUMKEY#44555) AS c0#44553,min(NUMKEY#44555) AS c1#44554][0m
[31m   MetastoreRelation HU, upuniq, None[0m
  
[31m  == Optimized Logical Plan ==[0m
[31m  Aggregate [max(NUMKEY#44555) AS c0#44553,min(NUMKEY#44555) AS c1#44554][0m
[31m   Project [NUMKEY#44555][0m
[31m    MetastoreRelation HU, upuniq, None[0m
  
[31m  == Physical Plan ==[0m
[31m  TungstenAggregate(key=[], functions=[(max(NUMKEY#44555),mode=Final,isDistinct=false),(min(NUMKEY#44555),mode=Final,isDistinct=false)], output=[c0#44553,c1#44554])[0m
[31m   TungstenExchange SinglePartition[0m
[31m    TungstenAggregate(key=[], functions=[(max(NUMKEY#44555),mode=Partial,isDistinct=false),(min(NUMKEY#44555),mode=Partial,isDistinct=false)], output=[max#44560,min#44562])[0m
[31m     HiveTableScan [NUMKEY#44555], (MetastoreRelation HU, upuniq, None)[0m
  
[31m  Code Generation: true[0m
[31m  c0	c1[0m
[31m  !== HIVE - 1 row(s) ==   == CATALYST - 1 row(s) ==[0m
[31m  !10	3                    10.0	3.0 (HiveComparisonTest.scala:433)[0m
Calcite parsing passed, start to transform. SELECT CITY FROM PROJ1 WHERE PNUM = 'P1'
[32m- 0266[0m
Calcite parsing passed, start to transform. SELECT STR110 FROM T4 WHERE NUM6 = 100
[32m- 0267[0m
Calcite parsing passed, start to transform. SELECT STR110 FROM T4 WHERE NUM6 = 101
[32m- 0268[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM T4 WHERE STR110 LIKE '%HU%'
[32m- 0270[0m
Calcite parsing passed, start to transform. SELECT COL1, MAX(COL2 + COL3), MIN(COL3 - COL2) FROM VTABLE GROUP BY COL1 ORDER BY COL1
Calcite parsing passed, start to transform. SELECT COL1, MAX(COL2 + COL3), MIN(COL3 - COL2) FROM VTABLE GROUP BY COL1 ORDER BY COL1
Calcite parsing passed, start to transform. SELECT COL1, MAX(COL2 + COL3), MIN(COL3 - COL2) FROM VTABLE GROUP BY COL1 ORDER BY COL1
[31m- 0271 *** FAILED ***[0m
[31m  Results do not match for 0271:[0m
[31m  == Parsed Logical Plan ==[0m
[31m  'Sort ['COL1 ASC], true[0m
[31m   'Aggregate ['COL1], ['COL1,'MAX(('COL2 + 'COL3)) AS c1#45126,'MIN(('COL3 - 'COL2)) AS c2#45127][0m
[31m    'UnresolvedRelation [VTABLE], None[0m
  
[31m  == Analyzed Logical Plan ==[0m
[31m  COL1: double, c1: double, c2: double[0m
[31m  Sort [COL1#45128 ASC], true[0m
[31m   Aggregate [COL1#45128], [COL1#45128,max((COL2#45129 + COL3#45130)) AS c1#45126,min((COL3#45130 - COL2#45129)) AS c2#45127][0m
[31m    MetastoreRelation HU, vtable, None[0m
  
[31m  == Optimized Logical Plan ==[0m
[31m  Sort [COL1#45128 ASC], true[0m
[31m   Aggregate [COL1#45128], [COL1#45128,max((COL2#45129 + COL3#45130)) AS c1#45126,min((COL3#45130 - COL2#45129)) AS c2#45127][0m
[31m    Project [COL1#45128,COL2#45129,COL3#45130][0m
[31m     MetastoreRelation HU, vtable, None[0m
  
[31m  == Physical Plan ==[0m
[31m  TungstenSort [COL1#45128 ASC], true, 0[0m
[31m   ConvertToUnsafe[0m
[31m    Exchange rangepartitioning(COL1#45128 ASC)[0m
[31m     ConvertToSafe[0m
[31m      TungstenAggregate(key=[COL1#45128], functions=[(max((COL2#45129 + COL3#45130)),mode=Final,isDistinct=false),(min((COL3#45130 - COL2#45129)),mode=Final,isDistinct=false)], output=[COL1#45128,c1#45126,c2#45127])[0m
[31m       TungstenExchange hashpartitioning(COL1#45128)[0m
[31m        TungstenAggregate(key=[COL1#45128], functions=[(max((COL2#45129 + COL3#45130)),mode=Partial,isDistinct=false),(min((COL3#45130 - COL2#45129)),mode=Partial,isDistinct=false)], output=[COL1#45128,max#45137,min#45139])[0m
[31m         HiveTableScan [COL1#45128,COL2#45129,COL3#45130], (MetastoreRelation HU, vtable, None)[0m
  
[31m  Code Generation: true[0m
[31m  COL1	c1	c2[0m
[31m  !== HIVE - 4 row(s) ==   == CATALYST - 4 row(s) ==[0m
[31m  !0	3	1                   0.0	3.0	1.0[0m
[31m  !10	50	1                 10.0	50.0	1.0[0m
[31m  !100	1223	100            100.0	1223.0	100.0[0m
[31m  !1000	1000	5000          1000.0	1000.0	5000.0 (HiveComparisonTest.scala:433)[0m
Calcite parsing passed, start to transform. SELECT COL1,SUM(2 * COL2 * COL3) FROM VTABLE GROUP BY COL1 HAVING SUM(COL2 * COL3) > 2000 OR SUM(COL2 * COL3) < -2000 ORDER BY COL1
Calcite parsing passed, start to transform. SELECT COL1,SUM(2 * COL2 * COL3) FROM VTABLE GROUP BY COL1 HAVING SUM(COL2 * COL3) > 2000 OR SUM(COL2 * COL3) < -2000 ORDER BY COL1
Calcite parsing passed, start to transform. SELECT COL1,SUM(2 * COL2 * COL3) FROM VTABLE GROUP BY COL1 HAVING SUM(COL2 * COL3) > 2000 OR SUM(COL2 * COL3) < -2000 ORDER BY COL1
[31m- 0272 *** FAILED ***[0m
[31m  Results do not match for 0272:[0m
[31m  == Parsed Logical Plan ==[0m
[31m  'Sort ['COL1 ASC], true[0m
[31m   'Filter (('SUM(('COL2 * 'COL3)) > 2000) || ('SUM(('COL2 * 'COL3)) < -2000))[0m
[31m    'Aggregate ['COL1], ['COL1,'SUM(((2 * 'COL2) * 'COL3)) AS c1#45349][0m
[31m     'UnresolvedRelation [VTABLE], None[0m
  
[31m  == Analyzed Logical Plan ==[0m
[31m  COL1: double, c1: double[0m
[31m  Sort [COL1#45350 ASC], true[0m
[31m   Project [COL1#45350,c1#45349][0m
[31m    Filter havingCondition#45355[0m
[31m     Aggregate [COL1#45350], [((sum((COL2#45351 * COL3#45352)) > cast(2000 as double)) || (sum((COL2#45351 * COL3#45352)) < cast(-2000 as double))) AS havingCondition#45355,COL1#45350,sum(((cast(2 as double) * COL2#45351) * COL3#45352)) AS c1#45349][0m
[31m      MetastoreRelation HU, vtable, None[0m
  
[31m  == Optimized Logical Plan ==[0m
[31m  Sort [COL1#45350 ASC], true[0m
[31m   Project [COL1#45350,c1#45349][0m
[31m    Filter havingCondition#45355[0m
[31m     Aggregate [COL1#45350], [((sum((COL2#45351 * COL3#45352)) > 2000.0) || (sum((COL2#45351 * COL3#45352)) < -2000.0)) AS havingCondition#45355,COL1#45350,sum(((2.0 * COL2#45351) * COL3#45352)) AS c1#45349][0m
[31m      Project [COL1#45350,COL2#45351,COL3#45352][0m
[31m       MetastoreRelation HU, vtable, None[0m
  
[31m  == Physical Plan ==[0m
[31m  TungstenSort [COL1#45350 ASC], true, 0[0m
[31m   ConvertToUnsafe[0m
[31m    Exchange rangepartitioning(COL1#45350 ASC)[0m
[31m     ConvertToSafe[0m
[31m      TungstenProject [COL1#45350,c1#45349][0m
[31m       Filter havingCondition#45355[0m
[31m        TungstenAggregate(key=[COL1#45350], functions=[(sum((COL2#45351 * COL3#45352)),mode=Final,isDistinct=false),(sum(((2.0 * COL2#45351) * COL3#45352)),mode=Final,isDistinct=false)], output=[havingCondition#45355,COL1#45350,c1#45349])[0m
[31m         TungstenExchange hashpartitioning(COL1#45350)[0m
[31m          TungstenAggregate(key=[COL1#45350], functions=[(sum((COL2#45351 * COL3#45352)),mode=Partial,isDistinct=false),(sum(((2.0 * COL2#45351) * COL3#45352)),mode=Partial,isDistinct=false)], output=[COL1#45350,currentSum#45360,currentSum#45364])[0m
[31m           HiveTableScan [COL1#45350,COL2#45351,COL3#45352], (MetastoreRelation HU, vtable, None)[0m
  
[31m  Code Generation: true[0m
[31m  COL1	c1[0m
[31m  !== HIVE - 2 row(s) ==   == CATALYST - 2 row(s) ==[0m
[31m  !100	613728              100.0	613728.0[0m
[31m  !1000	-12000000          1000.0	-1.2E7 (HiveComparisonTest.scala:433)[0m
NoViableAltException(231@[])
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.function(HiveParser_IdentifiersParser.java:3544)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.atomExpression(HiveParser_IdentifiersParser.java:6280)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceFieldExpression(HiveParser_IdentifiersParser.java:6383)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceUnaryPrefixExpression(HiveParser_IdentifiersParser.java:6768)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceUnarySuffixExpression(HiveParser_IdentifiersParser.java:6828)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceBitwiseXorExpression(HiveParser_IdentifiersParser.java:7012)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceStarExpression(HiveParser_IdentifiersParser.java:7172)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedencePlusExpression(HiveParser_IdentifiersParser.java:7332)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceAmpersandExpression(HiveParser_IdentifiersParser.java:7483)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceBitwiseOrExpression(HiveParser_IdentifiersParser.java:7634)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceEqualExpression(HiveParser_IdentifiersParser.java:8290)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceNotExpression(HiveParser_IdentifiersParser.java:9177)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceAndExpression(HiveParser_IdentifiersParser.java:9296)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceOrExpression(HiveParser_IdentifiersParser.java:9455)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.expression(HiveParser_IdentifiersParser.java:6105)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.havingCondition(HiveParser_IdentifiersParser.java:1840)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.havingClause(HiveParser_IdentifiersParser.java:1748)
	at org.apache.hadoop.hive.ql.parse.HiveParser.havingClause(HiveParser.java:45863)
	at org.apache.hadoop.hive.ql.parse.HiveParser.selectStatement(HiveParser.java:41597)
	at org.apache.hadoop.hive.ql.parse.HiveParser.regularBody(HiveParser.java:41402)
	at org.apache.hadoop.hive.ql.parse.HiveParser.queryStatementExpressionBody(HiveParser.java:40413)
	at org.apache.hadoop.hive.ql.parse.HiveParser.queryStatementExpression(HiveParser.java:40283)
	at org.apache.hadoop.hive.ql.parse.HiveParser.execStatement(HiveParser.java:1590)
	at org.apache.hadoop.hive.ql.parse.HiveParser.statement(HiveParser.java:1109)
	at org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:202)
	at org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:166)
	at org.apache.spark.sql.hive.HiveQl$.getAst(HiveQl.scala:258)
	at org.apache.spark.sql.hive.HiveQl$.createPlan(HiveQl.scala:283)
	at org.apache.spark.sql.hive.ExtendedHiveQlParser$$anonfun$hiveQl$1.apply(ExtendedHiveQlParser.scala:41)
	at org.apache.spark.sql.hive.ExtendedHiveQlParser$$anonfun$hiveQl$1.apply(ExtendedHiveQlParser.scala:40)
	at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)
	at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:135)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)
	at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Failure.append(Parsers.scala:202)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)
	at scala.util.parsing.combinator.Parsers$$anon$2$$anonfun$apply$14.apply(Parsers.scala:891)
	at scala.util.parsing.combinator.Parsers$$anon$2$$anonfun$apply$14.apply(Parsers.scala:891)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)
	at scala.util.parsing.combinator.Parsers$$anon$2.apply(Parsers.scala:890)
	at scala.util.parsing.combinator.PackratParsers$$anon$1.apply(PackratParsers.scala:110)
	at org.apache.spark.sql.catalyst.AbstractSparkSQLParser.parse(AbstractSparkSQLParser.scala:34)
	at org.apache.spark.sql.hive.HiveQl$.parseSql(HiveQl.scala:276)
	at org.apache.spark.sql.hive.HiveQLDialect.parse(HiveContext.scala:62)
	at com.intel.ssg.bdt.spark.sql.CalciteDialect.getLogicalPlan(CalciteDialect.scala:54)
	at com.intel.ssg.bdt.spark.sql.CalciteDialect.parse(CalciteDialect.scala:31)
	at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)
	at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)
	at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:115)
	at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:114)
	at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)
	at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:135)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)
	at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Failure.append(Parsers.scala:202)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)
	at scala.util.parsing.combinator.Parsers$$anon$2$$anonfun$apply$14.apply(Parsers.scala:891)
	at scala.util.parsing.combinator.Parsers$$anon$2$$anonfun$apply$14.apply(Parsers.scala:891)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)
	at scala.util.parsing.combinator.Parsers$$anon$2.apply(Parsers.scala:890)
	at scala.util.parsing.combinator.PackratParsers$$anon$1.apply(PackratParsers.scala:110)
	at org.apache.spark.sql.catalyst.AbstractSparkSQLParser.parse(AbstractSparkSQLParser.scala:34)
	at org.apache.spark.sql.SQLContext$$anonfun$2.apply(SQLContext.scala:166)
	at org.apache.spark.sql.SQLContext$$anonfun$2.apply(SQLContext.scala:166)
	at org.apache.spark.sql.execution.datasources.DDLParser.parse(DDLParser.scala:42)
	at org.apache.spark.sql.SQLContext.parseSql(SQLContext.scala:189)
	at org.apache.spark.sql.hive.HiveContext.parseSql(HiveContext.scala:280)
	at org.apache.spark.sql.hive.test.TestHiveContext$QueryExecution.<init>(TestHive.scala:179)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1$$anonfun$30.apply(HiveComparisonTest.scala:303)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1$$anonfun$30.apply(HiveComparisonTest.scala:303)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:34)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:244)
	at scala.collection.AbstractTraversable.map(Traversable.scala:105)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1.apply$mcV$sp(HiveComparisonTest.scala:303)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1.apply(HiveComparisonTest.scala:240)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1.apply(HiveComparisonTest.scala:240)
	at org.scalatest.Transformer$$anonfun$apply$1.apply$mcV$sp(Transformer.scala:22)
	at org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)
	at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
	at org.scalatest.Transformer.apply(Transformer.scala:22)
	at org.scalatest.Transformer.apply(Transformer.scala:20)
	at org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:166)
	at org.apache.spark.SparkFunSuite.withFixture(SparkFunSuite.scala:42)
	at org.scalatest.FunSuiteLike$class.invokeWithFixture$1(FunSuiteLike.scala:163)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)
	at org.scalatest.FunSuiteLike$class.runTest(FunSuiteLike.scala:175)
	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.org$scalatest$BeforeAndAfter$$super$runTest(HiveCompatibilitySuite.scala:32)
	at org.scalatest.BeforeAndAfter$class.runTest(BeforeAndAfter.scala:200)
	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.runTest(HiveCompatibilitySuite.scala:32)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:413)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:401)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)
	at org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:396)
	at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:483)
	at org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:208)
	at org.scalatest.FunSuite.runTests(FunSuite.scala:1555)
	at org.scalatest.Suite$class.run(Suite.scala:1424)
	at org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.SuperEngine.runImpl(Engine.scala:545)
	at org.scalatest.FunSuiteLike$class.run(FunSuiteLike.scala:212)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest.org$scalatest$BeforeAndAfterAll$$super$run(HiveComparisonTest.scala:44)
	at org.scalatest.BeforeAndAfterAll$class.liftedTree1$1(BeforeAndAfterAll.scala:257)
	at org.scalatest.BeforeAndAfterAll$class.run(BeforeAndAfterAll.scala:256)
	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.org$scalatest$BeforeAndAfter$$super$run(HiveCompatibilitySuite.scala:32)
	at org.scalatest.BeforeAndAfter$class.run(BeforeAndAfter.scala:241)
	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.run(HiveCompatibilitySuite.scala:32)
	at org.scalatest.Suite$class.callExecuteOnSuite$1(Suite.scala:1492)
	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1528)
	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1526)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.scalatest.Suite$class.runNestedSuites(Suite.scala:1526)
	at org.scalatest.tools.DiscoverySuite.runNestedSuites(DiscoverySuite.scala:29)
	at org.scalatest.Suite$class.run(Suite.scala:1421)
	at org.scalatest.tools.DiscoverySuite.run(DiscoverySuite.scala:29)
	at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:55)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2563)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2557)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:2557)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1044)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1043)
	at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:2722)
	at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1043)
	at org.scalatest.tools.Runner$.main(Runner.scala:860)
	at org.scalatest.tools.Runner.main(Runner.scala)
[31m- 0273 *** FAILED ***[0m
[31m  org.apache.spark.sql.AnalysisException: cannot recognize input near 'SELECT' 'GRADE' 'FROM' in function specification; line 1 pos 73[0m
[31m  at org.apache.spark.sql.hive.HiveQl$.createPlan(HiveQl.scala:296)[0m
[31m  at org.apache.spark.sql.hive.ExtendedHiveQlParser$$anonfun$hiveQl$1.apply(ExtendedHiveQlParser.scala:41)[0m
[31m  at org.apache.spark.sql.hive.ExtendedHiveQlParser$$anonfun$hiveQl$1.apply(ExtendedHiveQlParser.scala:40)[0m
[31m  at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)[0m
[31m  at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:135)[0m
[31m  at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)[0m
[31m  at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)[0m
[31m  at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)[0m
[31m  at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)[0m
[31m  at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)[0m
[31m  ...[0m
Calcite parsing passed, start to transform. SELECT COL1, MAX(COL2) FROM VTABLE GROUP BY COL1 HAVING EXISTS (SELECT * FROM STAFF WHERE EMPNUM = 'E1') AND MAX(COL2) BETWEEN 10 AND 90 ORDER BY COL1
error SELECT COL1, MAX(COL2) FROM VTABLE GROUP BY COL1 HAVING EXISTS (SELECT * FROM STAFF WHERE EMPNUM = 'E1') AND MAX(COL2) BETWEEN 10 AND 90 ORDER BY COL1[31m- 0274 ***  ***[0m
[31m  java.lang.RuntimeException: Parse failed.[0m
[31m  at scala.sys.package$.error(package.scala:27)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect$$anonfun$parse$1.apply(CalciteDialect.scala:33)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect$$anonfun$parse$1.apply(CalciteDialect.scala:32)[0m
[31m  at scala.Option.getOrElse(Option.scala:120)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect.parse(CalciteDialect.scala:31)[0m
[31m  at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)[0m
[31m  at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)[0m
[31m  at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:115)[0m
[31m  at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:114)[0m
[31m  at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)[0m
[31m  ...[0m
Calcite parsing passed, start to transform. SELECT SUM(COL1) FROM VTABLE WHERE 10 + COL1 > COL2 HAVING MAX(COL1) > 100
Calcite parsing passed, start to transform. SELECT SUM(COL1) FROM VTABLE WHERE 10 + COL1 > COL2 HAVING MAX(COL1) > 100
Calcite parsing passed, start to transform. SELECT SUM(COL1) FROM VTABLE WHERE 10 + COL1 > COL2 HAVING MAX(COL1) > 100
[31m- 0275 *** FAILED ***[0m
[31m  Results do not match for 0275:[0m
[31m  == Parsed Logical Plan ==[0m
[31m  'Filter ('MAX('COL1) > 100)[0m
[31m   'Project ['SUM('COL1) AS c0#46967][0m
[31m    'Filter ((10 + 'COL1) > 'COL2)[0m
[31m     'UnresolvedRelation [VTABLE], None[0m
  
[31m  == Analyzed Logical Plan ==[0m
[31m  c0: double[0m
[31m  Project [c0#46967][0m
[31m   Filter havingCondition#46973[0m
[31m    Aggregate [(max(COL1#46968) > cast(100 as double)) AS havingCondition#46973,sum(COL1#46968) AS c0#46967][0m
[31m     Filter ((cast(10 as double) + COL1#46968) > COL2#46969)[0m
[31m      MetastoreRelation HU, vtable, None[0m
  
[31m  == Optimized Logical Plan ==[0m
[31m  Project [c0#46967][0m
[31m   Filter havingCondition#46973[0m
[31m    Aggregate [(max(COL1#46968) > 100.0) AS havingCondition#46973,sum(COL1#46968) AS c0#46967][0m
[31m     Project [COL1#46968][0m
[31m      Filter ((10.0 + COL1#46968) > COL2#46969)[0m
[31m       MetastoreRelation HU, vtable, None[0m
  
[31m  == Physical Plan ==[0m
[31m  TungstenProject [c0#46967][0m
[31m   Filter havingCondition#46973[0m
[31m    TungstenAggregate(key=[], functions=[(max(COL1#46968),mode=Final,isDistinct=false),(sum(COL1#46968),mode=Final,isDistinct=false)], output=[havingCondition#46973,c0#46967])[0m
[31m     TungstenExchange SinglePartition[0m
[31m      TungstenAggregate(key=[], functions=[(max(COL1#46968),mode=Partial,isDistinct=false),(sum(COL1#46968),mode=Partial,isDistinct=false)], output=[max#46977,currentSum#46979])[0m
[31m       Project [COL1#46968][0m
[31m        Filter ((10.0 + COL1#46968) > COL2#46969)[0m
[31m         HiveTableScan [COL1#46968,COL2#46969], (MetastoreRelation HU, vtable, None)[0m
  
[31m  Code Generation: true[0m
[31m  c0[0m
[31m  !== HIVE - 1 row(s) ==   == CATALYST - 1 row(s) ==[0m
[31m  !1040                    1040.0 (HiveComparisonTest.scala:433)[0m
Calcite parsing passed, start to transform. SELECT SUM(COL1) FROM VTABLE WHERE 1000 + COL1 >= COL2 HAVING MAX(COL1) > 100
Calcite parsing passed, start to transform. SELECT SUM(COL1) FROM VTABLE WHERE 1000 + COL1 >= COL2 HAVING MAX(COL1) > 100
Calcite parsing passed, start to transform. SELECT SUM(COL1) FROM VTABLE WHERE 1000 + COL1 >= COL2 HAVING MAX(COL1) > 100
[31m- 0276 *** FAILED ***[0m
[31m  Results do not match for 0276:[0m
[31m  == Parsed Logical Plan ==[0m
[31m  'Filter ('MAX('COL1) > 100)[0m
[31m   'Project ['SUM('COL1) AS c0#49947][0m
[31m    'Filter ((1000 + 'COL1) >= 'COL2)[0m
[31m     'UnresolvedRelation [VTABLE], None[0m
  
[31m  == Analyzed Logical Plan ==[0m
[31m  c0: double[0m
[31m  Project [c0#49947][0m
[31m   Filter havingCondition#49953[0m
[31m    Aggregate [(max(COL1#49948) > cast(100 as double)) AS havingCondition#49953,sum(COL1#49948) AS c0#49947][0m
[31m     Filter ((cast(1000 as double) + COL1#49948) >= COL2#49949)[0m
[31m      MetastoreRelation HU, vtable, None[0m
  
[31m  == Optimized Logical Plan ==[0m
[31m  Project [c0#49947][0m
[31m   Filter havingCondition#49953[0m
[31m    Aggregate [(max(COL1#49948) > 100.0) AS havingCondition#49953,sum(COL1#49948) AS c0#49947][0m
[31m     Project [COL1#49948][0m
[31m      Filter ((1000.0 + COL1#49948) >= COL2#49949)[0m
[31m       MetastoreRelation HU, vtable, None[0m
  
[31m  == Physical Plan ==[0m
[31m  TungstenProject [c0#49947][0m
[31m   Filter havingCondition#49953[0m
[31m    TungstenAggregate(key=[], functions=[(max(COL1#49948),mode=Final,isDistinct=false),(sum(COL1#49948),mode=Final,isDistinct=false)], output=[havingCondition#49953,c0#49947])[0m
[31m     TungstenExchange SinglePartition[0m
[31m      TungstenAggregate(key=[], functions=[(max(COL1#49948),mode=Partial,isDistinct=false),(sum(COL1#49948),mode=Partial,isDistinct=false)], output=[max#49957,currentSum#49959])[0m
[31m       Project [COL1#49948][0m
[31m        Filter ((1000.0 + COL1#49948) >= COL2#49949)[0m
[31m         HiveTableScan [COL1#49948,COL2#49949], (MetastoreRelation HU, vtable, None)[0m
  
[31m  Code Generation: true[0m
[31m  c0[0m
[31m  !== HIVE - 1 row(s) ==   == CATALYST - 1 row(s) ==[0m
[31m  !1550                    1550.0 (HiveComparisonTest.scala:433)[0m
Calcite parsing passed, start to transform. SELECT COL1, COL2 FROM VTABLE WHERE(2*(COL3 - COL2)) BETWEEN 5 AND 200 ORDER BY COL1
Calcite parsing passed, start to transform. SELECT COL1, COL2 FROM VTABLE WHERE(2*(COL3 - COL2)) BETWEEN 5 AND 200 ORDER BY COL1
Calcite parsing passed, start to transform. SELECT COL1, COL2 FROM VTABLE WHERE(2*(COL3 - COL2)) BETWEEN 5 AND 200 ORDER BY COL1
[31m- 0277 *** FAILED ***[0m
[31m  Results do not match for 0277:[0m
[31m  == Parsed Logical Plan ==[0m
[31m  'Sort ['COL1 ASC], true[0m
[31m   'Project ['COL1,'COL2][0m
[31m    'Filter (((2 * ('COL3 - 'COL2)) >= 5) && ((2 * ('COL3 - 'COL2)) <= 200))[0m
[31m     'UnresolvedRelation [VTABLE], None[0m
  
[31m  == Analyzed Logical Plan ==[0m
[31m  COL1: double, COL2: double[0m
[31m  Sort [COL1#51639 ASC], true[0m
[31m   Project [COL1#51639,COL2#51640][0m
[31m    Filter (((cast(2 as double) * (COL3#51641 - COL2#51640)) >= cast(5 as double)) && ((cast(2 as double) * (COL3#51641 - COL2#51640)) <= cast(200 as double)))[0m
[31m     MetastoreRelation HU, vtable, None[0m
  
[31m  == Optimized Logical Plan ==[0m
[31m  Sort [COL1#51639 ASC], true[0m
[31m   Project [COL1#51639,COL2#51640][0m
[31m    Filter (((2.0 * (COL3#51641 - COL2#51640)) >= 5.0) && ((2.0 * (COL3#51641 - COL2#51640)) <= 200.0))[0m
[31m     MetastoreRelation HU, vtable, None[0m
  
[31m  == Physical Plan ==[0m
[31m  TungstenSort [COL1#51639 ASC], true, 0[0m
[31m   ConvertToUnsafe[0m
[31m    Exchange rangepartitioning(COL1#51639 ASC)[0m
[31m     Project [COL1#51639,COL2#51640][0m
[31m      Filter (((2.0 * (COL3#51641 - COL2#51640)) >= 5.0) && ((2.0 * (COL3#51641 - COL2#51640)) <= 200.0))[0m
[31m       HiveTableScan [COL1#51639,COL2#51640,COL3#51641], (MetastoreRelation HU, vtable, None)[0m
  
[31m  Code Generation: true[0m
[31m  COL1	COL2[0m
[31m  !== HIVE - 2 row(s) ==   == CATALYST - 2 row(s) ==[0m
[31m  !10	20                   10.0	20.0[0m
[31m  !100	200                 100.0	200.0 (HiveComparisonTest.scala:433)[0m
NoViableAltException(231@[])
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.function(HiveParser_IdentifiersParser.java:3544)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.atomExpression(HiveParser_IdentifiersParser.java:6280)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceFieldExpression(HiveParser_IdentifiersParser.java:6383)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceUnaryPrefixExpression(HiveParser_IdentifiersParser.java:6768)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceUnarySuffixExpression(HiveParser_IdentifiersParser.java:6828)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceBitwiseXorExpression(HiveParser_IdentifiersParser.java:7012)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceStarExpression(HiveParser_IdentifiersParser.java:7172)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedencePlusExpression(HiveParser_IdentifiersParser.java:7332)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceAmpersandExpression(HiveParser_IdentifiersParser.java:7483)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceBitwiseOrExpression(HiveParser_IdentifiersParser.java:7634)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceEqualExpression(HiveParser_IdentifiersParser.java:8290)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceNotExpression(HiveParser_IdentifiersParser.java:9177)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceAndExpression(HiveParser_IdentifiersParser.java:9296)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceOrExpression(HiveParser_IdentifiersParser.java:9455)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.expression(HiveParser_IdentifiersParser.java:6105)
	at org.apache.hadoop.hive.ql.parse.HiveParser.expression(HiveParser.java:45846)
	at org.apache.hadoop.hive.ql.parse.HiveParser_FromClauseParser.searchCondition(HiveParser_FromClauseParser.java:6637)
	at org.apache.hadoop.hive.ql.parse.HiveParser_FromClauseParser.whereClause(HiveParser_FromClauseParser.java:6545)
	at org.apache.hadoop.hive.ql.parse.HiveParser.whereClause(HiveParser.java:45849)
	at org.apache.hadoop.hive.ql.parse.HiveParser.selectStatement(HiveParser.java:41543)
	at org.apache.hadoop.hive.ql.parse.HiveParser.regularBody(HiveParser.java:41402)
	at org.apache.hadoop.hive.ql.parse.HiveParser.queryStatementExpressionBody(HiveParser.java:40413)
	at org.apache.hadoop.hive.ql.parse.HiveParser.queryStatementExpression(HiveParser.java:40283)
	at org.apache.hadoop.hive.ql.parse.HiveParser.execStatement(HiveParser.java:1590)
	at org.apache.hadoop.hive.ql.parse.HiveParser.statement(HiveParser.java:1109)
	at org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:202)
	at org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:166)
	at org.apache.spark.sql.hive.HiveQl$.getAst(HiveQl.scala:258)
	at org.apache.spark.sql.hive.HiveQl$.createPlan(HiveQl.scala:283)
	at org.apache.spark.sql.hive.ExtendedHiveQlParser$$anonfun$hiveQl$1.apply(ExtendedHiveQlParser.scala:41)
	at org.apache.spark.sql.hive.ExtendedHiveQlParser$$anonfun$hiveQl$1.apply(ExtendedHiveQlParser.scala:40)
	at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)
	at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:135)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)
	at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Failure.append(Parsers.scala:202)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)
	at scala.util.parsing.combinator.Parsers$$anon$2$$anonfun$apply$14.apply(Parsers.scala:891)
	at scala.util.parsing.combinator.Parsers$$anon$2$$anonfun$apply$14.apply(Parsers.scala:891)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)
	at scala.util.parsing.combinator.Parsers$$anon$2.apply(Parsers.scala:890)
	at scala.util.parsing.combinator.PackratParsers$$anon$1.apply(PackratParsers.scala:110)
	at org.apache.spark.sql.catalyst.AbstractSparkSQLParser.parse(AbstractSparkSQLParser.scala:34)
	at org.apache.spark.sql.hive.HiveQl$.parseSql(HiveQl.scala:276)
	at org.apache.spark.sql.hive.HiveQLDialect.parse(HiveContext.scala:62)
	at com.intel.ssg.bdt.spark.sql.CalciteDialect.getLogicalPlan(CalciteDialect.scala:54)
	at com.intel.ssg.bdt.spark.sql.CalciteDialect.parse(CalciteDialect.scala:31)
	at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)
	at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)
	at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:115)
	at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:114)
	at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)
	at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:135)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)
	at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Failure.append(Parsers.scala:202)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)
	at scala.util.parsing.combinator.Parsers$$anon$2$$anonfun$apply$14.apply(Parsers.scala:891)
	at scala.util.parsing.combinator.Parsers$$anon$2$$anonfun$apply$14.apply(Parsers.scala:891)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)
	at scala.util.parsing.combinator.Parsers$$anon$2.apply(Parsers.scala:890)
	at scala.util.parsing.combinator.PackratParsers$$anon$1.apply(PackratParsers.scala:110)
	at org.apache.spark.sql.catalyst.AbstractSparkSQLParser.parse(AbstractSparkSQLParser.scala:34)
	at org.apache.spark.sql.SQLContext$$anonfun$2.apply(SQLContext.scala:166)
	at org.apache.spark.sql.SQLContext$$anonfun$2.apply(SQLContext.scala:166)
	at org.apache.spark.sql.execution.datasources.DDLParser.parse(DDLParser.scala:42)
	at org.apache.spark.sql.SQLContext.parseSql(SQLContext.scala:189)
	at org.apache.spark.sql.hive.HiveContext.parseSql(HiveContext.scala:280)
	at org.apache.spark.sql.hive.test.TestHiveContext$QueryExecution.<init>(TestHive.scala:179)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1$$anonfun$30.apply(HiveComparisonTest.scala:303)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1$$anonfun$30.apply(HiveComparisonTest.scala:303)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:34)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:244)
	at scala.collection.AbstractTraversable.map(Traversable.scala:105)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1.apply$mcV$sp(HiveComparisonTest.scala:303)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1.apply(HiveComparisonTest.scala:240)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1.apply(HiveComparisonTest.scala:240)
	at org.scalatest.Transformer$$anonfun$apply$1.apply$mcV$sp(Transformer.scala:22)
	at org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)
	at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
	at org.scalatest.Transformer.apply(Transformer.scala:22)
	at org.scalatest.Transformer.apply(Transformer.scala:20)
	at org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:166)
	at org.apache.spark.SparkFunSuite.withFixture(SparkFunSuite.scala:42)
	at org.scalatest.FunSuiteLike$class.invokeWithFixture$1(FunSuiteLike.scala:163)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)
	at org.scalatest.FunSuiteLike$class.runTest(FunSuiteLike.scala:175)
	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.org$scalatest$BeforeAndAfter$$super$runTest(HiveCompatibilitySuite.scala:32)
	at org.scalatest.BeforeAndAfter$class.runTest(BeforeAndAfter.scala:200)
	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.runTest(HiveCompatibilitySuite.scala:32)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:413)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:401)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)
	at org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:396)
	at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:483)
	at org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:208)
	at org.scalatest.FunSuite.runTests(FunSuite.scala:1555)
	at org.scalatest.Suite$class.run(Suite.scala:1424)
	at org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.SuperEngine.runImpl(Engine.scala:545)
	at org.scalatest.FunSuiteLike$class.run(FunSuiteLike.scala:212)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest.org$scalatest$BeforeAndAfterAll$$super$run(HiveComparisonTest.scala:44)
	at org.scalatest.BeforeAndAfterAll$class.liftedTree1$1(BeforeAndAfterAll.scala:257)
	at org.scalatest.BeforeAndAfterAll$class.run(BeforeAndAfterAll.scala:256)
	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.org$scalatest$BeforeAndAfter$$super$run(HiveCompatibilitySuite.scala:32)
	at org.scalatest.BeforeAndAfter$class.run(BeforeAndAfter.scala:241)
	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.run(HiveCompatibilitySuite.scala:32)
	at org.scalatest.Suite$class.callExecuteOnSuite$1(Suite.scala:1492)
	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1528)
	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1526)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.scalatest.Suite$class.runNestedSuites(Suite.scala:1526)
	at org.scalatest.tools.DiscoverySuite.runNestedSuites(DiscoverySuite.scala:29)
	at org.scalatest.Suite$class.run(Suite.scala:1421)
	at org.scalatest.tools.DiscoverySuite.run(DiscoverySuite.scala:29)
	at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:55)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2563)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2557)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:2557)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1044)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1043)
	at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:2722)
	at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1043)
	at org.scalatest.tools.Runner$.main(Runner.scala:860)
	at org.scalatest.tools.Runner.main(Runner.scala)
[31m- 0278 *** FAILED ***[0m
[31m  org.apache.spark.sql.AnalysisException: cannot recognize input near 'SELECT' 'HOURS' 'FROM' in function specification; line 1 pos 62[0m
[31m  at org.apache.spark.sql.hive.HiveQl$.createPlan(HiveQl.scala:296)[0m
[31m  at org.apache.spark.sql.hive.ExtendedHiveQlParser$$anonfun$hiveQl$1.apply(ExtendedHiveQlParser.scala:41)[0m
[31m  at org.apache.spark.sql.hive.ExtendedHiveQlParser$$anonfun$hiveQl$1.apply(ExtendedHiveQlParser.scala:40)[0m
[31m  at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)[0m
[31m  at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:135)[0m
[31m  at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)[0m
[31m  at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)[0m
[31m  at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)[0m
[31m  at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)[0m
[31m  at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)[0m
[31m  ...[0m
Calcite parsing passed, start to transform. SELECT COL1, (COL3 * COL2/COL1 - COL2 + 10) FROM VTABLE WHERE COL1 > 0 ORDER BY 2
Calcite parsing passed, start to transform. SELECT COL1, (COL3 * COL2/COL1 - COL2 + 10) FROM VTABLE WHERE COL1 > 0 ORDER BY 2
Calcite parsing passed, start to transform. SELECT COL1, (COL3 * COL2/COL1 - COL2 + 10) FROM VTABLE WHERE COL1 > 0 ORDER BY 2
[31m- 0279 *** FAILED ***[0m
[31m  Results do not match for 0279:[0m
[31m  == Parsed Logical Plan ==[0m
[31m  'Sort ['c1 ASC], true[0m
[31m   'Project ['COL1,(((('COL3 * 'COL2) / 'COL1) - 'COL2) + 10) AS c1#51879][0m
[31m    'Filter ('COL1 > 0)[0m
[31m     'UnresolvedRelation [VTABLE], None[0m
  
[31m  == Analyzed Logical Plan ==[0m
[31m  COL1: double, c1: double[0m
[31m  Sort [c1#51879 ASC], true[0m
[31m   Project [COL1#51880,((((COL3#51882 * COL2#51881) / COL1#51880) - COL2#51881) + cast(10 as double)) AS c1#51879][0m
[31m    Filter (COL1#51880 > cast(0 as double))[0m
[31m     MetastoreRelation HU, vtable, None[0m
  
[31m  == Optimized Logical Plan ==[0m
[31m  Sort [c1#51879 ASC], true[0m
[31m   Project [COL1#51880,((((COL3#51882 * COL2#51881) / COL1#51880) - COL2#51881) + 10.0) AS c1#51879][0m
[31m    Filter (COL1#51880 > 0.0)[0m
[31m     MetastoreRelation HU, vtable, None[0m
  
[31m  == Physical Plan ==[0m
[31m  TungstenSort [c1#51879 ASC], true, 0[0m
[31m   ConvertToUnsafe[0m
[31m    Exchange rangepartitioning(c1#51879 ASC)[0m
[31m     Project [COL1#51880,((((COL3#51882 * COL2#51881) / COL1#51880) - COL2#51881) + 10.0) AS c1#51879][0m
[31m      Filter (COL1#51880 > 0.0)[0m
[31m       HiveTableScan [COL1#51880,COL3#51882,COL2#51881], (MetastoreRelation HU, vtable, None)[0m
  
[31m  Code Generation: true[0m
[31m  COL1	c1[0m
[31m  !== HIVE - 12 row(s) ==   == CATALYST - 12 row(s) ==[0m
[31m  !1000	-3990               1000.0	-3990.0[0m
[31m  !1	11                     1.0	11.0[0m
[31m  !10	12.2                  10.0	12.2[0m
[31m  !10	12.2                  10.0	12.2[0m
[31m  !10	12.2                  10.0	12.2[0m
[31m  !10	12.2                  10.0	12.2[0m
[31m  !10	50                    10.0	50.0[0m
[31m  !100	410                  100.0	410.0[0m
[31m  !100	1133.32              100.0	1133.32[0m
[31m  !100	1133.32              100.0	1133.32[0m
[31m  !100	1133.32              100.0	1133.32[0m
[31m  !100	1133.32              100.0	1133.32 (HiveComparisonTest.scala:433)[0m
Calcite parsing passed, start to transform. SELECT EMPNUM, PNUM, HOURS FROM SUBSP
Calcite parsing passed, start to transform. SELECT EMPNUM, PNUM, HOURS FROM SUBSP
Calcite parsing passed, start to transform. SELECT EMPNUM, PNUM, HOURS FROM SUBSP
[31m- 0280 *** FAILED ***[0m
[31m  Results do not match for 0280:[0m
[31m  == Parsed Logical Plan ==[0m
[31m  'Project ['EMPNUM,'PNUM,'HOURS][0m
[31m   'UnresolvedRelation [SUBSP], None[0m
  
[31m  == Analyzed Logical Plan ==[0m
[31m  EMPNUM: string, PNUM: string, HOURS: double[0m
[31m  Project [EMPNUM#52072,PNUM#52073,HOURS#52074][0m
[31m   MetastoreRelation HU, subsp, None[0m
  
[31m  == Optimized Logical Plan ==[0m
[31m  Project [EMPNUM#52072,PNUM#52073,HOURS#52074][0m
[31m   MetastoreRelation HU, subsp, None[0m
  
[31m  == Physical Plan ==[0m
[31m  HiveTableScan [EMPNUM#52072,PNUM#52073,HOURS#52074], (MetastoreRelation HU, subsp, None)[0m
  
[31m  Code Generation: true[0m
[31m  EMPNUM	PNUM	HOURS[0m
[31m  !== HIVE - 1 row(s) ==   == CATALYST - 1 row(s) ==[0m
[31m  !E3	P4	50                E3	P4	50.0 (HiveComparisonTest.scala:433)[0m
Calcite parsing passed, start to transform. SELECT * FROM WORKS
Calcite parsing passed, start to transform. SELECT * FROM WORKS
Calcite parsing passed, start to transform. SELECT * FROM WORKS
[31m- 0281 *** FAILED ***[0m
[31m  Results do not match for 0281:[0m
[31m  == Parsed Logical Plan ==[0m
[31m  'Project [*][0m
[31m   'UnresolvedRelation [WORKS], None[0m
  
[31m  == Analyzed Logical Plan ==[0m
[31m  empnum: string, pnum: string, hours: double[0m
[31m  Project [empnum#52326,pnum#52327,hours#52328][0m
[31m   MetastoreRelation HU, works, None[0m
  
[31m  == Optimized Logical Plan ==[0m
[31m  MetastoreRelation HU, works, None[0m
  
[31m  == Physical Plan ==[0m
[31m  HiveTableScan [empnum#52326,pnum#52327,hours#52328], (MetastoreRelation HU, works, None)[0m
  
[31m  Code Generation: true[0m
[31m  empnum	pnum	hours[0m
[31m  !== HIVE - 19 row(s) ==   == CATALYST - 19 row(s) ==[0m
[31m  !E1	P1	40                 E1	P1	40.0[0m
[31m  !E1	P2	20                 E1	P2	20.0[0m
[31m  !E1	P4	20                 E1	P4	20.0[0m
[31m  !E1	P5	12                 E1	P5	12.0[0m
[31m  !E1	P6	12                 E1	P6	12.0[0m
[31m  !E1	P7	90                 E1	P7	90.0[0m
[31m   E18	P18	NULL             E18	P18	NULL[0m
[31m  !E2	P1	40                 E2	P1	40.0[0m
[31m  !E2	P2	80                 E2	P2	80.0[0m
[31m   E22	P22	NULL             E22	P22	NULL[0m
[31m  !E3	P4	50                 E3	P4	50.0[0m
[31m  !E4	P2	20                 E4	P2	20.0[0m
[31m  !E4	P4	40                 E4	P4	40.0[0m
[31m  !E4	P5	80                 E4	P5	80.0[0m
[31m   E5	P5	NULL               E5	P5	NULL[0m
[31m  !E7	P4	95                 E7	P4	95.0[0m
[31m  !E8	P8	20                 E8	P8	20.0[0m
[31m   E9	P9	NULL               E9	P9	NULL[0m
[31m  !UPP	low	100              UPP	low	100.0 (HiveComparisonTest.scala:433)[0m
Calcite parsing passed, start to transform. SELECT * FROM WORKS
Calcite parsing passed, start to transform. SELECT * FROM WORKS
Calcite parsing passed, start to transform. SELECT * FROM WORKS
[31m- 0282 *** FAILED ***[0m
[31m  Results do not match for 0282:[0m
[31m  == Parsed Logical Plan ==[0m
[31m  'Project [*][0m
[31m   'UnresolvedRelation [WORKS], None[0m
  
[31m  == Analyzed Logical Plan ==[0m
[31m  empnum: string, pnum: string, hours: double[0m
[31m  Project [empnum#52660,pnum#52661,hours#52662][0m
[31m   MetastoreRelation HU, works, None[0m
  
[31m  == Optimized Logical Plan ==[0m
[31m  MetastoreRelation HU, works, None[0m
  
[31m  == Physical Plan ==[0m
[31m  HiveTableScan [empnum#52660,pnum#52661,hours#52662], (MetastoreRelation HU, works, None)[0m
  
[31m  Code Generation: true[0m
[31m  empnum	pnum	hours[0m
[31m  !== HIVE - 19 row(s) ==   == CATALYST - 19 row(s) ==[0m
[31m  !E1	P1	40                 E1	P1	40.0[0m
[31m  !E1	P2	20                 E1	P2	20.0[0m
[31m  !E1	P4	20                 E1	P4	20.0[0m
[31m  !E1	P5	12                 E1	P5	12.0[0m
[31m  !E1	P6	12                 E1	P6	12.0[0m
[31m  !E1	P7	90                 E1	P7	90.0[0m
[31m   E18	P18	NULL             E18	P18	NULL[0m
[31m  !E2	P1	40                 E2	P1	40.0[0m
[31m  !E2	P2	80                 E2	P2	80.0[0m
[31m   E22	P22	NULL             E22	P22	NULL[0m
[31m  !E3	P4	50                 E3	P4	50.0[0m
[31m  !E4	P2	20                 E4	P2	20.0[0m
[31m  !E4	P4	40                 E4	P4	40.0[0m
[31m  !E4	P5	80                 E4	P5	80.0[0m
[31m   E5	P5	NULL               E5	P5	NULL[0m
[31m  !E7	P4	95                 E7	P4	95.0[0m
[31m  !E8	P8	20                 E8	P8	20.0[0m
[31m   E9	P9	NULL               E9	P9	NULL[0m
[31m  !UPP	low	100              UPP	low	100.0 (HiveComparisonTest.scala:433)[0m
Calcite parsing passed, start to transform. SELECT EMPNUM, PNUM, HOURS FROM SUBSP
Calcite parsing passed, start to transform. SELECT EMPNUM, PNUM, HOURS FROM SUBSP
Calcite parsing passed, start to transform. SELECT EMPNUM, PNUM, HOURS FROM SUBSP
[31m- 0283 *** FAILED ***[0m
[31m  Results do not match for 0283:[0m
[31m  == Parsed Logical Plan ==[0m
[31m  'Project ['EMPNUM,'PNUM,'HOURS][0m
[31m   'UnresolvedRelation [SUBSP], None[0m
  
[31m  == Analyzed Logical Plan ==[0m
[31m  EMPNUM: string, PNUM: string, HOURS: double[0m
[31m  Project [EMPNUM#52924,PNUM#52925,HOURS#52926][0m
[31m   MetastoreRelation HU, subsp, None[0m
  
[31m  == Optimized Logical Plan ==[0m
[31m  Project [EMPNUM#52924,PNUM#52925,HOURS#52926][0m
[31m   MetastoreRelation HU, subsp, None[0m
  
[31m  == Physical Plan ==[0m
[31m  HiveTableScan [EMPNUM#52924,PNUM#52925,HOURS#52926], (MetastoreRelation HU, subsp, None)[0m
  
[31m  Code Generation: true[0m
[31m  EMPNUM	PNUM	HOURS[0m
[31m  !== HIVE - 1 row(s) ==   == CATALYST - 1 row(s) ==[0m
[31m  !E3	P4	50                E3	P4	50.0 (HiveComparisonTest.scala:433)[0m
Calcite parsing passed, start to transform. SELECT * FROM WORKS WHERE EMPNUM = 'E3'
Calcite parsing passed, start to transform. SELECT * FROM WORKS WHERE EMPNUM = 'E3'
Calcite parsing passed, start to transform. SELECT * FROM WORKS WHERE EMPNUM = 'E3'
[31m- 0284 *** FAILED ***[0m
[31m  Results do not match for 0284:[0m
[31m  == Parsed Logical Plan ==[0m
[31m  'Project [*][0m
[31m   'Filter ('EMPNUM = E3)[0m
[31m    'UnresolvedRelation [WORKS], None[0m
  
[31m  == Analyzed Logical Plan ==[0m
[31m  empnum: string, pnum: string, hours: double[0m
[31m  Project [empnum#53178,pnum#53179,hours#53180][0m
[31m   Filter (EMPNUM#53178 = E3)[0m
[31m    MetastoreRelation HU, works, None[0m
  
[31m  == Optimized Logical Plan ==[0m
[31m  Filter (EMPNUM#53178 = E3)[0m
[31m   MetastoreRelation HU, works, None[0m
  
[31m  == Physical Plan ==[0m
[31m  Filter (EMPNUM#53178 = E3)[0m
[31m   HiveTableScan [empnum#53178,pnum#53179,hours#53180], (MetastoreRelation HU, works, None)[0m
  
[31m  Code Generation: true[0m
[31m  empnum	pnum	hours[0m
[31m  !== HIVE - 1 row(s) ==   == CATALYST - 1 row(s) ==[0m
[31m  !E3	P4	50                E3	P4	50.0 (HiveComparisonTest.scala:433)[0m
Calcite parsing passed, start to transform. SELECT EMPNUM, PNUM, HOURS FROM SUBSP
Calcite parsing passed, start to transform. SELECT EMPNUM, PNUM, HOURS FROM SUBSP
Calcite parsing passed, start to transform. SELECT EMPNUM, PNUM, HOURS FROM SUBSP
[31m- 0285 *** FAILED ***[0m
[31m  Results do not match for 0285:[0m
[31m  == Parsed Logical Plan ==[0m
[31m  'Project ['EMPNUM,'PNUM,'HOURS][0m
[31m   'UnresolvedRelation [SUBSP], None[0m
  
[31m  == Analyzed Logical Plan ==[0m
[31m  EMPNUM: string, PNUM: string, HOURS: double[0m
[31m  Project [EMPNUM#53442,PNUM#53443,HOURS#53444][0m
[31m   MetastoreRelation HU, subsp, None[0m
  
[31m  == Optimized Logical Plan ==[0m
[31m  Project [EMPNUM#53442,PNUM#53443,HOURS#53444][0m
[31m   MetastoreRelation HU, subsp, None[0m
  
[31m  == Physical Plan ==[0m
[31m  HiveTableScan [EMPNUM#53442,PNUM#53443,HOURS#53444], (MetastoreRelation HU, subsp, None)[0m
  
[31m  Code Generation: true[0m
[31m  EMPNUM	PNUM	HOURS[0m
[31m  !== HIVE - 1 row(s) ==   == CATALYST - 1 row(s) ==[0m
[31m  !E3	P6	50                E3	P6	50.0 (HiveComparisonTest.scala:433)[0m
Calcite parsing passed, start to transform. SELECT * FROM WORKS WHERE EMPNUM = 'E3'
Calcite parsing passed, start to transform. SELECT * FROM WORKS WHERE EMPNUM = 'E3'
Calcite parsing passed, start to transform. SELECT * FROM WORKS WHERE EMPNUM = 'E3'
[31m- 0286 *** FAILED ***[0m
[31m  Results do not match for 0286:[0m
[31m  == Parsed Logical Plan ==[0m
[31m  'Project [*][0m
[31m   'Filter ('EMPNUM = E3)[0m
[31m    'UnresolvedRelation [WORKS], None[0m
  
[31m  == Analyzed Logical Plan ==[0m
[31m  empnum: string, pnum: string, hours: double[0m
[31m  Project [empnum#53696,pnum#53697,hours#53698][0m
[31m   Filter (EMPNUM#53696 = E3)[0m
[31m    MetastoreRelation HU, works, None[0m
  
[31m  == Optimized Logical Plan ==[0m
[31m  Filter (EMPNUM#53696 = E3)[0m
[31m   MetastoreRelation HU, works, None[0m
  
[31m  == Physical Plan ==[0m
[31m  Filter (EMPNUM#53696 = E3)[0m
[31m   HiveTableScan [empnum#53696,pnum#53697,hours#53698], (MetastoreRelation HU, works, None)[0m
  
[31m  Code Generation: true[0m
[31m  empnum	pnum	hours[0m
[31m  !== HIVE - 1 row(s) ==   == CATALYST - 1 row(s) ==[0m
[31m  !E3	P6	50                E3	P6	50.0 (HiveComparisonTest.scala:433)[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM WORKS1 WHERE EMPNUM = 'P1' AND HOURS > 30
[32m- 0287[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM WORKS WHERE HOURS BETWEEN 80 AND 40
[32m- 0288[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM WORKS WHERE HOURS BETWEEN -40 AND -80
[32m- 0289[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM WORKS WHERE HOURS BETWEEN -80 AND -40
[32m- 0290[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM WORKS WHERE HOURS BETWEEN 11.999 AND 12 OR HOURS BETWEEN 19.999 AND 2.001E1
[32m- 0291[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM WORKS,STAFF WHERE WORKS.EMPNUM = 'E1'
[32m- 0292[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM WORKS WHERE EMPNUM = 'E7' OR HOURS = 31 OR HOURS = 17
[32m- 0293[0m
Calcite parsing passed, start to transform. SELECT SUM(HOURS),MAX(HOURS),MIN(HOURS),MIN(EMPNUM) FROM WORKS
[32m- 0294[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM WORKS WHERE HOURS IS NULL
[32m- 0295[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM SULLIVAN1.AUTH_TABLE
[32m- 0297[0m
Calcite parsing passed, start to transform. SELECT CHARTEST FROM AA
[32m- 0298[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM STAFF1,WORKS1,PROJ1 WHERE STAFF1.EMPNUM = 'E9' AND STAFF1.EMPNUM = WORKS1.EMPNUM AND PROJ1.PNUM = WORKS1.PNUM
[32m- 0299[0m
Calcite parsing passed, start to transform. SELECT EMPNUM,SECOND2 FROM SULLIVAN1.MUL_SCH ORDER BY EMPNUM
[32m- 0300[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM STAFF
[32m- 0301[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM STAFF WHERE 40 IN (SELECT HOURS FROM WORKS WHERE STAFF.EMPNUM = WORKS.EMPNUM)
error SELECT COUNT(*) FROM STAFF WHERE 40 IN (SELECT HOURS FROM WORKS WHERE STAFF.EMPNUM = WORKS.EMPNUM)[31m- 0302 ***  ***[0m
[31m  java.lang.RuntimeException: Parse failed.[0m
[31m  at scala.sys.package$.error(package.scala:27)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect$$anonfun$parse$1.apply(CalciteDialect.scala:33)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect$$anonfun$parse$1.apply(CalciteDialect.scala:32)[0m
[31m  at scala.Option.getOrElse(Option.scala:120)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect.parse(CalciteDialect.scala:31)[0m
[31m  at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)[0m
[31m  at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)[0m
[31m  at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:115)[0m
[31m  at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:114)[0m
[31m  at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)[0m
[31m  ...[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM STAFF WHERE 40 NOT IN (SELECT HOURS FROM WORKS WHERE STAFF.EMPNUM = WORKS.EMPNUM)
error SELECT COUNT(*) FROM STAFF WHERE 40 NOT IN (SELECT HOURS FROM WORKS WHERE STAFF.EMPNUM = WORKS.EMPNUM)[31m- 0303 ***  ***[0m
[31m  java.lang.RuntimeException: Parse failed.[0m
[31m  at scala.sys.package$.error(package.scala:27)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect$$anonfun$parse$1.apply(CalciteDialect.scala:33)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect$$anonfun$parse$1.apply(CalciteDialect.scala:32)[0m
[31m  at scala.Option.getOrElse(Option.scala:120)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect.parse(CalciteDialect.scala:31)[0m
[31m  at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)[0m
[31m  at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)[0m
[31m  at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:115)[0m
[31m  at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:114)[0m
[31m  at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)[0m
[31m  ...[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM STAFF WHERE EXISTS (SELECT * FROM WORKS WHERE HOURS = 40 AND STAFF.EMPNUM = WORKS.EMPNUM)
error SELECT COUNT(*) FROM STAFF WHERE EXISTS (SELECT * FROM WORKS WHERE HOURS = 40 AND STAFF.EMPNUM = WORKS.EMPNUM)[31m- 0304 ***  ***[0m
[31m  java.lang.RuntimeException: Parse failed.[0m
[31m  at scala.sys.package$.error(package.scala:27)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect$$anonfun$parse$1.apply(CalciteDialect.scala:33)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect$$anonfun$parse$1.apply(CalciteDialect.scala:32)[0m
[31m  at scala.Option.getOrElse(Option.scala:120)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect.parse(CalciteDialect.scala:31)[0m
[31m  at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)[0m
[31m  at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)[0m
[31m  at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:115)[0m
[31m  at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:114)[0m
[31m  at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)[0m
[31m  ...[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM STAFF WHERE NOT EXISTS (SELECT * FROM WORKS WHERE HOURS = 40 AND STAFF.EMPNUM = WORKS.EMPNUM)
error SELECT COUNT(*) FROM STAFF WHERE NOT EXISTS (SELECT * FROM WORKS WHERE HOURS = 40 AND STAFF.EMPNUM = WORKS.EMPNUM)[31m- 0305 ***  ***[0m
[31m  java.lang.RuntimeException: Parse failed.[0m
[31m  at scala.sys.package$.error(package.scala:27)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect$$anonfun$parse$1.apply(CalciteDialect.scala:33)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect$$anonfun$parse$1.apply(CalciteDialect.scala:32)[0m
[31m  at scala.Option.getOrElse(Option.scala:120)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect.parse(CalciteDialect.scala:31)[0m
[31m  at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)[0m
[31m  at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)[0m
[31m  at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:115)[0m
[31m  at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:114)[0m
[31m  at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)[0m
[31m  ...[0m
Calcite parsing passed, start to transform. SELECT COUNT (*) FROM PROJ
[32m- 0306[0m
Calcite parsing passed, start to transform. SELECT COUNT (*) FROM WORKS WHERE HOURS = 10
[32m- 0307[0m
Calcite parsing passed, start to transform. SELECT COUNT (*) FROM WORKS WHERE EMPNUM = 'E7'
[32m- 0308[0m
Calcite parsing passed, start to transform. SELECT COUNT (*) FROM WORKS
[32m- 0309[0m
Calcite parsing passed, start to transform. SELECT COUNT (*) FROM STAFF
[32m- 0310[0m
Calcite parsing passed, start to transform. SELECT COUNT (*) FROM STAFF WHERE GRADE = 13
[32m- 0311[0m
Calcite parsing passed, start to transform. SELECT COUNT (*) FROM STAFF WHERE GRADE = 15
[32m- 0312[0m
Calcite parsing passed, start to transform. SELECT COUNT (*) FROM STAFF WHERE GRADE IS NULL OR EMPNAME = 'Kathy'
[32m- 0313[0m
Calcite parsing passed, start to transform. SELECT COUNT (*) FROM STAFF WHERE GRADE = 15
[32m- 0314[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM STAFF WHERE EMPNAME = 'Ed'
[32m- 0315[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM STAFF WHERE EMPNAME = 'Ed '
[32m- 0316[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM STAFF WHERE EMPNAME = 'Ed                '
[32m- 0317[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM STAFF WHERE GRADE = 25
[32m- 0318[0m
Calcite parsing passed, start to transform. SELECT PNUM FROM WORKS WHERE EMPNUM = 'E1' AND HOURS IN (SELECT COL1 FROM CUGINI.VTABLE WHERE  COL1 > 50)
error SELECT PNUM FROM WORKS WHERE EMPNUM = 'E1' AND HOURS IN (SELECT COL1 FROM CUGINI.VTABLE WHERE  COL1 > 50)[31m- 0319 ***  ***[0m
[31m  java.lang.RuntimeException: Parse failed.[0m
[31m  at scala.sys.package$.error(package.scala:27)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect$$anonfun$parse$1.apply(CalciteDialect.scala:33)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect$$anonfun$parse$1.apply(CalciteDialect.scala:32)[0m
[31m  at scala.Option.getOrElse(Option.scala:120)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect.parse(CalciteDialect.scala:31)[0m
[31m  at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)[0m
[31m  at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)[0m
[31m  at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:115)[0m
[31m  at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:114)[0m
[31m  at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)[0m
[31m  ...[0m
Calcite parsing passed, start to transform. SELECT * FROM WORKS1 WHERE EMPNUM = 'P2' ORDER BY EMPNUM, PNUM ASC
[32m- 0320[0m
Calcite parsing passed, start to transform. SELECT PNUM, WORKS.EMPNUM, EMPNAME, HOURS FROM WORKS, STAFF WHERE STAFF.EMPNUM = WORKS.EMPNUM ORDER BY 2
Calcite parsing passed, start to transform. SELECT PNUM, WORKS.EMPNUM, EMPNAME, HOURS FROM WORKS, STAFF WHERE STAFF.EMPNUM = WORKS.EMPNUM ORDER BY 2
Calcite parsing passed, start to transform. SELECT PNUM, WORKS.EMPNUM, EMPNAME, HOURS FROM WORKS, STAFF WHERE STAFF.EMPNUM = WORKS.EMPNUM ORDER BY 2
[31m- 0321 *** FAILED ***[0m
[31m  Results do not match for 0321:[0m
[31m  == Parsed Logical Plan ==[0m
[31m  'Sort ['WORKS.EMPNUM ASC], true[0m
[31m   'Project ['PNUM,'WORKS.EMPNUM,'EMPNAME,'HOURS][0m
[31m    'Filter ('STAFF.EMPNUM = 'WORKS.EMPNUM)[0m
[31m     'Join Inner, None[0m
[31m      'UnresolvedRelation [WORKS], None[0m
[31m      'UnresolvedRelation [STAFF], None[0m
  
[31m  == Analyzed Logical Plan ==[0m
[31m  PNUM: string, EMPNUM: string, EMPNAME: string, HOURS: double[0m
[31m  Sort [EMPNUM#59320 ASC], true[0m
[31m   Project [PNUM#59321,EMPNUM#59320,EMPNAME#59324,HOURS#59322][0m
[31m    Filter (EMPNUM#59323 = EMPNUM#59320)[0m
[31m     Join Inner, None[0m
[31m      MetastoreRelation HU, works, None[0m
[31m      MetastoreRelation HU, staff, None[0m
  
[31m  == Optimized Logical Plan ==[0m
[31m  Sort [EMPNUM#59320 ASC], true[0m
[31m   Project [PNUM#59321,EMPNUM#59320,EMPNAME#59324,HOURS#59322][0m
[31m    Join Inner, Some((EMPNUM#59323 = EMPNUM#59320))[0m
[31m     MetastoreRelation HU, works, None[0m
[31m     Project [EMPNAME#59324,EMPNUM#59323][0m
[31m      MetastoreRelation HU, staff, None[0m
  
[31m  == Physical Plan ==[0m
[31m  TungstenSort [EMPNUM#59320 ASC], true, 0[0m
[31m   ConvertToUnsafe[0m
[31m    Exchange rangepartitioning(EMPNUM#59320 ASC)[0m
[31m     ConvertToSafe[0m
[31m      TungstenProject [PNUM#59321,EMPNUM#59320,EMPNAME#59324,HOURS#59322][0m
[31m       BroadcastHashJoin [EMPNUM#59320], [EMPNUM#59323], BuildRight[0m
[31m        ConvertToUnsafe[0m
[31m         HiveTableScan [empnum#59320,pnum#59321,hours#59322], (MetastoreRelation HU, works, None)[0m
[31m        ConvertToUnsafe[0m
[31m         HiveTableScan [EMPNAME#59324,EMPNUM#59323], (MetastoreRelation HU, staff, None)[0m
  
[31m  Code Generation: true[0m
[31m  PNUM	EMPNUM	EMPNAME	HOURS[0m
[31m  !== HIVE - 5 row(s) ==   == CATALYST - 5 row(s) ==[0m
[31m   P6	E6	ALICE	NULL        P6	E6	ALICE	NULL[0m
[31m   P4	E7	yanping	NULL      P4	E7	yanping	NULL[0m
[31m   P8	E8	Yang Ling	NULL    P8	E8	Yang Ling	NULL[0m
[31m   P9	E9	JOHNNY	NULL       P9	E9	JOHNNY	NULL[0m
[31m  !P7	E9	JOHNNY	10         P7	E9	JOHNNY	10.0 (HiveComparisonTest.scala:433)[0m
Calcite parsing passed, start to transform. SELECT 'ZZ', EMPNUM, EMPNAME, -99 FROM STAFF WHERE NOT EXISTS (SELECT * FROM WORKS WHERE WORKS.EMPNUM = STAFF.EMPNUM) ORDER BY EMPNUM
error SELECT 'ZZ', EMPNUM, EMPNAME, -99 FROM STAFF WHERE NOT EXISTS (SELECT * FROM WORKS WHERE WORKS.EMPNUM = STAFF.EMPNUM) ORDER BY EMPNUM[31m- 0322 ***  ***[0m
[31m  java.lang.RuntimeException: Parse failed.[0m
[31m  at scala.sys.package$.error(package.scala:27)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect$$anonfun$parse$1.apply(CalciteDialect.scala:33)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect$$anonfun$parse$1.apply(CalciteDialect.scala:32)[0m
[31m  at scala.Option.getOrElse(Option.scala:120)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect.parse(CalciteDialect.scala:31)[0m
[31m  at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)[0m
[31m  at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)[0m
[31m  at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:115)[0m
[31m  at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:114)[0m
[31m  at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)[0m
[31m  ...[0m
Calcite parsing passed, start to transform. SELECT W1.EMPNUM FROM WORKS W1 WHERE W1.PNUM = 'P2' AND NOT EXISTS (SELECT * FROM WORKS W2 WHERE W2.EMPNUM = W1.EMPNUM AND W2.PNUM = 'P1') ORDER BY 1 ASC
error SELECT W1.EMPNUM FROM WORKS W1 WHERE W1.PNUM = 'P2' AND NOT EXISTS (SELECT * FROM WORKS W2 WHERE W2.EMPNUM = W1.EMPNUM AND W2.PNUM = 'P1') ORDER BY 1 ASC[31m- 0323 ***  ***[0m
[31m  java.lang.RuntimeException: Parse failed.[0m
[31m  at scala.sys.package$.error(package.scala:27)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect$$anonfun$parse$1.apply(CalciteDialect.scala:33)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect$$anonfun$parse$1.apply(CalciteDialect.scala:32)[0m
[31m  at scala.Option.getOrElse(Option.scala:120)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect.parse(CalciteDialect.scala:31)[0m
[31m  at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)[0m
[31m  at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)[0m
[31m  at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:115)[0m
[31m  at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:114)[0m
[31m  at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)[0m
[31m  ...[0m
Calcite parsing passed, start to transform. SELECT W1.EMPNUM FROM WORKS W1 WHERE W1.PNUM = 'P2' AND EXISTS (SELECT * FROM WORKS W2 WHERE W1.EMPNUM = W2.EMPNUM AND W2.PNUM = 'P1') ORDER BY EMPNUM ASC
error SELECT W1.EMPNUM FROM WORKS W1 WHERE W1.PNUM = 'P2' AND EXISTS (SELECT * FROM WORKS W2 WHERE W1.EMPNUM = W2.EMPNUM AND W2.PNUM = 'P1') ORDER BY EMPNUM ASC[31m- 0324 ***  ***[0m
[31m  java.lang.RuntimeException: Parse failed.[0m
[31m  at scala.sys.package$.error(package.scala:27)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect$$anonfun$parse$1.apply(CalciteDialect.scala:33)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect$$anonfun$parse$1.apply(CalciteDialect.scala:32)[0m
[31m  at scala.Option.getOrElse(Option.scala:120)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect.parse(CalciteDialect.scala:31)[0m
[31m  at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)[0m
[31m  at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)[0m
[31m  at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:115)[0m
[31m  at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:114)[0m
[31m  at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)[0m
[31m  ...[0m
Calcite parsing passed, start to transform. SELECT SUM(HOURS), MAX(HOURS) FROM  STAFF, WORKS
Calcite parsing passed, start to transform. SELECT SUM(HOURS), MAX(HOURS) FROM  STAFF, WORKS
Calcite parsing passed, start to transform. SELECT SUM(HOURS), MAX(HOURS) FROM  STAFF, WORKS
[31m- 0325 *** FAILED ***[0m
[31m  Results do not match for 0325:[0m
[31m  == Parsed Logical Plan ==[0m
[31m  'Project ['SUM('HOURS) AS c0#60086,'MAX('HOURS) AS c1#60087][0m
[31m   'Join Inner, None[0m
[31m    'UnresolvedRelation [STAFF], None[0m
[31m    'UnresolvedRelation [WORKS], None[0m
  
[31m  == Analyzed Logical Plan ==[0m
[31m  c0: double, c1: double[0m
[31m  Aggregate [sum(HOURS#60094) AS c0#60086,max(HOURS#60094) AS c1#60087][0m
[31m   Join Inner, None[0m
[31m    MetastoreRelation HU, staff, None[0m
[31m    MetastoreRelation HU, works, None[0m
  
[31m  == Optimized Logical Plan ==[0m
[31m  Aggregate [sum(HOURS#60094) AS c0#60086,max(HOURS#60094) AS c1#60087][0m
[31m   Project [HOURS#60094][0m
[31m    Join Inner, None[0m
[31m     Project[0m
[31m      MetastoreRelation HU, staff, None[0m
[31m     Project [HOURS#60094][0m
[31m      MetastoreRelation HU, works, None[0m
  
[31m  == Physical Plan ==[0m
[31m  TungstenAggregate(key=[], functions=[(sum(HOURS#60094),mode=Final,isDistinct=false),(max(HOURS#60094),mode=Final,isDistinct=false)], output=[c0#60086,c1#60087])[0m
[31m   TungstenExchange SinglePartition[0m
[31m    TungstenAggregate(key=[], functions=[(sum(HOURS#60094),mode=Partial,isDistinct=false),(max(HOURS#60094),mode=Partial,isDistinct=false)], output=[currentSum#60098,max#60100])[0m
[31m     TungstenProject [HOURS#60094][0m
[31m      CartesianProduct[0m
[31m       HiveTableScan (MetastoreRelation HU, staff, None)[0m
[31m       HiveTableScan [HOURS#60094], (MetastoreRelation HU, works, None)[0m
  
[31m  Code Generation: true[0m
[31m  c0	c1[0m
[31m  !== HIVE - 1 row(s) ==   == CATALYST - 1 row(s) ==[0m
[31m  !50	10                   50.0	10.0 (HiveComparisonTest.scala:433)[0m
Calcite parsing passed, start to transform. SELECT AVG(HOURS), MIN(HOURS) FROM  STAFF, WORKS WHERE STAFF.EMPNUM = 'E2' AND STAFF.EMPNUM = WORKS.EMPNUM
[32m- 0326[0m
Calcite parsing passed, start to transform. SELECT STAFF.EMPNUM, SUM(HOURS), MIN(HOURS) FROM  STAFF, WORKS GROUP BY STAFF.EMPNUM ORDER BY 1
Calcite parsing passed, start to transform. SELECT STAFF.EMPNUM, SUM(HOURS), MIN(HOURS) FROM  STAFF, WORKS GROUP BY STAFF.EMPNUM ORDER BY 1
Calcite parsing passed, start to transform. SELECT STAFF.EMPNUM, SUM(HOURS), MIN(HOURS) FROM  STAFF, WORKS GROUP BY STAFF.EMPNUM ORDER BY 1
[31m- 0327 *** FAILED ***[0m
[31m  Results do not match for 0327:[0m
[31m  == Parsed Logical Plan ==[0m
[31m  'Sort ['STAFF.EMPNUM ASC], true[0m
[31m   'Aggregate ['STAFF.EMPNUM], ['STAFF.EMPNUM,'SUM('HOURS) AS c1#61033,'MIN('HOURS) AS c2#61034][0m
[31m    'Join Inner, None[0m
[31m     'UnresolvedRelation [STAFF], None[0m
[31m     'UnresolvedRelation [WORKS], None[0m
  
[31m  == Analyzed Logical Plan ==[0m
[31m  EMPNUM: string, c1: double, c2: double[0m
[31m  Sort [EMPNUM#61035 ASC], true[0m
[31m   Aggregate [EMPNUM#61035], [EMPNUM#61035,sum(HOURS#61041) AS c1#61033,min(HOURS#61041) AS c2#61034][0m
[31m    Join Inner, None[0m
[31m     MetastoreRelation HU, staff, None[0m
[31m     MetastoreRelation HU, works, None[0m
  
[31m  == Optimized Logical Plan ==[0m
[31m  Sort [EMPNUM#61035 ASC], true[0m
[31m   Aggregate [EMPNUM#61035], [EMPNUM#61035,sum(HOURS#61041) AS c1#61033,min(HOURS#61041) AS c2#61034][0m
[31m    Project [EMPNUM#61035,HOURS#61041][0m
[31m     Join Inner, None[0m
[31m      Project [EMPNUM#61035][0m
[31m       MetastoreRelation HU, staff, None[0m
[31m      Project [HOURS#61041][0m
[31m       MetastoreRelation HU, works, None[0m
  
[31m  == Physical Plan ==[0m
[31m  TungstenSort [EMPNUM#61035 ASC], true, 0[0m
[31m   ConvertToUnsafe[0m
[31m    Exchange rangepartitioning(EMPNUM#61035 ASC)[0m
[31m     ConvertToSafe[0m
[31m      TungstenAggregate(key=[EMPNUM#61035], functions=[(sum(HOURS#61041),mode=Final,isDistinct=false),(min(HOURS#61041),mode=Final,isDistinct=false)], output=[EMPNUM#61035,c1#61033,c2#61034])[0m
[31m       TungstenExchange hashpartitioning(EMPNUM#61035)[0m
[31m        TungstenAggregate(key=[EMPNUM#61035], functions=[(sum(HOURS#61041),mode=Partial,isDistinct=false),(min(HOURS#61041),mode=Partial,isDistinct=false)], output=[EMPNUM#61035,currentSum#61046,min#61048])[0m
[31m         TungstenProject [EMPNUM#61035,HOURS#61041][0m
[31m          CartesianProduct[0m
[31m           HiveTableScan [EMPNUM#61035], (MetastoreRelation HU, staff, None)[0m
[31m           HiveTableScan [HOURS#61041], (MetastoreRelation HU, works, None)[0m
  
[31m  Code Generation: true[0m
[31m  EMPNUM	c1	c2[0m
[31m  !== HIVE - 5 row(s) ==   == CATALYST - 5 row(s) ==[0m
[31m  !E36	10	10               E36	10.0	10.0[0m
[31m  !E6	10	10                E6	10.0	10.0[0m
[31m  !E7	10	10                E7	10.0	10.0[0m
[31m  !E8	10	10                E8	10.0	10.0[0m
[31m  !E9	10	10                E9	10.0	10.0 (HiveComparisonTest.scala:433)[0m
Calcite parsing passed, start to transform. SELECT STAFF.EMPNUM, AVG(HOURS), MIN(HOURS) FROM  STAFF, WORKS WHERE STAFF.EMPNUM IN ('E1','E4','E3') AND STAFF.EMPNUM = WORKS.EMPNUM GROUP BY STAFF.EMPNUM HAVING COUNT(*) > 1 ORDER BY STAFF.EMPNUM
[32m- 0328[0m
Calcite parsing passed, start to transform. SELECT MAX(STAFF1.GRADE), SUM(STAFF1.GRADE) FROM STAFF1, STAFF GROUP BY STAFF1.CITY, STAFF.CITY
Calcite parsing passed, start to transform. SELECT MAX(STAFF1.GRADE), SUM(STAFF1.GRADE) FROM STAFF1, STAFF GROUP BY STAFF1.CITY, STAFF.CITY
Calcite parsing passed, start to transform. SELECT MAX(STAFF1.GRADE), SUM(STAFF1.GRADE) FROM STAFF1, STAFF GROUP BY STAFF1.CITY, STAFF.CITY
[31m- 0329 *** FAILED ***[0m
[31m  Results do not match for 0329:[0m
[31m  == Parsed Logical Plan ==[0m
[31m  'Aggregate ['STAFF1.CITY,'STAFF.CITY], ['MAX('STAFF1.GRADE) AS c0#61918,'SUM('STAFF1.GRADE) AS c1#61919][0m
[31m   'Join Inner, None[0m
[31m    'UnresolvedRelation [STAFF1], None[0m
[31m    'UnresolvedRelation [STAFF], None[0m
  
[31m  == Analyzed Logical Plan ==[0m
[31m  c0: double, c1: double[0m
[31m  Aggregate [CITY#61923,CITY#61927], [max(GRADE#61922) AS c0#61918,sum(GRADE#61922) AS c1#61919][0m
[31m   Join Inner, None[0m
[31m    MetastoreRelation HU, staff1, None[0m
[31m    MetastoreRelation HU, staff, None[0m
  
[31m  == Optimized Logical Plan ==[0m
[31m  Aggregate [CITY#61923,CITY#61927], [max(GRADE#61922) AS c0#61918,sum(GRADE#61922) AS c1#61919][0m
[31m   Project [CITY#61923,CITY#61927,GRADE#61922][0m
[31m    Join Inner, None[0m
[31m     Project [CITY#61923,GRADE#61922][0m
[31m      MetastoreRelation HU, staff1, None[0m
[31m     Project [CITY#61927][0m
[31m      MetastoreRelation HU, staff, None[0m
  
[31m  == Physical Plan ==[0m
[31m  TungstenAggregate(key=[CITY#61923,CITY#61927], functions=[(max(GRADE#61922),mode=Final,isDistinct=false),(sum(GRADE#61922),mode=Final,isDistinct=false)], output=[c0#61918,c1#61919])[0m
[31m   TungstenExchange hashpartitioning(CITY#61923,CITY#61927)[0m
[31m    TungstenAggregate(key=[CITY#61923,CITY#61927], functions=[(max(GRADE#61922),mode=Partial,isDistinct=false),(sum(GRADE#61922),mode=Partial,isDistinct=false)], output=[CITY#61923,CITY#61927,max#61931,currentSum#61933])[0m
[31m     TungstenProject [CITY#61923,CITY#61927,GRADE#61922][0m
[31m      CartesianProduct[0m
[31m       HiveTableScan [CITY#61923,GRADE#61922], (MetastoreRelation HU, staff1, None)[0m
[31m       HiveTableScan [CITY#61927], (MetastoreRelation HU, staff, None)[0m
  
[31m  Code Generation: true[0m
[31m  c0	c1[0m
[31m  !== HIVE - 25 row(s) ==   == CATALYST - 25 row(s) ==[0m
[31m  !15	15                    15.0	15.0[0m
[31m  !15	15                    15.0	15.0[0m
[31m  !15	15                    15.0	15.0[0m
[31m  !15	15                    15.0	15.0[0m
[31m  !15	15                    15.0	15.0[0m
[31m  !15	15                    15.0	15.0[0m
[31m  !15	15                    15.0	15.0[0m
[31m  !15	15                    15.0	15.0[0m
[31m  !15	15                    15.0	15.0[0m
[31m  !15	15                    15.0	15.0[0m
[31m  !15	15                    15.0	15.0[0m
[31m  !15	15                    15.0	15.0[0m
[31m  !15	15                    15.0	15.0[0m
[31m  !15	15                    15.0	15.0[0m
[31m  !15	15                    15.0	15.0[0m
[31m  !15	15                    15.0	15.0[0m
[31m  !15	15                    15.0	15.0[0m
[31m  !15	15                    15.0	15.0[0m
[31m  !15	15                    15.0	15.0[0m
[31m  !15	15                    15.0	15.0[0m
[31m   NULL	NULL                NULL	NULL[0m
[31m   NULL	NULL                NULL	NULL[0m
[31m   NULL	NULL                NULL	NULL[0m
[31m   NULL	NULL                NULL	NULL[0m
[31m   NULL	NULL                NULL	NULL (HiveComparisonTest.scala:433)[0m
Calcite parsing passed, start to transform. SELECT AVG(T1.COL4), AVG(T1.COL4 + T2.COL4), SUM(T2.COL4), COUNT(DISTINCT T1.COL4) FROM VTABLE T1, VTABLE T2
Calcite parsing passed, start to transform. SELECT AVG(T1.COL4), AVG(T1.COL4 + T2.COL4), SUM(T2.COL4), COUNT(DISTINCT T1.COL4) FROM VTABLE T1, VTABLE T2
Calcite parsing passed, start to transform. SELECT AVG(T1.COL4), AVG(T1.COL4 + T2.COL4), SUM(T2.COL4), COUNT(DISTINCT T1.COL4) FROM VTABLE T1, VTABLE T2
[31m- 0330 *** FAILED ***[0m
[31m  Results do not match for 0330:[0m
[31m  == Parsed Logical Plan ==[0m
[31m  'Project ['AVG('T1.COL4) AS c0#62291,'AVG(('T1.COL4 + 'T2.COL4)) AS c1#62292,'SUM('T2.COL4) AS c2#62293,COUNT(DISTINCT 'T1.COL4) AS c3#62294][0m
[31m   'Join Inner, None[0m
[31m    'UnresolvedRelation [VTABLE], Some(T1)[0m
[31m    'UnresolvedRelation [VTABLE], Some(T2)[0m
  
[31m  == Analyzed Logical Plan ==[0m
[31m  c0: double, c1: double, c2: double, c3: bigint[0m
[31m  Aggregate [avg(COL4#62298) AS c0#62291,avg((COL4#62298 + COL4#62303)) AS c1#62292,sum(COL4#62303) AS c2#62293,COUNT(DISTINCT COL4#62298) AS c3#62294L][0m
[31m   Join Inner, None[0m
[31m    MetastoreRelation HU, vtable, Some(T1)[0m
[31m    MetastoreRelation HU, vtable, Some(T2)[0m
  
[31m  == Optimized Logical Plan ==[0m
[31m  Aggregate [avg(COL4#62298) AS c0#62291,avg((COL4#62298 + COL4#62303)) AS c1#62292,sum(COL4#62303) AS c2#62293,COUNT(DISTINCT COL4#62298) AS c3#62294L][0m
[31m   Project [COL4#62298,COL4#62303][0m
[31m    Join Inner, None[0m
[31m     Project [COL4#62298][0m
[31m      MetastoreRelation HU, vtable, Some(T1)[0m
[31m     Project [COL4#62303][0m
[31m      MetastoreRelation HU, vtable, Some(T2)[0m
  
[31m  == Physical Plan ==[0m
[31m  TungstenAggregate(key=[], functions=[(average(COL4#62298),mode=Final,isDistinct=false),(average((COL4#62298 + COL4#62303)),mode=Final,isDistinct=false),(sum(COL4#62303),mode=Final,isDistinct=false),(count(COL4#62298),mode=Complete,isDistinct=true)], output=[c0#62291,c1#62292,c2#62293,c3#62294L])[0m
[31m   TungstenAggregate(key=[COL4#62298], functions=[(average(COL4#62298),mode=PartialMerge,isDistinct=false),(average((COL4#62298 + COL4#62303)),mode=PartialMerge,isDistinct=false),(sum(COL4#62303),mode=PartialMerge,isDistinct=false)], output=[COL4#62298,currentSum#62313,currentCount#62314L,currentSum#62317,currentCount#62318L,currentSum#62320])[0m
[31m    TungstenExchange SinglePartition[0m
[31m     TungstenAggregate(key=[COL4#62298], functions=[(average(COL4#62298),mode=Partial,isDistinct=false),(average((COL4#62298 + COL4#62303)),mode=Partial,isDistinct=false),(sum(COL4#62303),mode=Partial,isDistinct=false)], output=[COL4#62298,currentSum#62313,currentCount#62314L,currentSum#62317,currentCount#62318L,currentSum#62320])[0m
[31m      TungstenProject [COL4#62298,COL4#62303][0m
[31m       CartesianProduct[0m
[31m        HiveTableScan [COL4#62298], (MetastoreRelation HU, vtable, Some(T1))[0m
[31m        HiveTableScan [COL4#62303], (MetastoreRelation HU, vtable, Some(T2))[0m
  
[31m  Code Generation: true[0m
[31m  c0	c1	c2	c3[0m
[31m  !== HIVE - 1 row(s) ==                                                                        == CATALYST - 1 row(s) ==[0m
[31m  !86.09090909090909090909090909090909090909	172.181818181818181818181818181818181818	11364	5   86.0909090909091	172.1818181818182	11364.0	5 (HiveComparisonTest.scala:433)[0m
Calcite parsing passed, start to transform. SELECT SUM(COST), MAX(COST), MIN(COST) FROM STAFF_WORKS_DESIGN
[32m- 0331[0m
Calcite parsing passed, start to transform. SELECT COUNT (*) FROM STAFF WHERE EMPNUM IN (SELECT EMPNUM FROM WORKS)
error SELECT COUNT (*) FROM STAFF WHERE EMPNUM IN (SELECT EMPNUM FROM WORKS)[31m- 0332 ***  ***[0m
[31m  java.lang.RuntimeException: Parse failed.[0m
[31m  at scala.sys.package$.error(package.scala:27)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect$$anonfun$parse$1.apply(CalciteDialect.scala:33)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect$$anonfun$parse$1.apply(CalciteDialect.scala:32)[0m
[31m  at scala.Option.getOrElse(Option.scala:120)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect.parse(CalciteDialect.scala:31)[0m
[31m  at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)[0m
[31m  at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)[0m
[31m  at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:115)[0m
[31m  at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:114)[0m
[31m  at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)[0m
[31m  ...[0m
Calcite parsing passed, start to transform. SELECT COUNT (*) FROM STAFF1 WHERE EMPNUM IN (SELECT EMPNUM FROM WORKS)
error SELECT COUNT (*) FROM STAFF1 WHERE EMPNUM IN (SELECT EMPNUM FROM WORKS)[31m- 0333 ***  ***[0m
[31m  java.lang.RuntimeException: Parse failed.[0m
[31m  at scala.sys.package$.error(package.scala:27)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect$$anonfun$parse$1.apply(CalciteDialect.scala:33)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect$$anonfun$parse$1.apply(CalciteDialect.scala:32)[0m
[31m  at scala.Option.getOrElse(Option.scala:120)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect.parse(CalciteDialect.scala:31)[0m
[31m  at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)[0m
[31m  at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)[0m
[31m  at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:115)[0m
[31m  at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:114)[0m
[31m  at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)[0m
[31m  ...[0m
NoViableAltException(231@[])
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.function(HiveParser_IdentifiersParser.java:3544)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.atomExpression(HiveParser_IdentifiersParser.java:6280)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceFieldExpression(HiveParser_IdentifiersParser.java:6383)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceUnaryPrefixExpression(HiveParser_IdentifiersParser.java:6768)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceUnarySuffixExpression(HiveParser_IdentifiersParser.java:6828)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceBitwiseXorExpression(HiveParser_IdentifiersParser.java:7012)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceStarExpression(HiveParser_IdentifiersParser.java:7172)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedencePlusExpression(HiveParser_IdentifiersParser.java:7332)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceAmpersandExpression(HiveParser_IdentifiersParser.java:7483)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceBitwiseOrExpression(HiveParser_IdentifiersParser.java:7634)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceEqualExpression(HiveParser_IdentifiersParser.java:8290)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceNotExpression(HiveParser_IdentifiersParser.java:9177)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceAndExpression(HiveParser_IdentifiersParser.java:9296)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceOrExpression(HiveParser_IdentifiersParser.java:9455)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.expression(HiveParser_IdentifiersParser.java:6105)
	at org.apache.hadoop.hive.ql.parse.HiveParser.expression(HiveParser.java:45846)
	at org.apache.hadoop.hive.ql.parse.HiveParser_FromClauseParser.searchCondition(HiveParser_FromClauseParser.java:6637)
	at org.apache.hadoop.hive.ql.parse.HiveParser_FromClauseParser.whereClause(HiveParser_FromClauseParser.java:6545)
	at org.apache.hadoop.hive.ql.parse.HiveParser.whereClause(HiveParser.java:45849)
	at org.apache.hadoop.hive.ql.parse.HiveParser.selectStatement(HiveParser.java:41543)
	at org.apache.hadoop.hive.ql.parse.HiveParser.regularBody(HiveParser.java:41402)
	at org.apache.hadoop.hive.ql.parse.HiveParser.queryStatementExpressionBody(HiveParser.java:40413)
	at org.apache.hadoop.hive.ql.parse.HiveParser.queryStatementExpression(HiveParser.java:40283)
	at org.apache.hadoop.hive.ql.parse.HiveParser.execStatement(HiveParser.java:1590)
	at org.apache.hadoop.hive.ql.parse.HiveParser.statement(HiveParser.java:1109)
	at org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:202)
	at org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:166)
	at org.apache.spark.sql.hive.HiveQl$.getAst(HiveQl.scala:258)
	at org.apache.spark.sql.hive.HiveQl$.createPlan(HiveQl.scala:283)
	at org.apache.spark.sql.hive.ExtendedHiveQlParser$$anonfun$hiveQl$1.apply(ExtendedHiveQlParser.scala:41)
	at org.apache.spark.sql.hive.ExtendedHiveQlParser$$anonfun$hiveQl$1.apply(ExtendedHiveQlParser.scala:40)
	at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)
	at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:135)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)
	at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Failure.append(Parsers.scala:202)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)
	at scala.util.parsing.combinator.Parsers$$anon$2$$anonfun$apply$14.apply(Parsers.scala:891)
	at scala.util.parsing.combinator.Parsers$$anon$2$$anonfun$apply$14.apply(Parsers.scala:891)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)
	at scala.util.parsing.combinator.Parsers$$anon$2.apply(Parsers.scala:890)
	at scala.util.parsing.combinator.PackratParsers$$anon$1.apply(PackratParsers.scala:110)
	at org.apache.spark.sql.catalyst.AbstractSparkSQLParser.parse(AbstractSparkSQLParser.scala:34)
	at org.apache.spark.sql.hive.HiveQl$.parseSql(HiveQl.scala:276)
	at org.apache.spark.sql.hive.HiveQLDialect.parse(HiveContext.scala:62)
	at com.intel.ssg.bdt.spark.sql.CalciteDialect.getLogicalPlan(CalciteDialect.scala:54)
	at com.intel.ssg.bdt.spark.sql.CalciteDialect.parse(CalciteDialect.scala:31)
	at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)
	at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)
	at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:115)
	at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:114)
	at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)
	at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:135)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)
	at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Failure.append(Parsers.scala:202)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)
	at scala.util.parsing.combinator.Parsers$$anon$2$$anonfun$apply$14.apply(Parsers.scala:891)
	at scala.util.parsing.combinator.Parsers$$anon$2$$anonfun$apply$14.apply(Parsers.scala:891)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)
	at scala.util.parsing.combinator.Parsers$$anon$2.apply(Parsers.scala:890)
	at scala.util.parsing.combinator.PackratParsers$$anon$1.apply(PackratParsers.scala:110)
	at org.apache.spark.sql.catalyst.AbstractSparkSQLParser.parse(AbstractSparkSQLParser.scala:34)
	at org.apache.spark.sql.SQLContext$$anonfun$2.apply(SQLContext.scala:166)
	at org.apache.spark.sql.SQLContext$$anonfun$2.apply(SQLContext.scala:166)
	at org.apache.spark.sql.execution.datasources.DDLParser.parse(DDLParser.scala:42)
	at org.apache.spark.sql.SQLContext.parseSql(SQLContext.scala:189)
	at org.apache.spark.sql.hive.HiveContext.parseSql(HiveContext.scala:280)
	at org.apache.spark.sql.hive.test.TestHiveContext$QueryExecution.<init>(TestHive.scala:179)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1$$anonfun$30.apply(HiveComparisonTest.scala:303)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1$$anonfun$30.apply(HiveComparisonTest.scala:303)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:34)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:244)
	at scala.collection.AbstractTraversable.map(Traversable.scala:105)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1.apply$mcV$sp(HiveComparisonTest.scala:303)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1.apply(HiveComparisonTest.scala:240)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1.apply(HiveComparisonTest.scala:240)
	at org.scalatest.Transformer$$anonfun$apply$1.apply$mcV$sp(Transformer.scala:22)
	at org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)
	at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
	at org.scalatest.Transformer.apply(Transformer.scala:22)
	at org.scalatest.Transformer.apply(Transformer.scala:20)
	at org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:166)
	at org.apache.spark.SparkFunSuite.withFixture(SparkFunSuite.scala:42)
	at org.scalatest.FunSuiteLike$class.invokeWithFixture$1(FunSuiteLike.scala:163)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)
	at org.scalatest.FunSuiteLike$class.runTest(FunSuiteLike.scala:175)
	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.org$scalatest$BeforeAndAfter$$super$runTest(HiveCompatibilitySuite.scala:32)
	at org.scalatest.BeforeAndAfter$class.runTest(BeforeAndAfter.scala:200)
	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.runTest(HiveCompatibilitySuite.scala:32)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:413)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:401)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)
	at org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:396)
	at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:483)
	at org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:208)
	at org.scalatest.FunSuite.runTests(FunSuite.scala:1555)
	at org.scalatest.Suite$class.run(Suite.scala:1424)
	at org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.SuperEngine.runImpl(Engine.scala:545)
	at org.scalatest.FunSuiteLike$class.run(FunSuiteLike.scala:212)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest.org$scalatest$BeforeAndAfterAll$$super$run(HiveComparisonTest.scala:44)
	at org.scalatest.BeforeAndAfterAll$class.liftedTree1$1(BeforeAndAfterAll.scala:257)
	at org.scalatest.BeforeAndAfterAll$class.run(BeforeAndAfterAll.scala:256)
	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.org$scalatest$BeforeAndAfter$$super$run(HiveCompatibilitySuite.scala:32)
	at org.scalatest.BeforeAndAfter$class.run(BeforeAndAfter.scala:241)
	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.run(HiveCompatibilitySuite.scala:32)
	at org.scalatest.Suite$class.callExecuteOnSuite$1(Suite.scala:1492)
	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1528)
	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1526)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.scalatest.Suite$class.runNestedSuites(Suite.scala:1526)
	at org.scalatest.tools.DiscoverySuite.runNestedSuites(DiscoverySuite.scala:29)
	at org.scalatest.Suite$class.run(Suite.scala:1421)
	at org.scalatest.tools.DiscoverySuite.run(DiscoverySuite.scala:29)
	at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:55)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2563)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2557)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:2557)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1044)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1043)
	at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:2722)
	at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1043)
	at org.scalatest.tools.Runner$.main(Runner.scala:860)
	at org.scalatest.tools.Runner.main(Runner.scala)
[31m- 0334 *** FAILED ***[0m
[31m  org.apache.spark.sql.AnalysisException: cannot recognize input near 'SELECT' 'CITY' 'FROM' in function specification; line 1 pos 45[0m
[31m  at org.apache.spark.sql.hive.HiveQl$.createPlan(HiveQl.scala:296)[0m
[31m  at org.apache.spark.sql.hive.ExtendedHiveQlParser$$anonfun$hiveQl$1.apply(ExtendedHiveQlParser.scala:41)[0m
[31m  at org.apache.spark.sql.hive.ExtendedHiveQlParser$$anonfun$hiveQl$1.apply(ExtendedHiveQlParser.scala:40)[0m
[31m  at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)[0m
[31m  at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:135)[0m
[31m  at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)[0m
[31m  at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)[0m
[31m  at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)[0m
[31m  at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)[0m
[31m  at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)[0m
[31m  ...[0m
NoViableAltException(231@[])
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.function(HiveParser_IdentifiersParser.java:3544)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.atomExpression(HiveParser_IdentifiersParser.java:6280)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceFieldExpression(HiveParser_IdentifiersParser.java:6383)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceUnaryPrefixExpression(HiveParser_IdentifiersParser.java:6768)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceUnarySuffixExpression(HiveParser_IdentifiersParser.java:6828)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceBitwiseXorExpression(HiveParser_IdentifiersParser.java:7012)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceStarExpression(HiveParser_IdentifiersParser.java:7172)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedencePlusExpression(HiveParser_IdentifiersParser.java:7332)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceAmpersandExpression(HiveParser_IdentifiersParser.java:7483)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceBitwiseOrExpression(HiveParser_IdentifiersParser.java:7634)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceEqualExpression(HiveParser_IdentifiersParser.java:8290)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceNotExpression(HiveParser_IdentifiersParser.java:9177)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceAndExpression(HiveParser_IdentifiersParser.java:9296)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceOrExpression(HiveParser_IdentifiersParser.java:9455)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.expression(HiveParser_IdentifiersParser.java:6105)
	at org.apache.hadoop.hive.ql.parse.HiveParser.expression(HiveParser.java:45846)
	at org.apache.hadoop.hive.ql.parse.HiveParser_FromClauseParser.searchCondition(HiveParser_FromClauseParser.java:6637)
	at org.apache.hadoop.hive.ql.parse.HiveParser_FromClauseParser.whereClause(HiveParser_FromClauseParser.java:6545)
	at org.apache.hadoop.hive.ql.parse.HiveParser.whereClause(HiveParser.java:45849)
	at org.apache.hadoop.hive.ql.parse.HiveParser.selectStatement(HiveParser.java:41543)
	at org.apache.hadoop.hive.ql.parse.HiveParser.regularBody(HiveParser.java:41402)
	at org.apache.hadoop.hive.ql.parse.HiveParser.queryStatementExpressionBody(HiveParser.java:40413)
	at org.apache.hadoop.hive.ql.parse.HiveParser.queryStatementExpression(HiveParser.java:40283)
	at org.apache.hadoop.hive.ql.parse.HiveParser.execStatement(HiveParser.java:1590)
	at org.apache.hadoop.hive.ql.parse.HiveParser.statement(HiveParser.java:1109)
	at org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:202)
	at org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:166)
	at org.apache.spark.sql.hive.HiveQl$.getAst(HiveQl.scala:258)
	at org.apache.spark.sql.hive.HiveQl$.createPlan(HiveQl.scala:283)
	at org.apache.spark.sql.hive.ExtendedHiveQlParser$$anonfun$hiveQl$1.apply(ExtendedHiveQlParser.scala:41)
	at org.apache.spark.sql.hive.ExtendedHiveQlParser$$anonfun$hiveQl$1.apply(ExtendedHiveQlParser.scala:40)
	at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)
	at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:135)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)
	at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Failure.append(Parsers.scala:202)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)
	at scala.util.parsing.combinator.Parsers$$anon$2$$anonfun$apply$14.apply(Parsers.scala:891)
	at scala.util.parsing.combinator.Parsers$$anon$2$$anonfun$apply$14.apply(Parsers.scala:891)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)
	at scala.util.parsing.combinator.Parsers$$anon$2.apply(Parsers.scala:890)
	at scala.util.parsing.combinator.PackratParsers$$anon$1.apply(PackratParsers.scala:110)
	at org.apache.spark.sql.catalyst.AbstractSparkSQLParser.parse(AbstractSparkSQLParser.scala:34)
	at org.apache.spark.sql.hive.HiveQl$.parseSql(HiveQl.scala:276)
	at org.apache.spark.sql.hive.HiveQLDialect.parse(HiveContext.scala:62)
	at com.intel.ssg.bdt.spark.sql.CalciteDialect.getLogicalPlan(CalciteDialect.scala:54)
	at com.intel.ssg.bdt.spark.sql.CalciteDialect.parse(CalciteDialect.scala:31)
	at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)
	at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)
	at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:115)
	at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:114)
	at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)
	at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:135)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)
	at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Failure.append(Parsers.scala:202)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)
	at scala.util.parsing.combinator.Parsers$$anon$2$$anonfun$apply$14.apply(Parsers.scala:891)
	at scala.util.parsing.combinator.Parsers$$anon$2$$anonfun$apply$14.apply(Parsers.scala:891)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)
	at scala.util.parsing.combinator.Parsers$$anon$2.apply(Parsers.scala:890)
	at scala.util.parsing.combinator.PackratParsers$$anon$1.apply(PackratParsers.scala:110)
	at org.apache.spark.sql.catalyst.AbstractSparkSQLParser.parse(AbstractSparkSQLParser.scala:34)
	at org.apache.spark.sql.SQLContext$$anonfun$2.apply(SQLContext.scala:166)
	at org.apache.spark.sql.SQLContext$$anonfun$2.apply(SQLContext.scala:166)
	at org.apache.spark.sql.execution.datasources.DDLParser.parse(DDLParser.scala:42)
	at org.apache.spark.sql.SQLContext.parseSql(SQLContext.scala:189)
	at org.apache.spark.sql.hive.HiveContext.parseSql(HiveContext.scala:280)
	at org.apache.spark.sql.hive.test.TestHiveContext$QueryExecution.<init>(TestHive.scala:179)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1$$anonfun$30.apply(HiveComparisonTest.scala:303)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1$$anonfun$30.apply(HiveComparisonTest.scala:303)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:34)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:244)
	at scala.collection.AbstractTraversable.map(Traversable.scala:105)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1.apply$mcV$sp(HiveComparisonTest.scala:303)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1.apply(HiveComparisonTest.scala:240)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1.apply(HiveComparisonTest.scala:240)
	at org.scalatest.Transformer$$anonfun$apply$1.apply$mcV$sp(Transformer.scala:22)
	at org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)
	at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
	at org.scalatest.Transformer.apply(Transformer.scala:22)
	at org.scalatest.Transformer.apply(Transformer.scala:20)
	at org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:166)
	at org.apache.spark.SparkFunSuite.withFixture(SparkFunSuite.scala:42)
	at org.scalatest.FunSuiteLike$class.invokeWithFixture$1(FunSuiteLike.scala:163)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)
	at org.scalatest.FunSuiteLike$class.runTest(FunSuiteLike.scala:175)
	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.org$scalatest$BeforeAndAfter$$super$runTest(HiveCompatibilitySuite.scala:32)
	at org.scalatest.BeforeAndAfter$class.runTest(BeforeAndAfter.scala:200)
	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.runTest(HiveCompatibilitySuite.scala:32)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:413)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:401)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)
	at org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:396)
	at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:483)
	at org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:208)
	at org.scalatest.FunSuite.runTests(FunSuite.scala:1555)
	at org.scalatest.Suite$class.run(Suite.scala:1424)
	at org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.SuperEngine.runImpl(Engine.scala:545)
	at org.scalatest.FunSuiteLike$class.run(FunSuiteLike.scala:212)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest.org$scalatest$BeforeAndAfterAll$$super$run(HiveComparisonTest.scala:44)
	at org.scalatest.BeforeAndAfterAll$class.liftedTree1$1(BeforeAndAfterAll.scala:257)
	at org.scalatest.BeforeAndAfterAll$class.run(BeforeAndAfterAll.scala:256)
	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.org$scalatest$BeforeAndAfter$$super$run(HiveCompatibilitySuite.scala:32)
	at org.scalatest.BeforeAndAfter$class.run(BeforeAndAfter.scala:241)
	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.run(HiveCompatibilitySuite.scala:32)
	at org.scalatest.Suite$class.callExecuteOnSuite$1(Suite.scala:1492)
	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1528)
	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1526)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.scalatest.Suite$class.runNestedSuites(Suite.scala:1526)
	at org.scalatest.tools.DiscoverySuite.runNestedSuites(DiscoverySuite.scala:29)
	at org.scalatest.Suite$class.run(Suite.scala:1421)
	at org.scalatest.tools.DiscoverySuite.run(DiscoverySuite.scala:29)
	at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:55)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2563)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2557)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:2557)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1044)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1043)
	at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:2722)
	at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1043)
	at org.scalatest.tools.Runner$.main(Runner.scala:860)
	at org.scalatest.tools.Runner.main(Runner.scala)
[31m- 0335 *** FAILED ***[0m
[31m  org.apache.spark.sql.AnalysisException: cannot recognize input near 'SELECT' 'CITY' 'FROM' in function specification; line 1 pos 46[0m
[31m  at org.apache.spark.sql.hive.HiveQl$.createPlan(HiveQl.scala:296)[0m
[31m  at org.apache.spark.sql.hive.ExtendedHiveQlParser$$anonfun$hiveQl$1.apply(ExtendedHiveQlParser.scala:41)[0m
[31m  at org.apache.spark.sql.hive.ExtendedHiveQlParser$$anonfun$hiveQl$1.apply(ExtendedHiveQlParser.scala:40)[0m
[31m  at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)[0m
[31m  at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:135)[0m
[31m  at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)[0m
[31m  at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)[0m
[31m  at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)[0m
[31m  at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)[0m
[31m  at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)[0m
[31m  ...[0m
NoViableAltException(231@[])
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.function(HiveParser_IdentifiersParser.java:3544)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.atomExpression(HiveParser_IdentifiersParser.java:6280)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceFieldExpression(HiveParser_IdentifiersParser.java:6383)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceUnaryPrefixExpression(HiveParser_IdentifiersParser.java:6768)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceUnarySuffixExpression(HiveParser_IdentifiersParser.java:6828)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceBitwiseXorExpression(HiveParser_IdentifiersParser.java:7012)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceStarExpression(HiveParser_IdentifiersParser.java:7172)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedencePlusExpression(HiveParser_IdentifiersParser.java:7332)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceAmpersandExpression(HiveParser_IdentifiersParser.java:7483)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceBitwiseOrExpression(HiveParser_IdentifiersParser.java:7634)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceEqualExpression(HiveParser_IdentifiersParser.java:8290)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceNotExpression(HiveParser_IdentifiersParser.java:9177)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceAndExpression(HiveParser_IdentifiersParser.java:9296)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceOrExpression(HiveParser_IdentifiersParser.java:9455)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.expression(HiveParser_IdentifiersParser.java:6105)
	at org.apache.hadoop.hive.ql.parse.HiveParser.expression(HiveParser.java:45846)
	at org.apache.hadoop.hive.ql.parse.HiveParser_FromClauseParser.searchCondition(HiveParser_FromClauseParser.java:6637)
	at org.apache.hadoop.hive.ql.parse.HiveParser_FromClauseParser.whereClause(HiveParser_FromClauseParser.java:6545)
	at org.apache.hadoop.hive.ql.parse.HiveParser.whereClause(HiveParser.java:45849)
	at org.apache.hadoop.hive.ql.parse.HiveParser.selectStatement(HiveParser.java:41543)
	at org.apache.hadoop.hive.ql.parse.HiveParser.regularBody(HiveParser.java:41402)
	at org.apache.hadoop.hive.ql.parse.HiveParser.queryStatementExpressionBody(HiveParser.java:40413)
	at org.apache.hadoop.hive.ql.parse.HiveParser.queryStatementExpression(HiveParser.java:40283)
	at org.apache.hadoop.hive.ql.parse.HiveParser.execStatement(HiveParser.java:1590)
	at org.apache.hadoop.hive.ql.parse.HiveParser.statement(HiveParser.java:1109)
	at org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:202)
	at org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:166)
	at org.apache.spark.sql.hive.HiveQl$.getAst(HiveQl.scala:258)
	at org.apache.spark.sql.hive.HiveQl$.createPlan(HiveQl.scala:283)
	at org.apache.spark.sql.hive.ExtendedHiveQlParser$$anonfun$hiveQl$1.apply(ExtendedHiveQlParser.scala:41)
	at org.apache.spark.sql.hive.ExtendedHiveQlParser$$anonfun$hiveQl$1.apply(ExtendedHiveQlParser.scala:40)
	at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)
	at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:135)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)
	at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Failure.append(Parsers.scala:202)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)
	at scala.util.parsing.combinator.Parsers$$anon$2$$anonfun$apply$14.apply(Parsers.scala:891)
	at scala.util.parsing.combinator.Parsers$$anon$2$$anonfun$apply$14.apply(Parsers.scala:891)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)
	at scala.util.parsing.combinator.Parsers$$anon$2.apply(Parsers.scala:890)
	at scala.util.parsing.combinator.PackratParsers$$anon$1.apply(PackratParsers.scala:110)
	at org.apache.spark.sql.catalyst.AbstractSparkSQLParser.parse(AbstractSparkSQLParser.scala:34)
	at org.apache.spark.sql.hive.HiveQl$.parseSql(HiveQl.scala:276)
	at org.apache.spark.sql.hive.HiveQLDialect.parse(HiveContext.scala:62)
	at com.intel.ssg.bdt.spark.sql.CalciteDialect.getLogicalPlan(CalciteDialect.scala:54)
	at com.intel.ssg.bdt.spark.sql.CalciteDialect.parse(CalciteDialect.scala:31)
	at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)
	at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)
	at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:115)
	at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:114)
	at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)
	at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:135)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)
	at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Failure.append(Parsers.scala:202)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)
	at scala.util.parsing.combinator.Parsers$$anon$2$$anonfun$apply$14.apply(Parsers.scala:891)
	at scala.util.parsing.combinator.Parsers$$anon$2$$anonfun$apply$14.apply(Parsers.scala:891)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)
	at scala.util.parsing.combinator.Parsers$$anon$2.apply(Parsers.scala:890)
	at scala.util.parsing.combinator.PackratParsers$$anon$1.apply(PackratParsers.scala:110)
	at org.apache.spark.sql.catalyst.AbstractSparkSQLParser.parse(AbstractSparkSQLParser.scala:34)
	at org.apache.spark.sql.SQLContext$$anonfun$2.apply(SQLContext.scala:166)
	at org.apache.spark.sql.SQLContext$$anonfun$2.apply(SQLContext.scala:166)
	at org.apache.spark.sql.execution.datasources.DDLParser.parse(DDLParser.scala:42)
	at org.apache.spark.sql.SQLContext.parseSql(SQLContext.scala:189)
	at org.apache.spark.sql.hive.HiveContext.parseSql(HiveContext.scala:280)
	at org.apache.spark.sql.hive.test.TestHiveContext$QueryExecution.<init>(TestHive.scala:179)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1$$anonfun$30.apply(HiveComparisonTest.scala:303)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1$$anonfun$30.apply(HiveComparisonTest.scala:303)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:34)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:244)
	at scala.collection.AbstractTraversable.map(Traversable.scala:105)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1.apply$mcV$sp(HiveComparisonTest.scala:303)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1.apply(HiveComparisonTest.scala:240)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1.apply(HiveComparisonTest.scala:240)
	at org.scalatest.Transformer$$anonfun$apply$1.apply$mcV$sp(Transformer.scala:22)
	at org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)
	at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
	at org.scalatest.Transformer.apply(Transformer.scala:22)
	at org.scalatest.Transformer.apply(Transformer.scala:20)
	at org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:166)
	at org.apache.spark.SparkFunSuite.withFixture(SparkFunSuite.scala:42)
	at org.scalatest.FunSuiteLike$class.invokeWithFixture$1(FunSuiteLike.scala:163)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)
	at org.scalatest.FunSuiteLike$class.runTest(FunSuiteLike.scala:175)
	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.org$scalatest$BeforeAndAfter$$super$runTest(HiveCompatibilitySuite.scala:32)
	at org.scalatest.BeforeAndAfter$class.runTest(BeforeAndAfter.scala:200)
	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.runTest(HiveCompatibilitySuite.scala:32)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:413)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:401)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)
	at org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:396)
	at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:483)
	at org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:208)
	at org.scalatest.FunSuite.runTests(FunSuite.scala:1555)
	at org.scalatest.Suite$class.run(Suite.scala:1424)
	at org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.SuperEngine.runImpl(Engine.scala:545)
	at org.scalatest.FunSuiteLike$class.run(FunSuiteLike.scala:212)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest.org$scalatest$BeforeAndAfterAll$$super$run(HiveComparisonTest.scala:44)
	at org.scalatest.BeforeAndAfterAll$class.liftedTree1$1(BeforeAndAfterAll.scala:257)
	at org.scalatest.BeforeAndAfterAll$class.run(BeforeAndAfterAll.scala:256)
	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.org$scalatest$BeforeAndAfter$$super$run(HiveCompatibilitySuite.scala:32)
	at org.scalatest.BeforeAndAfter$class.run(BeforeAndAfter.scala:241)
	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.run(HiveCompatibilitySuite.scala:32)
	at org.scalatest.Suite$class.callExecuteOnSuite$1(Suite.scala:1492)
	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1528)
	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1526)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.scalatest.Suite$class.runNestedSuites(Suite.scala:1526)
	at org.scalatest.tools.DiscoverySuite.runNestedSuites(DiscoverySuite.scala:29)
	at org.scalatest.Suite$class.run(Suite.scala:1421)
	at org.scalatest.tools.DiscoverySuite.run(DiscoverySuite.scala:29)
	at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:55)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2563)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2557)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:2557)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1044)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1043)
	at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:2722)
	at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1043)
	at org.scalatest.tools.Runner$.main(Runner.scala:860)
	at org.scalatest.tools.Runner.main(Runner.scala)
[31m- 0336 *** FAILED ***[0m
[31m  org.apache.spark.sql.AnalysisException: cannot recognize input near 'SELECT' 'CITY' 'FROM' in function specification; line 1 pos 45[0m
[31m  at org.apache.spark.sql.hive.HiveQl$.createPlan(HiveQl.scala:296)[0m
[31m  at org.apache.spark.sql.hive.ExtendedHiveQlParser$$anonfun$hiveQl$1.apply(ExtendedHiveQlParser.scala:41)[0m
[31m  at org.apache.spark.sql.hive.ExtendedHiveQlParser$$anonfun$hiveQl$1.apply(ExtendedHiveQlParser.scala:40)[0m
[31m  at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)[0m
[31m  at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:135)[0m
[31m  at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)[0m
[31m  at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)[0m
[31m  at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)[0m
[31m  at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)[0m
[31m  at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)[0m
[31m  ...[0m
NoViableAltException(231@[])
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.function(HiveParser_IdentifiersParser.java:3544)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.atomExpression(HiveParser_IdentifiersParser.java:6280)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceFieldExpression(HiveParser_IdentifiersParser.java:6383)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceUnaryPrefixExpression(HiveParser_IdentifiersParser.java:6768)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceUnarySuffixExpression(HiveParser_IdentifiersParser.java:6828)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceBitwiseXorExpression(HiveParser_IdentifiersParser.java:7012)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceStarExpression(HiveParser_IdentifiersParser.java:7172)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedencePlusExpression(HiveParser_IdentifiersParser.java:7332)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceAmpersandExpression(HiveParser_IdentifiersParser.java:7483)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceBitwiseOrExpression(HiveParser_IdentifiersParser.java:7634)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceEqualExpression(HiveParser_IdentifiersParser.java:8290)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceNotExpression(HiveParser_IdentifiersParser.java:9177)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceAndExpression(HiveParser_IdentifiersParser.java:9296)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceOrExpression(HiveParser_IdentifiersParser.java:9455)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.expression(HiveParser_IdentifiersParser.java:6105)
	at org.apache.hadoop.hive.ql.parse.HiveParser.expression(HiveParser.java:45846)
	at org.apache.hadoop.hive.ql.parse.HiveParser_FromClauseParser.searchCondition(HiveParser_FromClauseParser.java:6637)
	at org.apache.hadoop.hive.ql.parse.HiveParser_FromClauseParser.whereClause(HiveParser_FromClauseParser.java:6545)
	at org.apache.hadoop.hive.ql.parse.HiveParser.whereClause(HiveParser.java:45849)
	at org.apache.hadoop.hive.ql.parse.HiveParser.selectStatement(HiveParser.java:41543)
	at org.apache.hadoop.hive.ql.parse.HiveParser.regularBody(HiveParser.java:41402)
	at org.apache.hadoop.hive.ql.parse.HiveParser.queryStatementExpressionBody(HiveParser.java:40413)
	at org.apache.hadoop.hive.ql.parse.HiveParser.queryStatementExpression(HiveParser.java:40283)
	at org.apache.hadoop.hive.ql.parse.HiveParser.execStatement(HiveParser.java:1590)
	at org.apache.hadoop.hive.ql.parse.HiveParser.statement(HiveParser.java:1109)
	at org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:202)
	at org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:166)
	at org.apache.spark.sql.hive.HiveQl$.getAst(HiveQl.scala:258)
	at org.apache.spark.sql.hive.HiveQl$.createPlan(HiveQl.scala:283)
	at org.apache.spark.sql.hive.ExtendedHiveQlParser$$anonfun$hiveQl$1.apply(ExtendedHiveQlParser.scala:41)
	at org.apache.spark.sql.hive.ExtendedHiveQlParser$$anonfun$hiveQl$1.apply(ExtendedHiveQlParser.scala:40)
	at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)
	at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:135)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)
	at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Failure.append(Parsers.scala:202)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)
	at scala.util.parsing.combinator.Parsers$$anon$2$$anonfun$apply$14.apply(Parsers.scala:891)
	at scala.util.parsing.combinator.Parsers$$anon$2$$anonfun$apply$14.apply(Parsers.scala:891)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)
	at scala.util.parsing.combinator.Parsers$$anon$2.apply(Parsers.scala:890)
	at scala.util.parsing.combinator.PackratParsers$$anon$1.apply(PackratParsers.scala:110)
	at org.apache.spark.sql.catalyst.AbstractSparkSQLParser.parse(AbstractSparkSQLParser.scala:34)
	at org.apache.spark.sql.hive.HiveQl$.parseSql(HiveQl.scala:276)
	at org.apache.spark.sql.hive.HiveQLDialect.parse(HiveContext.scala:62)
	at com.intel.ssg.bdt.spark.sql.CalciteDialect.getLogicalPlan(CalciteDialect.scala:54)
	at com.intel.ssg.bdt.spark.sql.CalciteDialect.parse(CalciteDialect.scala:31)
	at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)
	at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)
	at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:115)
	at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:114)
	at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)
	at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:135)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)
	at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Failure.append(Parsers.scala:202)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)
	at scala.util.parsing.combinator.Parsers$$anon$2$$anonfun$apply$14.apply(Parsers.scala:891)
	at scala.util.parsing.combinator.Parsers$$anon$2$$anonfun$apply$14.apply(Parsers.scala:891)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)
	at scala.util.parsing.combinator.Parsers$$anon$2.apply(Parsers.scala:890)
	at scala.util.parsing.combinator.PackratParsers$$anon$1.apply(PackratParsers.scala:110)
	at org.apache.spark.sql.catalyst.AbstractSparkSQLParser.parse(AbstractSparkSQLParser.scala:34)
	at org.apache.spark.sql.SQLContext$$anonfun$2.apply(SQLContext.scala:166)
	at org.apache.spark.sql.SQLContext$$anonfun$2.apply(SQLContext.scala:166)
	at org.apache.spark.sql.execution.datasources.DDLParser.parse(DDLParser.scala:42)
	at org.apache.spark.sql.SQLContext.parseSql(SQLContext.scala:189)
	at org.apache.spark.sql.hive.HiveContext.parseSql(HiveContext.scala:280)
	at org.apache.spark.sql.hive.test.TestHiveContext$QueryExecution.<init>(TestHive.scala:179)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1$$anonfun$30.apply(HiveComparisonTest.scala:303)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1$$anonfun$30.apply(HiveComparisonTest.scala:303)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:34)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:244)
	at scala.collection.AbstractTraversable.map(Traversable.scala:105)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1.apply$mcV$sp(HiveComparisonTest.scala:303)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1.apply(HiveComparisonTest.scala:240)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1.apply(HiveComparisonTest.scala:240)
	at org.scalatest.Transformer$$anonfun$apply$1.apply$mcV$sp(Transformer.scala:22)
	at org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)
	at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
	at org.scalatest.Transformer.apply(Transformer.scala:22)
	at org.scalatest.Transformer.apply(Transformer.scala:20)
	at org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:166)
	at org.apache.spark.SparkFunSuite.withFixture(SparkFunSuite.scala:42)
	at org.scalatest.FunSuiteLike$class.invokeWithFixture$1(FunSuiteLike.scala:163)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)
	at org.scalatest.FunSuiteLike$class.runTest(FunSuiteLike.scala:175)
	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.org$scalatest$BeforeAndAfter$$super$runTest(HiveCompatibilitySuite.scala:32)
	at org.scalatest.BeforeAndAfter$class.runTest(BeforeAndAfter.scala:200)
	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.runTest(HiveCompatibilitySuite.scala:32)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:413)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:401)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)
	at org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:396)
	at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:483)
	at org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:208)
	at org.scalatest.FunSuite.runTests(FunSuite.scala:1555)
	at org.scalatest.Suite$class.run(Suite.scala:1424)
	at org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.SuperEngine.runImpl(Engine.scala:545)
	at org.scalatest.FunSuiteLike$class.run(FunSuiteLike.scala:212)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest.org$scalatest$BeforeAndAfterAll$$super$run(HiveComparisonTest.scala:44)
	at org.scalatest.BeforeAndAfterAll$class.liftedTree1$1(BeforeAndAfterAll.scala:257)
	at org.scalatest.BeforeAndAfterAll$class.run(BeforeAndAfterAll.scala:256)
	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.org$scalatest$BeforeAndAfter$$super$run(HiveCompatibilitySuite.scala:32)
	at org.scalatest.BeforeAndAfter$class.run(BeforeAndAfter.scala:241)
	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.run(HiveCompatibilitySuite.scala:32)
	at org.scalatest.Suite$class.callExecuteOnSuite$1(Suite.scala:1492)
	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1528)
	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1526)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.scalatest.Suite$class.runNestedSuites(Suite.scala:1526)
	at org.scalatest.tools.DiscoverySuite.runNestedSuites(DiscoverySuite.scala:29)
	at org.scalatest.Suite$class.run(Suite.scala:1421)
	at org.scalatest.tools.DiscoverySuite.run(DiscoverySuite.scala:29)
	at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:55)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2563)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2557)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:2557)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1044)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1043)
	at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:2722)
	at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1043)
	at org.scalatest.tools.Runner$.main(Runner.scala:860)
	at org.scalatest.tools.Runner.main(Runner.scala)
[31m- 0337 *** FAILED ***[0m
[31m  org.apache.spark.sql.AnalysisException: cannot recognize input near 'SELECT' 'CITY' 'FROM' in function specification; line 1 pos 46[0m
[31m  at org.apache.spark.sql.hive.HiveQl$.createPlan(HiveQl.scala:296)[0m
[31m  at org.apache.spark.sql.hive.ExtendedHiveQlParser$$anonfun$hiveQl$1.apply(ExtendedHiveQlParser.scala:41)[0m
[31m  at org.apache.spark.sql.hive.ExtendedHiveQlParser$$anonfun$hiveQl$1.apply(ExtendedHiveQlParser.scala:40)[0m
[31m  at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)[0m
[31m  at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:135)[0m
[31m  at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)[0m
[31m  at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)[0m
[31m  at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)[0m
[31m  at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)[0m
[31m  at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)[0m
[31m  ...[0m
NoViableAltException(231@[])
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.function(HiveParser_IdentifiersParser.java:3544)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.atomExpression(HiveParser_IdentifiersParser.java:6280)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceFieldExpression(HiveParser_IdentifiersParser.java:6383)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceUnaryPrefixExpression(HiveParser_IdentifiersParser.java:6768)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceUnarySuffixExpression(HiveParser_IdentifiersParser.java:6828)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceBitwiseXorExpression(HiveParser_IdentifiersParser.java:7012)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceStarExpression(HiveParser_IdentifiersParser.java:7172)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedencePlusExpression(HiveParser_IdentifiersParser.java:7332)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceAmpersandExpression(HiveParser_IdentifiersParser.java:7483)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceBitwiseOrExpression(HiveParser_IdentifiersParser.java:7634)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceEqualExpression(HiveParser_IdentifiersParser.java:8290)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceNotExpression(HiveParser_IdentifiersParser.java:9177)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceAndExpression(HiveParser_IdentifiersParser.java:9296)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceOrExpression(HiveParser_IdentifiersParser.java:9455)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.expression(HiveParser_IdentifiersParser.java:6105)
	at org.apache.hadoop.hive.ql.parse.HiveParser.expression(HiveParser.java:45846)
	at org.apache.hadoop.hive.ql.parse.HiveParser_FromClauseParser.searchCondition(HiveParser_FromClauseParser.java:6637)
	at org.apache.hadoop.hive.ql.parse.HiveParser_FromClauseParser.whereClause(HiveParser_FromClauseParser.java:6545)
	at org.apache.hadoop.hive.ql.parse.HiveParser.whereClause(HiveParser.java:45849)
	at org.apache.hadoop.hive.ql.parse.HiveParser.selectStatement(HiveParser.java:41543)
	at org.apache.hadoop.hive.ql.parse.HiveParser.regularBody(HiveParser.java:41402)
	at org.apache.hadoop.hive.ql.parse.HiveParser.queryStatementExpressionBody(HiveParser.java:40413)
	at org.apache.hadoop.hive.ql.parse.HiveParser.queryStatementExpression(HiveParser.java:40283)
	at org.apache.hadoop.hive.ql.parse.HiveParser.execStatement(HiveParser.java:1590)
	at org.apache.hadoop.hive.ql.parse.HiveParser.statement(HiveParser.java:1109)
	at org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:202)
	at org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:166)
	at org.apache.spark.sql.hive.HiveQl$.getAst(HiveQl.scala:258)
	at org.apache.spark.sql.hive.HiveQl$.createPlan(HiveQl.scala:283)
	at org.apache.spark.sql.hive.ExtendedHiveQlParser$$anonfun$hiveQl$1.apply(ExtendedHiveQlParser.scala:41)
	at org.apache.spark.sql.hive.ExtendedHiveQlParser$$anonfun$hiveQl$1.apply(ExtendedHiveQlParser.scala:40)
	at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)
	at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:135)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)
	at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Failure.append(Parsers.scala:202)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)
	at scala.util.parsing.combinator.Parsers$$anon$2$$anonfun$apply$14.apply(Parsers.scala:891)
	at scala.util.parsing.combinator.Parsers$$anon$2$$anonfun$apply$14.apply(Parsers.scala:891)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)
	at scala.util.parsing.combinator.Parsers$$anon$2.apply(Parsers.scala:890)
	at scala.util.parsing.combinator.PackratParsers$$anon$1.apply(PackratParsers.scala:110)
	at org.apache.spark.sql.catalyst.AbstractSparkSQLParser.parse(AbstractSparkSQLParser.scala:34)
	at org.apache.spark.sql.hive.HiveQl$.parseSql(HiveQl.scala:276)
	at org.apache.spark.sql.hive.HiveQLDialect.parse(HiveContext.scala:62)
	at com.intel.ssg.bdt.spark.sql.CalciteDialect.getLogicalPlan(CalciteDialect.scala:54)
	at com.intel.ssg.bdt.spark.sql.CalciteDialect.parse(CalciteDialect.scala:31)
	at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)
	at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)
	at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:115)
	at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:114)
	at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)
	at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:135)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)
	at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Failure.append(Parsers.scala:202)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)
	at scala.util.parsing.combinator.Parsers$$anon$2$$anonfun$apply$14.apply(Parsers.scala:891)
	at scala.util.parsing.combinator.Parsers$$anon$2$$anonfun$apply$14.apply(Parsers.scala:891)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)
	at scala.util.parsing.combinator.Parsers$$anon$2.apply(Parsers.scala:890)
	at scala.util.parsing.combinator.PackratParsers$$anon$1.apply(PackratParsers.scala:110)
	at org.apache.spark.sql.catalyst.AbstractSparkSQLParser.parse(AbstractSparkSQLParser.scala:34)
	at org.apache.spark.sql.SQLContext$$anonfun$2.apply(SQLContext.scala:166)
	at org.apache.spark.sql.SQLContext$$anonfun$2.apply(SQLContext.scala:166)
	at org.apache.spark.sql.execution.datasources.DDLParser.parse(DDLParser.scala:42)
	at org.apache.spark.sql.SQLContext.parseSql(SQLContext.scala:189)
	at org.apache.spark.sql.hive.HiveContext.parseSql(HiveContext.scala:280)
	at org.apache.spark.sql.hive.test.TestHiveContext$QueryExecution.<init>(TestHive.scala:179)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1$$anonfun$30.apply(HiveComparisonTest.scala:303)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1$$anonfun$30.apply(HiveComparisonTest.scala:303)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:34)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:244)
	at scala.collection.AbstractTraversable.map(Traversable.scala:105)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1.apply$mcV$sp(HiveComparisonTest.scala:303)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1.apply(HiveComparisonTest.scala:240)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1.apply(HiveComparisonTest.scala:240)
	at org.scalatest.Transformer$$anonfun$apply$1.apply$mcV$sp(Transformer.scala:22)
	at org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)
	at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
	at org.scalatest.Transformer.apply(Transformer.scala:22)
	at org.scalatest.Transformer.apply(Transformer.scala:20)
	at org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:166)
	at org.apache.spark.SparkFunSuite.withFixture(SparkFunSuite.scala:42)
	at org.scalatest.FunSuiteLike$class.invokeWithFixture$1(FunSuiteLike.scala:163)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)
	at org.scalatest.FunSuiteLike$class.runTest(FunSuiteLike.scala:175)
	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.org$scalatest$BeforeAndAfter$$super$runTest(HiveCompatibilitySuite.scala:32)
	at org.scalatest.BeforeAndAfter$class.runTest(BeforeAndAfter.scala:200)
	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.runTest(HiveCompatibilitySuite.scala:32)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:413)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:401)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)
	at org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:396)
	at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:483)
	at org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:208)
	at org.scalatest.FunSuite.runTests(FunSuite.scala:1555)
	at org.scalatest.Suite$class.run(Suite.scala:1424)
	at org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.SuperEngine.runImpl(Engine.scala:545)
	at org.scalatest.FunSuiteLike$class.run(FunSuiteLike.scala:212)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest.org$scalatest$BeforeAndAfterAll$$super$run(HiveComparisonTest.scala:44)
	at org.scalatest.BeforeAndAfterAll$class.liftedTree1$1(BeforeAndAfterAll.scala:257)
	at org.scalatest.BeforeAndAfterAll$class.run(BeforeAndAfterAll.scala:256)
	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.org$scalatest$BeforeAndAfter$$super$run(HiveCompatibilitySuite.scala:32)
	at org.scalatest.BeforeAndAfter$class.run(BeforeAndAfter.scala:241)
	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.run(HiveCompatibilitySuite.scala:32)
	at org.scalatest.Suite$class.callExecuteOnSuite$1(Suite.scala:1492)
	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1528)
	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1526)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.scalatest.Suite$class.runNestedSuites(Suite.scala:1526)
	at org.scalatest.tools.DiscoverySuite.runNestedSuites(DiscoverySuite.scala:29)
	at org.scalatest.Suite$class.run(Suite.scala:1421)
	at org.scalatest.tools.DiscoverySuite.run(DiscoverySuite.scala:29)
	at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:55)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2563)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2557)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:2557)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1044)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1043)
	at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:2722)
	at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1043)
	at org.scalatest.tools.Runner$.main(Runner.scala:860)
	at org.scalatest.tools.Runner.main(Runner.scala)
[31m- 0338 *** FAILED ***[0m
[31m  org.apache.spark.sql.AnalysisException: cannot recognize input near 'SELECT' 'CITY' 'FROM' in function specification; line 1 pos 46[0m
[31m  at org.apache.spark.sql.hive.HiveQl$.createPlan(HiveQl.scala:296)[0m
[31m  at org.apache.spark.sql.hive.ExtendedHiveQlParser$$anonfun$hiveQl$1.apply(ExtendedHiveQlParser.scala:41)[0m
[31m  at org.apache.spark.sql.hive.ExtendedHiveQlParser$$anonfun$hiveQl$1.apply(ExtendedHiveQlParser.scala:40)[0m
[31m  at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)[0m
[31m  at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:135)[0m
[31m  at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)[0m
[31m  at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)[0m
[31m  at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)[0m
[31m  at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)[0m
[31m  at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)[0m
[31m  ...[0m
NoViableAltException(231@[])
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.function(HiveParser_IdentifiersParser.java:3544)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.atomExpression(HiveParser_IdentifiersParser.java:6280)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceFieldExpression(HiveParser_IdentifiersParser.java:6383)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceUnaryPrefixExpression(HiveParser_IdentifiersParser.java:6768)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceUnarySuffixExpression(HiveParser_IdentifiersParser.java:6828)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceBitwiseXorExpression(HiveParser_IdentifiersParser.java:7012)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceStarExpression(HiveParser_IdentifiersParser.java:7172)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedencePlusExpression(HiveParser_IdentifiersParser.java:7332)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceAmpersandExpression(HiveParser_IdentifiersParser.java:7483)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceBitwiseOrExpression(HiveParser_IdentifiersParser.java:7634)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceEqualExpression(HiveParser_IdentifiersParser.java:8290)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceNotExpression(HiveParser_IdentifiersParser.java:9177)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceAndExpression(HiveParser_IdentifiersParser.java:9296)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceOrExpression(HiveParser_IdentifiersParser.java:9455)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.expression(HiveParser_IdentifiersParser.java:6105)
	at org.apache.hadoop.hive.ql.parse.HiveParser.expression(HiveParser.java:45846)
	at org.apache.hadoop.hive.ql.parse.HiveParser_FromClauseParser.searchCondition(HiveParser_FromClauseParser.java:6637)
	at org.apache.hadoop.hive.ql.parse.HiveParser_FromClauseParser.whereClause(HiveParser_FromClauseParser.java:6545)
	at org.apache.hadoop.hive.ql.parse.HiveParser.whereClause(HiveParser.java:45849)
	at org.apache.hadoop.hive.ql.parse.HiveParser.selectStatement(HiveParser.java:41543)
	at org.apache.hadoop.hive.ql.parse.HiveParser.regularBody(HiveParser.java:41402)
	at org.apache.hadoop.hive.ql.parse.HiveParser.queryStatementExpressionBody(HiveParser.java:40413)
	at org.apache.hadoop.hive.ql.parse.HiveParser.queryStatementExpression(HiveParser.java:40283)
	at org.apache.hadoop.hive.ql.parse.HiveParser.execStatement(HiveParser.java:1590)
	at org.apache.hadoop.hive.ql.parse.HiveParser.statement(HiveParser.java:1109)
	at org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:202)
	at org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:166)
	at org.apache.spark.sql.hive.HiveQl$.getAst(HiveQl.scala:258)
	at org.apache.spark.sql.hive.HiveQl$.createPlan(HiveQl.scala:283)
	at org.apache.spark.sql.hive.ExtendedHiveQlParser$$anonfun$hiveQl$1.apply(ExtendedHiveQlParser.scala:41)
	at org.apache.spark.sql.hive.ExtendedHiveQlParser$$anonfun$hiveQl$1.apply(ExtendedHiveQlParser.scala:40)
	at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)
	at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:135)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)
	at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Failure.append(Parsers.scala:202)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)
	at scala.util.parsing.combinator.Parsers$$anon$2$$anonfun$apply$14.apply(Parsers.scala:891)
	at scala.util.parsing.combinator.Parsers$$anon$2$$anonfun$apply$14.apply(Parsers.scala:891)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)
	at scala.util.parsing.combinator.Parsers$$anon$2.apply(Parsers.scala:890)
	at scala.util.parsing.combinator.PackratParsers$$anon$1.apply(PackratParsers.scala:110)
	at org.apache.spark.sql.catalyst.AbstractSparkSQLParser.parse(AbstractSparkSQLParser.scala:34)
	at org.apache.spark.sql.hive.HiveQl$.parseSql(HiveQl.scala:276)
	at org.apache.spark.sql.hive.HiveQLDialect.parse(HiveContext.scala:62)
	at com.intel.ssg.bdt.spark.sql.CalciteDialect.getLogicalPlan(CalciteDialect.scala:54)
	at com.intel.ssg.bdt.spark.sql.CalciteDialect.parse(CalciteDialect.scala:31)
	at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)
	at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)
	at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:115)
	at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:114)
	at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)
	at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:135)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)
	at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Failure.append(Parsers.scala:202)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)
	at scala.util.parsing.combinator.Parsers$$anon$2$$anonfun$apply$14.apply(Parsers.scala:891)
	at scala.util.parsing.combinator.Parsers$$anon$2$$anonfun$apply$14.apply(Parsers.scala:891)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)
	at scala.util.parsing.combinator.Parsers$$anon$2.apply(Parsers.scala:890)
	at scala.util.parsing.combinator.PackratParsers$$anon$1.apply(PackratParsers.scala:110)
	at org.apache.spark.sql.catalyst.AbstractSparkSQLParser.parse(AbstractSparkSQLParser.scala:34)
	at org.apache.spark.sql.SQLContext$$anonfun$2.apply(SQLContext.scala:166)
	at org.apache.spark.sql.SQLContext$$anonfun$2.apply(SQLContext.scala:166)
	at org.apache.spark.sql.execution.datasources.DDLParser.parse(DDLParser.scala:42)
	at org.apache.spark.sql.SQLContext.parseSql(SQLContext.scala:189)
	at org.apache.spark.sql.hive.HiveContext.parseSql(HiveContext.scala:280)
	at org.apache.spark.sql.hive.test.TestHiveContext$QueryExecution.<init>(TestHive.scala:179)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1$$anonfun$30.apply(HiveComparisonTest.scala:303)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1$$anonfun$30.apply(HiveComparisonTest.scala:303)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:34)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:244)
	at scala.collection.AbstractTraversable.map(Traversable.scala:105)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1.apply$mcV$sp(HiveComparisonTest.scala:303)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1.apply(HiveComparisonTest.scala:240)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1.apply(HiveComparisonTest.scala:240)
	at org.scalatest.Transformer$$anonfun$apply$1.apply$mcV$sp(Transformer.scala:22)
	at org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)
	at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
	at org.scalatest.Transformer.apply(Transformer.scala:22)
	at org.scalatest.Transformer.apply(Transformer.scala:20)
	at org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:166)
	at org.apache.spark.SparkFunSuite.withFixture(SparkFunSuite.scala:42)
	at org.scalatest.FunSuiteLike$class.invokeWithFixture$1(FunSuiteLike.scala:163)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)
	at org.scalatest.FunSuiteLike$class.runTest(FunSuiteLike.scala:175)
	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.org$scalatest$BeforeAndAfter$$super$runTest(HiveCompatibilitySuite.scala:32)
	at org.scalatest.BeforeAndAfter$class.runTest(BeforeAndAfter.scala:200)
	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.runTest(HiveCompatibilitySuite.scala:32)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:413)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:401)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)
	at org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:396)
	at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:483)
	at org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:208)
	at org.scalatest.FunSuite.runTests(FunSuite.scala:1555)
	at org.scalatest.Suite$class.run(Suite.scala:1424)
	at org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.SuperEngine.runImpl(Engine.scala:545)
	at org.scalatest.FunSuiteLike$class.run(FunSuiteLike.scala:212)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest.org$scalatest$BeforeAndAfterAll$$super$run(HiveComparisonTest.scala:44)
	at org.scalatest.BeforeAndAfterAll$class.liftedTree1$1(BeforeAndAfterAll.scala:257)
	at org.scalatest.BeforeAndAfterAll$class.run(BeforeAndAfterAll.scala:256)
	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.org$scalatest$BeforeAndAfter$$super$run(HiveCompatibilitySuite.scala:32)
	at org.scalatest.BeforeAndAfter$class.run(BeforeAndAfter.scala:241)
	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.run(HiveCompatibilitySuite.scala:32)
	at org.scalatest.Suite$class.callExecuteOnSuite$1(Suite.scala:1492)
	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1528)
	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1526)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.scalatest.Suite$class.runNestedSuites(Suite.scala:1526)
	at org.scalatest.tools.DiscoverySuite.runNestedSuites(DiscoverySuite.scala:29)
	at org.scalatest.Suite$class.run(Suite.scala:1421)
	at org.scalatest.tools.DiscoverySuite.run(DiscoverySuite.scala:29)
	at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:55)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2563)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2557)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:2557)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1044)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1043)
	at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:2722)
	at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1043)
	at org.scalatest.tools.Runner$.main(Runner.scala:860)
	at org.scalatest.tools.Runner.main(Runner.scala)
[31m- 0339 *** FAILED ***[0m
[31m  org.apache.spark.sql.AnalysisException: cannot recognize input near 'SELECT' 'CITY' 'FROM' in function specification; line 1 pos 47[0m
[31m  at org.apache.spark.sql.hive.HiveQl$.createPlan(HiveQl.scala:296)[0m
[31m  at org.apache.spark.sql.hive.ExtendedHiveQlParser$$anonfun$hiveQl$1.apply(ExtendedHiveQlParser.scala:41)[0m
[31m  at org.apache.spark.sql.hive.ExtendedHiveQlParser$$anonfun$hiveQl$1.apply(ExtendedHiveQlParser.scala:40)[0m
[31m  at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)[0m
[31m  at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:135)[0m
[31m  at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)[0m
[31m  at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)[0m
[31m  at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)[0m
[31m  at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)[0m
[31m  at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)[0m
[31m  ...[0m
NoViableAltException(231@[])
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.function(HiveParser_IdentifiersParser.java:3544)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.atomExpression(HiveParser_IdentifiersParser.java:6280)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceFieldExpression(HiveParser_IdentifiersParser.java:6383)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceUnaryPrefixExpression(HiveParser_IdentifiersParser.java:6768)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceUnarySuffixExpression(HiveParser_IdentifiersParser.java:6828)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceBitwiseXorExpression(HiveParser_IdentifiersParser.java:7012)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceStarExpression(HiveParser_IdentifiersParser.java:7172)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedencePlusExpression(HiveParser_IdentifiersParser.java:7332)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceAmpersandExpression(HiveParser_IdentifiersParser.java:7483)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceBitwiseOrExpression(HiveParser_IdentifiersParser.java:7634)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceEqualExpression(HiveParser_IdentifiersParser.java:8290)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceNotExpression(HiveParser_IdentifiersParser.java:9177)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceAndExpression(HiveParser_IdentifiersParser.java:9296)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceOrExpression(HiveParser_IdentifiersParser.java:9455)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.expression(HiveParser_IdentifiersParser.java:6105)
	at org.apache.hadoop.hive.ql.parse.HiveParser.expression(HiveParser.java:45846)
	at org.apache.hadoop.hive.ql.parse.HiveParser_FromClauseParser.searchCondition(HiveParser_FromClauseParser.java:6637)
	at org.apache.hadoop.hive.ql.parse.HiveParser_FromClauseParser.whereClause(HiveParser_FromClauseParser.java:6545)
	at org.apache.hadoop.hive.ql.parse.HiveParser.whereClause(HiveParser.java:45849)
	at org.apache.hadoop.hive.ql.parse.HiveParser.selectStatement(HiveParser.java:41543)
	at org.apache.hadoop.hive.ql.parse.HiveParser.regularBody(HiveParser.java:41402)
	at org.apache.hadoop.hive.ql.parse.HiveParser.queryStatementExpressionBody(HiveParser.java:40413)
	at org.apache.hadoop.hive.ql.parse.HiveParser.queryStatementExpression(HiveParser.java:40283)
	at org.apache.hadoop.hive.ql.parse.HiveParser.execStatement(HiveParser.java:1590)
	at org.apache.hadoop.hive.ql.parse.HiveParser.statement(HiveParser.java:1109)
	at org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:202)
	at org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:166)
	at org.apache.spark.sql.hive.HiveQl$.getAst(HiveQl.scala:258)
	at org.apache.spark.sql.hive.HiveQl$.createPlan(HiveQl.scala:283)
	at org.apache.spark.sql.hive.ExtendedHiveQlParser$$anonfun$hiveQl$1.apply(ExtendedHiveQlParser.scala:41)
	at org.apache.spark.sql.hive.ExtendedHiveQlParser$$anonfun$hiveQl$1.apply(ExtendedHiveQlParser.scala:40)
	at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)
	at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:135)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)
	at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Failure.append(Parsers.scala:202)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)
	at scala.util.parsing.combinator.Parsers$$anon$2$$anonfun$apply$14.apply(Parsers.scala:891)
	at scala.util.parsing.combinator.Parsers$$anon$2$$anonfun$apply$14.apply(Parsers.scala:891)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)
	at scala.util.parsing.combinator.Parsers$$anon$2.apply(Parsers.scala:890)
	at scala.util.parsing.combinator.PackratParsers$$anon$1.apply(PackratParsers.scala:110)
	at org.apache.spark.sql.catalyst.AbstractSparkSQLParser.parse(AbstractSparkSQLParser.scala:34)
	at org.apache.spark.sql.hive.HiveQl$.parseSql(HiveQl.scala:276)
	at org.apache.spark.sql.hive.HiveQLDialect.parse(HiveContext.scala:62)
	at com.intel.ssg.bdt.spark.sql.CalciteDialect.getLogicalPlan(CalciteDialect.scala:54)
	at com.intel.ssg.bdt.spark.sql.CalciteDialect.parse(CalciteDialect.scala:31)
	at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)
	at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)
	at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:115)
	at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:114)
	at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)
	at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:135)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)
	at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Failure.append(Parsers.scala:202)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)
	at scala.util.parsing.combinator.Parsers$$anon$2$$anonfun$apply$14.apply(Parsers.scala:891)
	at scala.util.parsing.combinator.Parsers$$anon$2$$anonfun$apply$14.apply(Parsers.scala:891)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)
	at scala.util.parsing.combinator.Parsers$$anon$2.apply(Parsers.scala:890)
	at scala.util.parsing.combinator.PackratParsers$$anon$1.apply(PackratParsers.scala:110)
	at org.apache.spark.sql.catalyst.AbstractSparkSQLParser.parse(AbstractSparkSQLParser.scala:34)
	at org.apache.spark.sql.SQLContext$$anonfun$2.apply(SQLContext.scala:166)
	at org.apache.spark.sql.SQLContext$$anonfun$2.apply(SQLContext.scala:166)
	at org.apache.spark.sql.execution.datasources.DDLParser.parse(DDLParser.scala:42)
	at org.apache.spark.sql.SQLContext.parseSql(SQLContext.scala:189)
	at org.apache.spark.sql.hive.HiveContext.parseSql(HiveContext.scala:280)
	at org.apache.spark.sql.hive.test.TestHiveContext$QueryExecution.<init>(TestHive.scala:179)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1$$anonfun$30.apply(HiveComparisonTest.scala:303)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1$$anonfun$30.apply(HiveComparisonTest.scala:303)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:34)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:244)
	at scala.collection.AbstractTraversable.map(Traversable.scala:105)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1.apply$mcV$sp(HiveComparisonTest.scala:303)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1.apply(HiveComparisonTest.scala:240)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1.apply(HiveComparisonTest.scala:240)
	at org.scalatest.Transformer$$anonfun$apply$1.apply$mcV$sp(Transformer.scala:22)
	at org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)
	at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
	at org.scalatest.Transformer.apply(Transformer.scala:22)
	at org.scalatest.Transformer.apply(Transformer.scala:20)
	at org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:166)
	at org.apache.spark.SparkFunSuite.withFixture(SparkFunSuite.scala:42)
	at org.scalatest.FunSuiteLike$class.invokeWithFixture$1(FunSuiteLike.scala:163)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)
	at org.scalatest.FunSuiteLike$class.runTest(FunSuiteLike.scala:175)
	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.org$scalatest$BeforeAndAfter$$super$runTest(HiveCompatibilitySuite.scala:32)
	at org.scalatest.BeforeAndAfter$class.runTest(BeforeAndAfter.scala:200)
	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.runTest(HiveCompatibilitySuite.scala:32)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:413)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:401)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)
	at org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:396)
	at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:483)
	at org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:208)
	at org.scalatest.FunSuite.runTests(FunSuite.scala:1555)
	at org.scalatest.Suite$class.run(Suite.scala:1424)
	at org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.SuperEngine.runImpl(Engine.scala:545)
	at org.scalatest.FunSuiteLike$class.run(FunSuiteLike.scala:212)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest.org$scalatest$BeforeAndAfterAll$$super$run(HiveComparisonTest.scala:44)
	at org.scalatest.BeforeAndAfterAll$class.liftedTree1$1(BeforeAndAfterAll.scala:257)
	at org.scalatest.BeforeAndAfterAll$class.run(BeforeAndAfterAll.scala:256)
	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.org$scalatest$BeforeAndAfter$$super$run(HiveCompatibilitySuite.scala:32)
	at org.scalatest.BeforeAndAfter$class.run(BeforeAndAfter.scala:241)
	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.run(HiveCompatibilitySuite.scala:32)
	at org.scalatest.Suite$class.callExecuteOnSuite$1(Suite.scala:1492)
	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1528)
	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1526)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.scalatest.Suite$class.runNestedSuites(Suite.scala:1526)
	at org.scalatest.tools.DiscoverySuite.runNestedSuites(DiscoverySuite.scala:29)
	at org.scalatest.Suite$class.run(Suite.scala:1421)
	at org.scalatest.tools.DiscoverySuite.run(DiscoverySuite.scala:29)
	at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:55)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2563)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2557)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:2557)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1044)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1043)
	at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:2722)
	at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1043)
	at org.scalatest.tools.Runner$.main(Runner.scala:860)
	at org.scalatest.tools.Runner.main(Runner.scala)
[31m- 0340 *** FAILED ***[0m
[31m  org.apache.spark.sql.AnalysisException: cannot recognize input near 'SELECT' 'PNUM' 'FROM' in function specification; line 1 pos 44[0m
[31m  at org.apache.spark.sql.hive.HiveQl$.createPlan(HiveQl.scala:296)[0m
[31m  at org.apache.spark.sql.hive.ExtendedHiveQlParser$$anonfun$hiveQl$1.apply(ExtendedHiveQlParser.scala:41)[0m
[31m  at org.apache.spark.sql.hive.ExtendedHiveQlParser$$anonfun$hiveQl$1.apply(ExtendedHiveQlParser.scala:40)[0m
[31m  at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)[0m
[31m  at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:135)[0m
[31m  at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)[0m
[31m  at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)[0m
[31m  at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)[0m
[31m  at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)[0m
[31m  at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)[0m
[31m  ...[0m
NoViableAltException(231@[])
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.function(HiveParser_IdentifiersParser.java:3544)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.atomExpression(HiveParser_IdentifiersParser.java:6280)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceFieldExpression(HiveParser_IdentifiersParser.java:6383)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceUnaryPrefixExpression(HiveParser_IdentifiersParser.java:6768)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceUnarySuffixExpression(HiveParser_IdentifiersParser.java:6828)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceBitwiseXorExpression(HiveParser_IdentifiersParser.java:7012)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceStarExpression(HiveParser_IdentifiersParser.java:7172)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedencePlusExpression(HiveParser_IdentifiersParser.java:7332)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceAmpersandExpression(HiveParser_IdentifiersParser.java:7483)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceBitwiseOrExpression(HiveParser_IdentifiersParser.java:7634)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceEqualExpression(HiveParser_IdentifiersParser.java:8290)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceNotExpression(HiveParser_IdentifiersParser.java:9177)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceAndExpression(HiveParser_IdentifiersParser.java:9296)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceOrExpression(HiveParser_IdentifiersParser.java:9455)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.expression(HiveParser_IdentifiersParser.java:6105)
	at org.apache.hadoop.hive.ql.parse.HiveParser.expression(HiveParser.java:45846)
	at org.apache.hadoop.hive.ql.parse.HiveParser_FromClauseParser.searchCondition(HiveParser_FromClauseParser.java:6637)
	at org.apache.hadoop.hive.ql.parse.HiveParser_FromClauseParser.whereClause(HiveParser_FromClauseParser.java:6545)
	at org.apache.hadoop.hive.ql.parse.HiveParser.whereClause(HiveParser.java:45849)
	at org.apache.hadoop.hive.ql.parse.HiveParser.selectStatement(HiveParser.java:41543)
	at org.apache.hadoop.hive.ql.parse.HiveParser.regularBody(HiveParser.java:41402)
	at org.apache.hadoop.hive.ql.parse.HiveParser.queryStatementExpressionBody(HiveParser.java:40413)
	at org.apache.hadoop.hive.ql.parse.HiveParser.queryStatementExpression(HiveParser.java:40283)
	at org.apache.hadoop.hive.ql.parse.HiveParser.execStatement(HiveParser.java:1590)
	at org.apache.hadoop.hive.ql.parse.HiveParser.statement(HiveParser.java:1109)
	at org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:202)
	at org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:166)
	at org.apache.spark.sql.hive.HiveQl$.getAst(HiveQl.scala:258)
	at org.apache.spark.sql.hive.HiveQl$.createPlan(HiveQl.scala:283)
	at org.apache.spark.sql.hive.ExtendedHiveQlParser$$anonfun$hiveQl$1.apply(ExtendedHiveQlParser.scala:41)
	at org.apache.spark.sql.hive.ExtendedHiveQlParser$$anonfun$hiveQl$1.apply(ExtendedHiveQlParser.scala:40)
	at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)
	at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:135)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)
	at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Failure.append(Parsers.scala:202)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)
	at scala.util.parsing.combinator.Parsers$$anon$2$$anonfun$apply$14.apply(Parsers.scala:891)
	at scala.util.parsing.combinator.Parsers$$anon$2$$anonfun$apply$14.apply(Parsers.scala:891)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)
	at scala.util.parsing.combinator.Parsers$$anon$2.apply(Parsers.scala:890)
	at scala.util.parsing.combinator.PackratParsers$$anon$1.apply(PackratParsers.scala:110)
	at org.apache.spark.sql.catalyst.AbstractSparkSQLParser.parse(AbstractSparkSQLParser.scala:34)
	at org.apache.spark.sql.hive.HiveQl$.parseSql(HiveQl.scala:276)
	at org.apache.spark.sql.hive.HiveQLDialect.parse(HiveContext.scala:62)
	at com.intel.ssg.bdt.spark.sql.CalciteDialect.getLogicalPlan(CalciteDialect.scala:54)
	at com.intel.ssg.bdt.spark.sql.CalciteDialect.parse(CalciteDialect.scala:31)
	at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)
	at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)
	at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:115)
	at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:114)
	at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)
	at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:135)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)
	at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Failure.append(Parsers.scala:202)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)
	at scala.util.parsing.combinator.Parsers$$anon$2$$anonfun$apply$14.apply(Parsers.scala:891)
	at scala.util.parsing.combinator.Parsers$$anon$2$$anonfun$apply$14.apply(Parsers.scala:891)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)
	at scala.util.parsing.combinator.Parsers$$anon$2.apply(Parsers.scala:890)
	at scala.util.parsing.combinator.PackratParsers$$anon$1.apply(PackratParsers.scala:110)
	at org.apache.spark.sql.catalyst.AbstractSparkSQLParser.parse(AbstractSparkSQLParser.scala:34)
	at org.apache.spark.sql.SQLContext$$anonfun$2.apply(SQLContext.scala:166)
	at org.apache.spark.sql.SQLContext$$anonfun$2.apply(SQLContext.scala:166)
	at org.apache.spark.sql.execution.datasources.DDLParser.parse(DDLParser.scala:42)
	at org.apache.spark.sql.SQLContext.parseSql(SQLContext.scala:189)
	at org.apache.spark.sql.hive.HiveContext.parseSql(HiveContext.scala:280)
	at org.apache.spark.sql.hive.test.TestHiveContext$QueryExecution.<init>(TestHive.scala:179)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1$$anonfun$30.apply(HiveComparisonTest.scala:303)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1$$anonfun$30.apply(HiveComparisonTest.scala:303)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:34)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:244)
	at scala.collection.AbstractTraversable.map(Traversable.scala:105)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1.apply$mcV$sp(HiveComparisonTest.scala:303)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1.apply(HiveComparisonTest.scala:240)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1.apply(HiveComparisonTest.scala:240)
	at org.scalatest.Transformer$$anonfun$apply$1.apply$mcV$sp(Transformer.scala:22)
	at org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)
	at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
	at org.scalatest.Transformer.apply(Transformer.scala:22)
	at org.scalatest.Transformer.apply(Transformer.scala:20)
	at org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:166)
	at org.apache.spark.SparkFunSuite.withFixture(SparkFunSuite.scala:42)
	at org.scalatest.FunSuiteLike$class.invokeWithFixture$1(FunSuiteLike.scala:163)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)
	at org.scalatest.FunSuiteLike$class.runTest(FunSuiteLike.scala:175)
	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.org$scalatest$BeforeAndAfter$$super$runTest(HiveCompatibilitySuite.scala:32)
	at org.scalatest.BeforeAndAfter$class.runTest(BeforeAndAfter.scala:200)
	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.runTest(HiveCompatibilitySuite.scala:32)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:413)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:401)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)
	at org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:396)
	at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:483)
	at org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:208)
	at org.scalatest.FunSuite.runTests(FunSuite.scala:1555)
	at org.scalatest.Suite$class.run(Suite.scala:1424)
	at org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.SuperEngine.runImpl(Engine.scala:545)
	at org.scalatest.FunSuiteLike$class.run(FunSuiteLike.scala:212)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest.org$scalatest$BeforeAndAfterAll$$super$run(HiveComparisonTest.scala:44)
	at org.scalatest.BeforeAndAfterAll$class.liftedTree1$1(BeforeAndAfterAll.scala:257)
	at org.scalatest.BeforeAndAfterAll$class.run(BeforeAndAfterAll.scala:256)
	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.org$scalatest$BeforeAndAfter$$super$run(HiveCompatibilitySuite.scala:32)
	at org.scalatest.BeforeAndAfter$class.run(BeforeAndAfter.scala:241)
	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.run(HiveCompatibilitySuite.scala:32)
	at org.scalatest.Suite$class.callExecuteOnSuite$1(Suite.scala:1492)
	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1528)
	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1526)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.scalatest.Suite$class.runNestedSuites(Suite.scala:1526)
	at org.scalatest.tools.DiscoverySuite.runNestedSuites(DiscoverySuite.scala:29)
	at org.scalatest.Suite$class.run(Suite.scala:1421)
	at org.scalatest.tools.DiscoverySuite.run(DiscoverySuite.scala:29)
	at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:55)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2563)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2557)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:2557)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1044)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1043)
	at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:2722)
	at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1043)
	at org.scalatest.tools.Runner$.main(Runner.scala:860)
	at org.scalatest.tools.Runner.main(Runner.scala)
[31m- 0341 *** FAILED ***[0m
[31m  org.apache.spark.sql.AnalysisException: cannot recognize input near 'SELECT' 'PNUM' 'FROM' in function specification; line 1 pos 45[0m
[31m  at org.apache.spark.sql.hive.HiveQl$.createPlan(HiveQl.scala:296)[0m
[31m  at org.apache.spark.sql.hive.ExtendedHiveQlParser$$anonfun$hiveQl$1.apply(ExtendedHiveQlParser.scala:41)[0m
[31m  at org.apache.spark.sql.hive.ExtendedHiveQlParser$$anonfun$hiveQl$1.apply(ExtendedHiveQlParser.scala:40)[0m
[31m  at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)[0m
[31m  at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:135)[0m
[31m  at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)[0m
[31m  at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)[0m
[31m  at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)[0m
[31m  at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)[0m
[31m  at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)[0m
[31m  ...[0m
NoViableAltException(231@[])
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.function(HiveParser_IdentifiersParser.java:3544)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.atomExpression(HiveParser_IdentifiersParser.java:6280)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceFieldExpression(HiveParser_IdentifiersParser.java:6383)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceUnaryPrefixExpression(HiveParser_IdentifiersParser.java:6768)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceUnarySuffixExpression(HiveParser_IdentifiersParser.java:6828)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceBitwiseXorExpression(HiveParser_IdentifiersParser.java:7012)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceStarExpression(HiveParser_IdentifiersParser.java:7172)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedencePlusExpression(HiveParser_IdentifiersParser.java:7332)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceAmpersandExpression(HiveParser_IdentifiersParser.java:7483)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceBitwiseOrExpression(HiveParser_IdentifiersParser.java:7634)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceEqualExpression(HiveParser_IdentifiersParser.java:8290)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceNotExpression(HiveParser_IdentifiersParser.java:9177)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceAndExpression(HiveParser_IdentifiersParser.java:9296)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceOrExpression(HiveParser_IdentifiersParser.java:9455)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.expression(HiveParser_IdentifiersParser.java:6105)
	at org.apache.hadoop.hive.ql.parse.HiveParser.expression(HiveParser.java:45846)
	at org.apache.hadoop.hive.ql.parse.HiveParser_FromClauseParser.searchCondition(HiveParser_FromClauseParser.java:6637)
	at org.apache.hadoop.hive.ql.parse.HiveParser_FromClauseParser.whereClause(HiveParser_FromClauseParser.java:6545)
	at org.apache.hadoop.hive.ql.parse.HiveParser.whereClause(HiveParser.java:45849)
	at org.apache.hadoop.hive.ql.parse.HiveParser.selectStatement(HiveParser.java:41543)
	at org.apache.hadoop.hive.ql.parse.HiveParser.regularBody(HiveParser.java:41402)
	at org.apache.hadoop.hive.ql.parse.HiveParser.queryStatementExpressionBody(HiveParser.java:40413)
	at org.apache.hadoop.hive.ql.parse.HiveParser.queryStatementExpression(HiveParser.java:40283)
	at org.apache.hadoop.hive.ql.parse.HiveParser.execStatement(HiveParser.java:1590)
	at org.apache.hadoop.hive.ql.parse.HiveParser.statement(HiveParser.java:1109)
	at org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:202)
	at org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:166)
	at org.apache.spark.sql.hive.HiveQl$.getAst(HiveQl.scala:258)
	at org.apache.spark.sql.hive.HiveQl$.createPlan(HiveQl.scala:283)
	at org.apache.spark.sql.hive.ExtendedHiveQlParser$$anonfun$hiveQl$1.apply(ExtendedHiveQlParser.scala:41)
	at org.apache.spark.sql.hive.ExtendedHiveQlParser$$anonfun$hiveQl$1.apply(ExtendedHiveQlParser.scala:40)
	at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)
	at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:135)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)
	at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Failure.append(Parsers.scala:202)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)
	at scala.util.parsing.combinator.Parsers$$anon$2$$anonfun$apply$14.apply(Parsers.scala:891)
	at scala.util.parsing.combinator.Parsers$$anon$2$$anonfun$apply$14.apply(Parsers.scala:891)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)
	at scala.util.parsing.combinator.Parsers$$anon$2.apply(Parsers.scala:890)
	at scala.util.parsing.combinator.PackratParsers$$anon$1.apply(PackratParsers.scala:110)
	at org.apache.spark.sql.catalyst.AbstractSparkSQLParser.parse(AbstractSparkSQLParser.scala:34)
	at org.apache.spark.sql.hive.HiveQl$.parseSql(HiveQl.scala:276)
	at org.apache.spark.sql.hive.HiveQLDialect.parse(HiveContext.scala:62)
	at com.intel.ssg.bdt.spark.sql.CalciteDialect.getLogicalPlan(CalciteDialect.scala:54)
	at com.intel.ssg.bdt.spark.sql.CalciteDialect.parse(CalciteDialect.scala:31)
	at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)
	at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)
	at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:115)
	at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:114)
	at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)
	at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:135)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)
	at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Failure.append(Parsers.scala:202)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)
	at scala.util.parsing.combinator.Parsers$$anon$2$$anonfun$apply$14.apply(Parsers.scala:891)
	at scala.util.parsing.combinator.Parsers$$anon$2$$anonfun$apply$14.apply(Parsers.scala:891)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)
	at scala.util.parsing.combinator.Parsers$$anon$2.apply(Parsers.scala:890)
	at scala.util.parsing.combinator.PackratParsers$$anon$1.apply(PackratParsers.scala:110)
	at org.apache.spark.sql.catalyst.AbstractSparkSQLParser.parse(AbstractSparkSQLParser.scala:34)
	at org.apache.spark.sql.SQLContext$$anonfun$2.apply(SQLContext.scala:166)
	at org.apache.spark.sql.SQLContext$$anonfun$2.apply(SQLContext.scala:166)
	at org.apache.spark.sql.execution.datasources.DDLParser.parse(DDLParser.scala:42)
	at org.apache.spark.sql.SQLContext.parseSql(SQLContext.scala:189)
	at org.apache.spark.sql.hive.HiveContext.parseSql(HiveContext.scala:280)
	at org.apache.spark.sql.hive.test.TestHiveContext$QueryExecution.<init>(TestHive.scala:179)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1$$anonfun$30.apply(HiveComparisonTest.scala:303)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1$$anonfun$30.apply(HiveComparisonTest.scala:303)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:34)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:244)
	at scala.collection.AbstractTraversable.map(Traversable.scala:105)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1.apply$mcV$sp(HiveComparisonTest.scala:303)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1.apply(HiveComparisonTest.scala:240)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1.apply(HiveComparisonTest.scala:240)
	at org.scalatest.Transformer$$anonfun$apply$1.apply$mcV$sp(Transformer.scala:22)
	at org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)
	at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
	at org.scalatest.Transformer.apply(Transformer.scala:22)
	at org.scalatest.Transformer.apply(Transformer.scala:20)
	at org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:166)
	at org.apache.spark.SparkFunSuite.withFixture(SparkFunSuite.scala:42)
	at org.scalatest.FunSuiteLike$class.invokeWithFixture$1(FunSuiteLike.scala:163)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)
	at org.scalatest.FunSuiteLike$class.runTest(FunSuiteLike.scala:175)
	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.org$scalatest$BeforeAndAfter$$super$runTest(HiveCompatibilitySuite.scala:32)
	at org.scalatest.BeforeAndAfter$class.runTest(BeforeAndAfter.scala:200)
	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.runTest(HiveCompatibilitySuite.scala:32)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:413)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:401)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)
	at org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:396)
	at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:483)
	at org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:208)
	at org.scalatest.FunSuite.runTests(FunSuite.scala:1555)
	at org.scalatest.Suite$class.run(Suite.scala:1424)
	at org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.SuperEngine.runImpl(Engine.scala:545)
	at org.scalatest.FunSuiteLike$class.run(FunSuiteLike.scala:212)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest.org$scalatest$BeforeAndAfterAll$$super$run(HiveComparisonTest.scala:44)
	at org.scalatest.BeforeAndAfterAll$class.liftedTree1$1(BeforeAndAfterAll.scala:257)
	at org.scalatest.BeforeAndAfterAll$class.run(BeforeAndAfterAll.scala:256)
	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.org$scalatest$BeforeAndAfter$$super$run(HiveCompatibilitySuite.scala:32)
	at org.scalatest.BeforeAndAfter$class.run(BeforeAndAfter.scala:241)
	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.run(HiveCompatibilitySuite.scala:32)
	at org.scalatest.Suite$class.callExecuteOnSuite$1(Suite.scala:1492)
	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1528)
	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1526)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.scalatest.Suite$class.runNestedSuites(Suite.scala:1526)
	at org.scalatest.tools.DiscoverySuite.runNestedSuites(DiscoverySuite.scala:29)
	at org.scalatest.Suite$class.run(Suite.scala:1421)
	at org.scalatest.tools.DiscoverySuite.run(DiscoverySuite.scala:29)
	at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:55)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2563)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2557)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:2557)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1044)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1043)
	at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:2722)
	at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1043)
	at org.scalatest.tools.Runner$.main(Runner.scala:860)
	at org.scalatest.tools.Runner.main(Runner.scala)
[31m- 0342 *** FAILED ***[0m
[31m  org.apache.spark.sql.AnalysisException: cannot recognize input near 'SELECT' 'PNUM' 'FROM' in function specification; line 1 pos 44[0m
[31m  at org.apache.spark.sql.hive.HiveQl$.createPlan(HiveQl.scala:296)[0m
[31m  at org.apache.spark.sql.hive.ExtendedHiveQlParser$$anonfun$hiveQl$1.apply(ExtendedHiveQlParser.scala:41)[0m
[31m  at org.apache.spark.sql.hive.ExtendedHiveQlParser$$anonfun$hiveQl$1.apply(ExtendedHiveQlParser.scala:40)[0m
[31m  at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)[0m
[31m  at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:135)[0m
[31m  at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)[0m
[31m  at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)[0m
[31m  at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)[0m
[31m  at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)[0m
[31m  at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)[0m
[31m  ...[0m
NoViableAltException(231@[])
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.function(HiveParser_IdentifiersParser.java:3544)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.atomExpression(HiveParser_IdentifiersParser.java:6280)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceFieldExpression(HiveParser_IdentifiersParser.java:6383)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceUnaryPrefixExpression(HiveParser_IdentifiersParser.java:6768)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceUnarySuffixExpression(HiveParser_IdentifiersParser.java:6828)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceBitwiseXorExpression(HiveParser_IdentifiersParser.java:7012)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceStarExpression(HiveParser_IdentifiersParser.java:7172)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedencePlusExpression(HiveParser_IdentifiersParser.java:7332)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceAmpersandExpression(HiveParser_IdentifiersParser.java:7483)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceBitwiseOrExpression(HiveParser_IdentifiersParser.java:7634)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceEqualExpression(HiveParser_IdentifiersParser.java:8290)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceNotExpression(HiveParser_IdentifiersParser.java:9177)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceAndExpression(HiveParser_IdentifiersParser.java:9296)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceOrExpression(HiveParser_IdentifiersParser.java:9455)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.expression(HiveParser_IdentifiersParser.java:6105)
	at org.apache.hadoop.hive.ql.parse.HiveParser.expression(HiveParser.java:45846)
	at org.apache.hadoop.hive.ql.parse.HiveParser_FromClauseParser.searchCondition(HiveParser_FromClauseParser.java:6637)
	at org.apache.hadoop.hive.ql.parse.HiveParser_FromClauseParser.whereClause(HiveParser_FromClauseParser.java:6545)
	at org.apache.hadoop.hive.ql.parse.HiveParser.whereClause(HiveParser.java:45849)
	at org.apache.hadoop.hive.ql.parse.HiveParser.selectStatement(HiveParser.java:41543)
	at org.apache.hadoop.hive.ql.parse.HiveParser.regularBody(HiveParser.java:41402)
	at org.apache.hadoop.hive.ql.parse.HiveParser.queryStatementExpressionBody(HiveParser.java:40413)
	at org.apache.hadoop.hive.ql.parse.HiveParser.queryStatementExpression(HiveParser.java:40283)
	at org.apache.hadoop.hive.ql.parse.HiveParser.execStatement(HiveParser.java:1590)
	at org.apache.hadoop.hive.ql.parse.HiveParser.statement(HiveParser.java:1109)
	at org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:202)
	at org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:166)
	at org.apache.spark.sql.hive.HiveQl$.getAst(HiveQl.scala:258)
	at org.apache.spark.sql.hive.HiveQl$.createPlan(HiveQl.scala:283)
	at org.apache.spark.sql.hive.ExtendedHiveQlParser$$anonfun$hiveQl$1.apply(ExtendedHiveQlParser.scala:41)
	at org.apache.spark.sql.hive.ExtendedHiveQlParser$$anonfun$hiveQl$1.apply(ExtendedHiveQlParser.scala:40)
	at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)
	at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:135)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)
	at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Failure.append(Parsers.scala:202)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)
	at scala.util.parsing.combinator.Parsers$$anon$2$$anonfun$apply$14.apply(Parsers.scala:891)
	at scala.util.parsing.combinator.Parsers$$anon$2$$anonfun$apply$14.apply(Parsers.scala:891)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)
	at scala.util.parsing.combinator.Parsers$$anon$2.apply(Parsers.scala:890)
	at scala.util.parsing.combinator.PackratParsers$$anon$1.apply(PackratParsers.scala:110)
	at org.apache.spark.sql.catalyst.AbstractSparkSQLParser.parse(AbstractSparkSQLParser.scala:34)
	at org.apache.spark.sql.hive.HiveQl$.parseSql(HiveQl.scala:276)
	at org.apache.spark.sql.hive.HiveQLDialect.parse(HiveContext.scala:62)
	at com.intel.ssg.bdt.spark.sql.CalciteDialect.getLogicalPlan(CalciteDialect.scala:54)
	at com.intel.ssg.bdt.spark.sql.CalciteDialect.parse(CalciteDialect.scala:31)
	at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)
	at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)
	at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:115)
	at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:114)
	at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)
	at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:135)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)
	at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Failure.append(Parsers.scala:202)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)
	at scala.util.parsing.combinator.Parsers$$anon$2$$anonfun$apply$14.apply(Parsers.scala:891)
	at scala.util.parsing.combinator.Parsers$$anon$2$$anonfun$apply$14.apply(Parsers.scala:891)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)
	at scala.util.parsing.combinator.Parsers$$anon$2.apply(Parsers.scala:890)
	at scala.util.parsing.combinator.PackratParsers$$anon$1.apply(PackratParsers.scala:110)
	at org.apache.spark.sql.catalyst.AbstractSparkSQLParser.parse(AbstractSparkSQLParser.scala:34)
	at org.apache.spark.sql.SQLContext$$anonfun$2.apply(SQLContext.scala:166)
	at org.apache.spark.sql.SQLContext$$anonfun$2.apply(SQLContext.scala:166)
	at org.apache.spark.sql.execution.datasources.DDLParser.parse(DDLParser.scala:42)
	at org.apache.spark.sql.SQLContext.parseSql(SQLContext.scala:189)
	at org.apache.spark.sql.hive.HiveContext.parseSql(HiveContext.scala:280)
	at org.apache.spark.sql.hive.test.TestHiveContext$QueryExecution.<init>(TestHive.scala:179)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1$$anonfun$30.apply(HiveComparisonTest.scala:303)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1$$anonfun$30.apply(HiveComparisonTest.scala:303)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:34)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:244)
	at scala.collection.AbstractTraversable.map(Traversable.scala:105)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1.apply$mcV$sp(HiveComparisonTest.scala:303)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1.apply(HiveComparisonTest.scala:240)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1.apply(HiveComparisonTest.scala:240)
	at org.scalatest.Transformer$$anonfun$apply$1.apply$mcV$sp(Transformer.scala:22)
	at org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)
	at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
	at org.scalatest.Transformer.apply(Transformer.scala:22)
	at org.scalatest.Transformer.apply(Transformer.scala:20)
	at org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:166)
	at org.apache.spark.SparkFunSuite.withFixture(SparkFunSuite.scala:42)
	at org.scalatest.FunSuiteLike$class.invokeWithFixture$1(FunSuiteLike.scala:163)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)
	at org.scalatest.FunSuiteLike$class.runTest(FunSuiteLike.scala:175)
	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.org$scalatest$BeforeAndAfter$$super$runTest(HiveCompatibilitySuite.scala:32)
	at org.scalatest.BeforeAndAfter$class.runTest(BeforeAndAfter.scala:200)
	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.runTest(HiveCompatibilitySuite.scala:32)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:413)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:401)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)
	at org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:396)
	at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:483)
	at org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:208)
	at org.scalatest.FunSuite.runTests(FunSuite.scala:1555)
	at org.scalatest.Suite$class.run(Suite.scala:1424)
	at org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.SuperEngine.runImpl(Engine.scala:545)
	at org.scalatest.FunSuiteLike$class.run(FunSuiteLike.scala:212)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest.org$scalatest$BeforeAndAfterAll$$super$run(HiveComparisonTest.scala:44)
	at org.scalatest.BeforeAndAfterAll$class.liftedTree1$1(BeforeAndAfterAll.scala:257)
	at org.scalatest.BeforeAndAfterAll$class.run(BeforeAndAfterAll.scala:256)
	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.org$scalatest$BeforeAndAfter$$super$run(HiveCompatibilitySuite.scala:32)
	at org.scalatest.BeforeAndAfter$class.run(BeforeAndAfter.scala:241)
	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.run(HiveCompatibilitySuite.scala:32)
	at org.scalatest.Suite$class.callExecuteOnSuite$1(Suite.scala:1492)
	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1528)
	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1526)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.scalatest.Suite$class.runNestedSuites(Suite.scala:1526)
	at org.scalatest.tools.DiscoverySuite.runNestedSuites(DiscoverySuite.scala:29)
	at org.scalatest.Suite$class.run(Suite.scala:1421)
	at org.scalatest.tools.DiscoverySuite.run(DiscoverySuite.scala:29)
	at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:55)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2563)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2557)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:2557)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1044)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1043)
	at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:2722)
	at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1043)
	at org.scalatest.tools.Runner$.main(Runner.scala:860)
	at org.scalatest.tools.Runner.main(Runner.scala)
[31m- 0343 *** FAILED ***[0m
[31m  org.apache.spark.sql.AnalysisException: cannot recognize input near 'SELECT' 'PNUM' 'FROM' in function specification; line 1 pos 45[0m
[31m  at org.apache.spark.sql.hive.HiveQl$.createPlan(HiveQl.scala:296)[0m
[31m  at org.apache.spark.sql.hive.ExtendedHiveQlParser$$anonfun$hiveQl$1.apply(ExtendedHiveQlParser.scala:41)[0m
[31m  at org.apache.spark.sql.hive.ExtendedHiveQlParser$$anonfun$hiveQl$1.apply(ExtendedHiveQlParser.scala:40)[0m
[31m  at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)[0m
[31m  at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:135)[0m
[31m  at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)[0m
[31m  at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)[0m
[31m  at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)[0m
[31m  at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)[0m
[31m  at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)[0m
[31m  ...[0m
NoViableAltException(231@[])
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.function(HiveParser_IdentifiersParser.java:3544)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.atomExpression(HiveParser_IdentifiersParser.java:6280)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceFieldExpression(HiveParser_IdentifiersParser.java:6383)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceUnaryPrefixExpression(HiveParser_IdentifiersParser.java:6768)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceUnarySuffixExpression(HiveParser_IdentifiersParser.java:6828)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceBitwiseXorExpression(HiveParser_IdentifiersParser.java:7012)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceStarExpression(HiveParser_IdentifiersParser.java:7172)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedencePlusExpression(HiveParser_IdentifiersParser.java:7332)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceAmpersandExpression(HiveParser_IdentifiersParser.java:7483)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceBitwiseOrExpression(HiveParser_IdentifiersParser.java:7634)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceEqualExpression(HiveParser_IdentifiersParser.java:8290)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceNotExpression(HiveParser_IdentifiersParser.java:9177)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceAndExpression(HiveParser_IdentifiersParser.java:9296)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceOrExpression(HiveParser_IdentifiersParser.java:9455)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.expression(HiveParser_IdentifiersParser.java:6105)
	at org.apache.hadoop.hive.ql.parse.HiveParser.expression(HiveParser.java:45846)
	at org.apache.hadoop.hive.ql.parse.HiveParser_FromClauseParser.searchCondition(HiveParser_FromClauseParser.java:6637)
	at org.apache.hadoop.hive.ql.parse.HiveParser_FromClauseParser.whereClause(HiveParser_FromClauseParser.java:6545)
	at org.apache.hadoop.hive.ql.parse.HiveParser.whereClause(HiveParser.java:45849)
	at org.apache.hadoop.hive.ql.parse.HiveParser.selectStatement(HiveParser.java:41543)
	at org.apache.hadoop.hive.ql.parse.HiveParser.regularBody(HiveParser.java:41402)
	at org.apache.hadoop.hive.ql.parse.HiveParser.queryStatementExpressionBody(HiveParser.java:40413)
	at org.apache.hadoop.hive.ql.parse.HiveParser.queryStatementExpression(HiveParser.java:40283)
	at org.apache.hadoop.hive.ql.parse.HiveParser.execStatement(HiveParser.java:1590)
	at org.apache.hadoop.hive.ql.parse.HiveParser.statement(HiveParser.java:1109)
	at org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:202)
	at org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:166)
	at org.apache.spark.sql.hive.HiveQl$.getAst(HiveQl.scala:258)
	at org.apache.spark.sql.hive.HiveQl$.createPlan(HiveQl.scala:283)
	at org.apache.spark.sql.hive.ExtendedHiveQlParser$$anonfun$hiveQl$1.apply(ExtendedHiveQlParser.scala:41)
	at org.apache.spark.sql.hive.ExtendedHiveQlParser$$anonfun$hiveQl$1.apply(ExtendedHiveQlParser.scala:40)
	at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)
	at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:135)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)
	at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Failure.append(Parsers.scala:202)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)
	at scala.util.parsing.combinator.Parsers$$anon$2$$anonfun$apply$14.apply(Parsers.scala:891)
	at scala.util.parsing.combinator.Parsers$$anon$2$$anonfun$apply$14.apply(Parsers.scala:891)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)
	at scala.util.parsing.combinator.Parsers$$anon$2.apply(Parsers.scala:890)
	at scala.util.parsing.combinator.PackratParsers$$anon$1.apply(PackratParsers.scala:110)
	at org.apache.spark.sql.catalyst.AbstractSparkSQLParser.parse(AbstractSparkSQLParser.scala:34)
	at org.apache.spark.sql.hive.HiveQl$.parseSql(HiveQl.scala:276)
	at org.apache.spark.sql.hive.HiveQLDialect.parse(HiveContext.scala:62)
	at com.intel.ssg.bdt.spark.sql.CalciteDialect.getLogicalPlan(CalciteDialect.scala:54)
	at com.intel.ssg.bdt.spark.sql.CalciteDialect.parse(CalciteDialect.scala:31)
	at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)
	at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)
	at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:115)
	at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:114)
	at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)
	at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:135)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)
	at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Failure.append(Parsers.scala:202)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)
	at scala.util.parsing.combinator.Parsers$$anon$2$$anonfun$apply$14.apply(Parsers.scala:891)
	at scala.util.parsing.combinator.Parsers$$anon$2$$anonfun$apply$14.apply(Parsers.scala:891)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)
	at scala.util.parsing.combinator.Parsers$$anon$2.apply(Parsers.scala:890)
	at scala.util.parsing.combinator.PackratParsers$$anon$1.apply(PackratParsers.scala:110)
	at org.apache.spark.sql.catalyst.AbstractSparkSQLParser.parse(AbstractSparkSQLParser.scala:34)
	at org.apache.spark.sql.SQLContext$$anonfun$2.apply(SQLContext.scala:166)
	at org.apache.spark.sql.SQLContext$$anonfun$2.apply(SQLContext.scala:166)
	at org.apache.spark.sql.execution.datasources.DDLParser.parse(DDLParser.scala:42)
	at org.apache.spark.sql.SQLContext.parseSql(SQLContext.scala:189)
	at org.apache.spark.sql.hive.HiveContext.parseSql(HiveContext.scala:280)
	at org.apache.spark.sql.hive.test.TestHiveContext$QueryExecution.<init>(TestHive.scala:179)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1$$anonfun$30.apply(HiveComparisonTest.scala:303)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1$$anonfun$30.apply(HiveComparisonTest.scala:303)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:34)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:244)
	at scala.collection.AbstractTraversable.map(Traversable.scala:105)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1.apply$mcV$sp(HiveComparisonTest.scala:303)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1.apply(HiveComparisonTest.scala:240)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1.apply(HiveComparisonTest.scala:240)
	at org.scalatest.Transformer$$anonfun$apply$1.apply$mcV$sp(Transformer.scala:22)
	at org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)
	at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
	at org.scalatest.Transformer.apply(Transformer.scala:22)
	at org.scalatest.Transformer.apply(Transformer.scala:20)
	at org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:166)
	at org.apache.spark.SparkFunSuite.withFixture(SparkFunSuite.scala:42)
	at org.scalatest.FunSuiteLike$class.invokeWithFixture$1(FunSuiteLike.scala:163)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)
	at org.scalatest.FunSuiteLike$class.runTest(FunSuiteLike.scala:175)
	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.org$scalatest$BeforeAndAfter$$super$runTest(HiveCompatibilitySuite.scala:32)
	at org.scalatest.BeforeAndAfter$class.runTest(BeforeAndAfter.scala:200)
	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.runTest(HiveCompatibilitySuite.scala:32)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:413)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:401)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)
	at org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:396)
	at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:483)
	at org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:208)
	at org.scalatest.FunSuite.runTests(FunSuite.scala:1555)
	at org.scalatest.Suite$class.run(Suite.scala:1424)
	at org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.SuperEngine.runImpl(Engine.scala:545)
	at org.scalatest.FunSuiteLike$class.run(FunSuiteLike.scala:212)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest.org$scalatest$BeforeAndAfterAll$$super$run(HiveComparisonTest.scala:44)
	at org.scalatest.BeforeAndAfterAll$class.liftedTree1$1(BeforeAndAfterAll.scala:257)
	at org.scalatest.BeforeAndAfterAll$class.run(BeforeAndAfterAll.scala:256)
	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.org$scalatest$BeforeAndAfter$$super$run(HiveCompatibilitySuite.scala:32)
	at org.scalatest.BeforeAndAfter$class.run(BeforeAndAfter.scala:241)
	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.run(HiveCompatibilitySuite.scala:32)
	at org.scalatest.Suite$class.callExecuteOnSuite$1(Suite.scala:1492)
	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1528)
	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1526)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.scalatest.Suite$class.runNestedSuites(Suite.scala:1526)
	at org.scalatest.tools.DiscoverySuite.runNestedSuites(DiscoverySuite.scala:29)
	at org.scalatest.Suite$class.run(Suite.scala:1421)
	at org.scalatest.tools.DiscoverySuite.run(DiscoverySuite.scala:29)
	at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:55)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2563)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2557)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:2557)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1044)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1043)
	at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:2722)
	at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1043)
	at org.scalatest.tools.Runner$.main(Runner.scala:860)
	at org.scalatest.tools.Runner.main(Runner.scala)
[31m- 0344 *** FAILED ***[0m
[31m  org.apache.spark.sql.AnalysisException: cannot recognize input near 'SELECT' 'PNUM' 'FROM' in function specification; line 1 pos 45[0m
[31m  at org.apache.spark.sql.hive.HiveQl$.createPlan(HiveQl.scala:296)[0m
[31m  at org.apache.spark.sql.hive.ExtendedHiveQlParser$$anonfun$hiveQl$1.apply(ExtendedHiveQlParser.scala:41)[0m
[31m  at org.apache.spark.sql.hive.ExtendedHiveQlParser$$anonfun$hiveQl$1.apply(ExtendedHiveQlParser.scala:40)[0m
[31m  at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)[0m
[31m  at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:135)[0m
[31m  at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)[0m
[31m  at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)[0m
[31m  at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)[0m
[31m  at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)[0m
[31m  at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)[0m
[31m  ...[0m
NoViableAltException(231@[])
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.function(HiveParser_IdentifiersParser.java:3544)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.atomExpression(HiveParser_IdentifiersParser.java:6280)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceFieldExpression(HiveParser_IdentifiersParser.java:6383)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceUnaryPrefixExpression(HiveParser_IdentifiersParser.java:6768)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceUnarySuffixExpression(HiveParser_IdentifiersParser.java:6828)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceBitwiseXorExpression(HiveParser_IdentifiersParser.java:7012)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceStarExpression(HiveParser_IdentifiersParser.java:7172)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedencePlusExpression(HiveParser_IdentifiersParser.java:7332)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceAmpersandExpression(HiveParser_IdentifiersParser.java:7483)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceBitwiseOrExpression(HiveParser_IdentifiersParser.java:7634)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceEqualExpression(HiveParser_IdentifiersParser.java:8290)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceNotExpression(HiveParser_IdentifiersParser.java:9177)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceAndExpression(HiveParser_IdentifiersParser.java:9296)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceOrExpression(HiveParser_IdentifiersParser.java:9455)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.expression(HiveParser_IdentifiersParser.java:6105)
	at org.apache.hadoop.hive.ql.parse.HiveParser.expression(HiveParser.java:45846)
	at org.apache.hadoop.hive.ql.parse.HiveParser_FromClauseParser.searchCondition(HiveParser_FromClauseParser.java:6637)
	at org.apache.hadoop.hive.ql.parse.HiveParser_FromClauseParser.whereClause(HiveParser_FromClauseParser.java:6545)
	at org.apache.hadoop.hive.ql.parse.HiveParser.whereClause(HiveParser.java:45849)
	at org.apache.hadoop.hive.ql.parse.HiveParser.selectStatement(HiveParser.java:41543)
	at org.apache.hadoop.hive.ql.parse.HiveParser.regularBody(HiveParser.java:41402)
	at org.apache.hadoop.hive.ql.parse.HiveParser.queryStatementExpressionBody(HiveParser.java:40413)
	at org.apache.hadoop.hive.ql.parse.HiveParser.queryStatementExpression(HiveParser.java:40283)
	at org.apache.hadoop.hive.ql.parse.HiveParser.execStatement(HiveParser.java:1590)
	at org.apache.hadoop.hive.ql.parse.HiveParser.statement(HiveParser.java:1109)
	at org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:202)
	at org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:166)
	at org.apache.spark.sql.hive.HiveQl$.getAst(HiveQl.scala:258)
	at org.apache.spark.sql.hive.HiveQl$.createPlan(HiveQl.scala:283)
	at org.apache.spark.sql.hive.ExtendedHiveQlParser$$anonfun$hiveQl$1.apply(ExtendedHiveQlParser.scala:41)
	at org.apache.spark.sql.hive.ExtendedHiveQlParser$$anonfun$hiveQl$1.apply(ExtendedHiveQlParser.scala:40)
	at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)
	at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:135)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)
	at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Failure.append(Parsers.scala:202)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)
	at scala.util.parsing.combinator.Parsers$$anon$2$$anonfun$apply$14.apply(Parsers.scala:891)
	at scala.util.parsing.combinator.Parsers$$anon$2$$anonfun$apply$14.apply(Parsers.scala:891)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)
	at scala.util.parsing.combinator.Parsers$$anon$2.apply(Parsers.scala:890)
	at scala.util.parsing.combinator.PackratParsers$$anon$1.apply(PackratParsers.scala:110)
	at org.apache.spark.sql.catalyst.AbstractSparkSQLParser.parse(AbstractSparkSQLParser.scala:34)
	at org.apache.spark.sql.hive.HiveQl$.parseSql(HiveQl.scala:276)
	at org.apache.spark.sql.hive.HiveQLDialect.parse(HiveContext.scala:62)
	at com.intel.ssg.bdt.spark.sql.CalciteDialect.getLogicalPlan(CalciteDialect.scala:54)
	at com.intel.ssg.bdt.spark.sql.CalciteDialect.parse(CalciteDialect.scala:31)
	at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)
	at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)
	at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:115)
	at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:114)
	at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)
	at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:135)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)
	at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Failure.append(Parsers.scala:202)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)
	at scala.util.parsing.combinator.Parsers$$anon$2$$anonfun$apply$14.apply(Parsers.scala:891)
	at scala.util.parsing.combinator.Parsers$$anon$2$$anonfun$apply$14.apply(Parsers.scala:891)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)
	at scala.util.parsing.combinator.Parsers$$anon$2.apply(Parsers.scala:890)
	at scala.util.parsing.combinator.PackratParsers$$anon$1.apply(PackratParsers.scala:110)
	at org.apache.spark.sql.catalyst.AbstractSparkSQLParser.parse(AbstractSparkSQLParser.scala:34)
	at org.apache.spark.sql.SQLContext$$anonfun$2.apply(SQLContext.scala:166)
	at org.apache.spark.sql.SQLContext$$anonfun$2.apply(SQLContext.scala:166)
	at org.apache.spark.sql.execution.datasources.DDLParser.parse(DDLParser.scala:42)
	at org.apache.spark.sql.SQLContext.parseSql(SQLContext.scala:189)
	at org.apache.spark.sql.hive.HiveContext.parseSql(HiveContext.scala:280)
	at org.apache.spark.sql.hive.test.TestHiveContext$QueryExecution.<init>(TestHive.scala:179)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1$$anonfun$30.apply(HiveComparisonTest.scala:303)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1$$anonfun$30.apply(HiveComparisonTest.scala:303)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:34)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:244)
	at scala.collection.AbstractTraversable.map(Traversable.scala:105)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1.apply$mcV$sp(HiveComparisonTest.scala:303)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1.apply(HiveComparisonTest.scala:240)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1.apply(HiveComparisonTest.scala:240)
	at org.scalatest.Transformer$$anonfun$apply$1.apply$mcV$sp(Transformer.scala:22)
	at org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)
	at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
	at org.scalatest.Transformer.apply(Transformer.scala:22)
	at org.scalatest.Transformer.apply(Transformer.scala:20)
	at org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:166)
	at org.apache.spark.SparkFunSuite.withFixture(SparkFunSuite.scala:42)
	at org.scalatest.FunSuiteLike$class.invokeWithFixture$1(FunSuiteLike.scala:163)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)
	at org.scalatest.FunSuiteLike$class.runTest(FunSuiteLike.scala:175)
	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.org$scalatest$BeforeAndAfter$$super$runTest(HiveCompatibilitySuite.scala:32)
	at org.scalatest.BeforeAndAfter$class.runTest(BeforeAndAfter.scala:200)
	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.runTest(HiveCompatibilitySuite.scala:32)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:413)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:401)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)
	at org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:396)
	at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:483)
	at org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:208)
	at org.scalatest.FunSuite.runTests(FunSuite.scala:1555)
	at org.scalatest.Suite$class.run(Suite.scala:1424)
	at org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.SuperEngine.runImpl(Engine.scala:545)
	at org.scalatest.FunSuiteLike$class.run(FunSuiteLike.scala:212)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest.org$scalatest$BeforeAndAfterAll$$super$run(HiveComparisonTest.scala:44)
	at org.scalatest.BeforeAndAfterAll$class.liftedTree1$1(BeforeAndAfterAll.scala:257)
	at org.scalatest.BeforeAndAfterAll$class.run(BeforeAndAfterAll.scala:256)
	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.org$scalatest$BeforeAndAfter$$super$run(HiveCompatibilitySuite.scala:32)
	at org.scalatest.BeforeAndAfter$class.run(BeforeAndAfter.scala:241)
	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.run(HiveCompatibilitySuite.scala:32)
	at org.scalatest.Suite$class.callExecuteOnSuite$1(Suite.scala:1492)
	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1528)
	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1526)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.scalatest.Suite$class.runNestedSuites(Suite.scala:1526)
	at org.scalatest.tools.DiscoverySuite.runNestedSuites(DiscoverySuite.scala:29)
	at org.scalatest.Suite$class.run(Suite.scala:1421)
	at org.scalatest.tools.DiscoverySuite.run(DiscoverySuite.scala:29)
	at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:55)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2563)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2557)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:2557)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1044)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1043)
	at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:2722)
	at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1043)
	at org.scalatest.tools.Runner$.main(Runner.scala:860)
	at org.scalatest.tools.Runner.main(Runner.scala)
[31m- 0345 *** FAILED ***[0m
[31m  org.apache.spark.sql.AnalysisException: cannot recognize input near 'SELECT' 'PNUM' 'FROM' in function specification; line 1 pos 46[0m
[31m  at org.apache.spark.sql.hive.HiveQl$.createPlan(HiveQl.scala:296)[0m
[31m  at org.apache.spark.sql.hive.ExtendedHiveQlParser$$anonfun$hiveQl$1.apply(ExtendedHiveQlParser.scala:41)[0m
[31m  at org.apache.spark.sql.hive.ExtendedHiveQlParser$$anonfun$hiveQl$1.apply(ExtendedHiveQlParser.scala:40)[0m
[31m  at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)[0m
[31m  at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:135)[0m
[31m  at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)[0m
[31m  at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)[0m
[31m  at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)[0m
[31m  at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)[0m
[31m  at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)[0m
[31m  ...[0m
Calcite parsing passed, start to transform. SELECT PNUM, SUM(HOURS) FROM WORKS GROUP BY PNUM HAVING EXISTS (SELECT PNAME FROM PROJ WHERE PROJ.PNUM = WORKS.PNUM AND SUM(WORKS.HOURS) > PROJ.BUDGET / 200)
error SELECT PNUM, SUM(HOURS) FROM WORKS GROUP BY PNUM HAVING EXISTS (SELECT PNAME FROM PROJ WHERE PROJ.PNUM = WORKS.PNUM AND SUM(WORKS.HOURS) > PROJ.BUDGET / 200)[31m- 0346 ***  ***[0m
[31m  java.lang.RuntimeException: Parse failed.[0m
[31m  at scala.sys.package$.error(package.scala:27)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect$$anonfun$parse$1.apply(CalciteDialect.scala:33)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect$$anonfun$parse$1.apply(CalciteDialect.scala:32)[0m
[31m  at scala.Option.getOrElse(Option.scala:120)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect.parse(CalciteDialect.scala:31)[0m
[31m  at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)[0m
[31m  at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)[0m
[31m  at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:115)[0m
[31m  at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:114)[0m
[31m  at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)[0m
[31m  ...[0m
Calcite parsing passed, start to transform. SELECT PTYPE, CITY FROM PROJ GROUP BY PTYPE, CITY HAVING AVG(BUDGET) > 21000
[32m- 0347[0m
Calcite parsing passed, start to transform. SELECT DISTINCT PTYPE, CITY FROM PROJ GROUP BY PTYPE, CITY HAVING AVG(BUDGET) > 21000
[31m- 0348 *** FAILED ***[0m
[31m  Failed to execute query using catalyst:[0m
[31m  Error: cannot resolve 'BUDGET' given input columns PTYPE, CITY;[0m
[31m  org.apache.spark.sql.AnalysisException: cannot resolve 'BUDGET' given input columns PTYPE, CITY;[0m
[31m  	at org.apache.spark.sql.catalyst.analysis.package$AnalysisErrorAt.failAnalysis(package.scala:42)[0m
[31m  	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$apply$2.applyOrElse(CheckAnalysis.scala:56)[0m
[31m  	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$apply$2.applyOrElse(CheckAnalysis.scala:53)[0m
[31m  	at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformUp$1.apply(TreeNode.scala:293)[0m
[31m  	at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformUp$1.apply(TreeNode.scala:293)[0m
[31m  	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:51)[0m
[31m  	at org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:292)[0m
[31m  	at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$5.apply(TreeNode.scala:290)[0m
[31m  	at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$5.apply(TreeNode.scala:290)[0m
[31m  	at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4$$anonfun$apply$7.apply(TreeNode.scala:268)[0m
[31m  	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)[0m
[31m  	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)[0m
[31m  	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)[0m
[31m  	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)[0m
[31m  	at scala.collection.TraversableLike$class.map(TraversableLike.scala:244)[0m
[31m  	at scala.collection.AbstractTraversable.map(Traversable.scala:105)[0m
[31m  	at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:266)[0m
[31m  	at scala.collection.Iterator$$anon$11.next(Iterator.scala:328)[0m
[31m  	at scala.collection.Iterator$class.foreach(Iterator.scala:727)[0m
[31m  	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)[0m
[31m  	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:48)[0m
[31m  	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:103)[0m
[31m  	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:47)[0m
[31m  	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:273)[0m
[31m  	at scala.collection.AbstractIterator.to(Iterator.scala:1157)[0m
[31m  	at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:265)[0m
[31m  	at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1157)[0m
[31m  	at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:252)[0m
[31m  	at scala.collection.AbstractIterator.toArray(Iterator.scala:1157)[0m
[31m  	at org.apache.spark.sql.catalyst.trees.TreeNode.transformChildren(TreeNode.scala:279)[0m
[31m  	at org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:290)[0m
[31m  	at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$5.apply(TreeNode.scala:290)[0m
[31m  	at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$5.apply(TreeNode.scala:290)[0m
[31m  	at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:249)[0m
[31m  	at scala.collection.Iterator$$anon$11.next(Iterator.scala:328)[0m
[31m  	at scala.collection.Iterator$class.foreach(Iterator.scala:727)[0m
[31m  	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)[0m
[31m  	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:48)[0m
[31m  	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:103)[0m
[31m  	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:47)[0m
[31m  	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:273)[0m
[31m  	at scala.collection.AbstractIterator.to(Iterator.scala:1157)[0m
[31m  	at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:265)[0m
[31m  	at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1157)[0m
[31m  	at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:252)[0m
[31m  	at scala.collection.AbstractIterator.toArray(Iterator.scala:1157)[0m
[31m  	at org.apache.spark.sql.catalyst.trees.TreeNode.transformChildren(TreeNode.scala:279)[0m
[31m  	at org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:290)[0m
[31m  	at org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpressionUp$1(QueryPlan.scala:108)[0m
[31m  	at org.apache.spark.sql.catalyst.plans.QueryPlan.org$apache$spark$sql$catalyst$plans$QueryPlan$$recursiveTransform$2(QueryPlan.scala:118)[0m
[31m  	at org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$2.apply(QueryPlan.scala:126)[0m
[31m  	at scala.collection.Iterator$$anon$11.next(Iterator.scala:328)[0m
[31m  	at scala.collection.Iterator$class.foreach(Iterator.scala:727)[0m
[31m  	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)[0m
[31m  	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:48)[0m
[31m  	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:103)[0m
[31m  	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:47)[0m
[31m  	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:273)[0m
[31m  	at scala.collection.AbstractIterator.to(Iterator.scala:1157)[0m
[31m  	at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:265)[0m
[31m  	at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1157)[0m
[31m  	at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:252)[0m
[31m  	at scala.collection.AbstractIterator.toArray(Iterator.scala:1157)[0m
[31m  	at org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpressionsUp(QueryPlan.scala:126)[0m
[31m  	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1.apply(CheckAnalysis.scala:53)[0m
[31m  	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1.apply(CheckAnalysis.scala:49)[0m
[31m  	at org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:103)[0m
[31m  	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis$class.checkAnalysis(CheckAnalysis.scala:49)[0m
[31m  	at org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis(Analyzer.scala:44)[0m
[31m  	at org.apache.spark.sql.SQLContext$QueryExecution.assertAnalyzed(SQLContext.scala:908)[0m
[31m  	at org.apache.spark.sql.SQLContext$QueryExecution.withCachedData$lzycompute(SQLContext.scala:912)[0m
[31m  	at org.apache.spark.sql.SQLContext$QueryExecution.withCachedData(SQLContext.scala:911)[0m
[31m  	at org.apache.spark.sql.SQLContext$QueryExecution.optimizedPlan$lzycompute(SQLContext.scala:915)[0m
[31m  	at org.apache.spark.sql.SQLContext$QueryExecution.optimizedPlan(SQLContext.scala:915)[0m
[31m  	at org.apache.spark.sql.SQLContext$QueryExecution.sparkPlan$lzycompute(SQLContext.scala:920)[0m
[31m  	at org.apache.spark.sql.SQLContext$QueryExecution.sparkPlan(SQLContext.scala:918)[0m
[31m  	at org.apache.spark.sql.SQLContext$QueryExecution.executedPlan$lzycompute(SQLContext.scala:924)[0m
[31m  	at org.apache.spark.sql.SQLContext$QueryExecution.executedPlan(SQLContext.scala:924)[0m
[31m  	at org.apache.spark.sql.hive.HiveContext$QueryExecution.stringResult(HiveContext.scala:573)[0m
[31m  	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1$$anonfun$33.apply(HiveComparisonTest.scala:354)[0m
[31m  	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1$$anonfun$33.apply(HiveComparisonTest.scala:352)[0m
[31m  	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)[0m
[31m  	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)[0m
[31m  	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)[0m
[31m  	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)[0m
[31m  	at scala.collection.TraversableLike$class.map(TraversableLike.scala:244)[0m
[31m  	at scala.collection.AbstractTraversable.map(Traversable.scala:105)[0m
[31m  	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1.apply$mcV$sp(HiveComparisonTest.scala:352)[0m
[31m  	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1.apply(HiveComparisonTest.scala:240)[0m
[31m  	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1.apply(HiveComparisonTest.scala:240)[0m
[31m  	at org.scalatest.Transformer$$anonfun$apply$1.apply$mcV$sp(Transformer.scala:22)[0m
[31m  	at org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)[0m
[31m  	at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)[0m
[31m  	at org.scalatest.Transformer.apply(Transformer.scala:22)[0m
[31m  	at org.scalatest.Transformer.apply(Transformer.scala:20)[0m
[31m  	at org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:166)[0m
[31m  	at org.apache.spark.SparkFunSuite.withFixture(SparkFunSuite.scala:42)[0m
[31m  	at org.scalatest.FunSuiteLike$class.invokeWithFixture$1(FunSuiteLike.scala:163)[0m
[31m  	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)[0m
[31m  	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)[0m
[31m  	at org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)[0m
[31m  	at org.scalatest.FunSuiteLike$class.runTest(FunSuiteLike.scala:175)[0m
[31m  	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.org$scalatest$BeforeAndAfter$$super$runTest(HiveCompatibilitySuite.scala:32)[0m
[31m  	at org.scalatest.BeforeAndAfter$class.runTest(BeforeAndAfter.scala:200)[0m
[31m  	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.runTest(HiveCompatibilitySuite.scala:32)[0m
[31m  	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)[0m
[31m  	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)[0m
[31m  	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:413)[0m
[31m  	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:401)[0m
[31m  	at scala.collection.immutable.List.foreach(List.scala:318)[0m
[31m  	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)[0m
[31m  	at org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:396)[0m
[31m  	at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:483)[0m
[31m  	at org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:208)[0m
[31m  	at org.scalatest.FunSuite.runTests(FunSuite.scala:1555)[0m
[31m  	at org.scalatest.Suite$class.run(Suite.scala:1424)[0m
[31m  	at org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1555)[0m
[31m  	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)[0m
[31m  	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)[0m
[31m  	at org.scalatest.SuperEngine.runImpl(Engine.scala:545)[0m
[31m  	at org.scalatest.FunSuiteLike$class.run(FunSuiteLike.scala:212)[0m
[31m  	at org.apache.spark.sql.hive.execution.HiveComparisonTest.org$scalatest$BeforeAndAfterAll$$super$run(HiveComparisonTest.scala:44)[0m
[31m  	at org.scalatest.BeforeAndAfterAll$class.liftedTree1$1(BeforeAndAfterAll.scala:257)[0m
[31m  	at org.scalatest.BeforeAndAfterAll$class.run(BeforeAndAfterAll.scala:256)[0m
[31m  	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.org$scalatest$BeforeAndAfter$$super$run(HiveCompatibilitySuite.scala:32)[0m
[31m  	at org.scalatest.BeforeAndAfter$class.run(BeforeAndAfter.scala:241)[0m
[31m  	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.run(HiveCompatibilitySuite.scala:32)[0m
[31m  	at org.scalatest.Suite$class.callExecuteOnSuite$1(Suite.scala:1492)[0m
[31m  	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1528)[0m
[31m  	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1526)[0m
[31m  	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)[0m
[31m  	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)[0m
[31m  	at org.scalatest.Suite$class.runNestedSuites(Suite.scala:1526)[0m
[31m  	at org.scalatest.tools.DiscoverySuite.runNestedSuites(DiscoverySuite.scala:29)[0m
[31m  	at org.scalatest.Suite$class.run(Suite.scala:1421)[0m
[31m  	at org.scalatest.tools.DiscoverySuite.run(DiscoverySuite.scala:29)[0m
[31m  	at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:55)[0m
[31m  	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2563)[0m
[31m  	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2557)[0m
[31m  	at scala.collection.immutable.List.foreach(List.scala:318)[0m
[31m  	at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:2557)[0m
[31m  	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1044)[0m
[31m  	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1043)[0m
[31m  	at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:2722)[0m
[31m  	at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1043)[0m
[31m  	at org.scalatest.tools.Runner$.main(Runner.scala:860)[0m
[31m  	at org.scalatest.tools.Runner.main(Runner.scala)[0m
  
[31m  == Parsed Logical Plan ==[0m
[31m  'Filter ('AVG('BUDGET) > 21000)[0m
[31m   'Distinct[0m
[31m    'Aggregate ['PTYPE,'CITY], ['PTYPE,'CITY][0m
[31m     'UnresolvedRelation [PROJ], None[0m
  
[31m  == Analyzed Logical Plan ==[0m
[31m  PTYPE: string, CITY: string[0m
[31m  'Filter ('AVG('BUDGET) > 21000)[0m
[31m   Distinct[0m
[31m    Aggregate [PTYPE#63570,CITY#63572], [PTYPE#63570,CITY#63572][0m
[31m     MetastoreRelation HU, proj, None[0m
  
[31m  == Optimized Logical Plan ==[0m
[31m  org.apache.spark.sql.AnalysisException: cannot resolve 'BUDGET' given input columns PTYPE, CITY;[0m
[31m  == Physical Plan ==[0m
[31m  org.apache.spark.sql.AnalysisException: cannot resolve 'BUDGET' given input columns PTYPE, CITY;[0m
[31m  Code Generation: org.apache.spark.sql.AnalysisException: cannot resolve 'BUDGET' given input columns PTYPE, CITY;[0m
[31m  == HIVE - 1 row(s) ==[0m
[31m  Code	Vienna (HiveComparisonTest.scala:366)[0m
Calcite parsing passed, start to transform. SELECT DISTINCT SUM(BUDGET) FROM PROJ GROUP BY PTYPE, CITY HAVING AVG(BUDGET) > 21000
[31m- 0349 *** FAILED ***[0m
[31m  Failed to execute query using catalyst:[0m
[31m  Error: cannot resolve 'BUDGET' given input columns c0;[0m
[31m  org.apache.spark.sql.AnalysisException: cannot resolve 'BUDGET' given input columns c0;[0m
[31m  	at org.apache.spark.sql.catalyst.analysis.package$AnalysisErrorAt.failAnalysis(package.scala:42)[0m
[31m  	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$apply$2.applyOrElse(CheckAnalysis.scala:56)[0m
[31m  	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$apply$2.applyOrElse(CheckAnalysis.scala:53)[0m
[31m  	at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformUp$1.apply(TreeNode.scala:293)[0m
[31m  	at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformUp$1.apply(TreeNode.scala:293)[0m
[31m  	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:51)[0m
[31m  	at org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:292)[0m
[31m  	at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$5.apply(TreeNode.scala:290)[0m
[31m  	at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$5.apply(TreeNode.scala:290)[0m
[31m  	at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4$$anonfun$apply$7.apply(TreeNode.scala:268)[0m
[31m  	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)[0m
[31m  	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)[0m
[31m  	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)[0m
[31m  	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)[0m
[31m  	at scala.collection.TraversableLike$class.map(TraversableLike.scala:244)[0m
[31m  	at scala.collection.AbstractTraversable.map(Traversable.scala:105)[0m
[31m  	at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:266)[0m
[31m  	at scala.collection.Iterator$$anon$11.next(Iterator.scala:328)[0m
[31m  	at scala.collection.Iterator$class.foreach(Iterator.scala:727)[0m
[31m  	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)[0m
[31m  	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:48)[0m
[31m  	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:103)[0m
[31m  	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:47)[0m
[31m  	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:273)[0m
[31m  	at scala.collection.AbstractIterator.to(Iterator.scala:1157)[0m
[31m  	at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:265)[0m
[31m  	at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1157)[0m
[31m  	at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:252)[0m
[31m  	at scala.collection.AbstractIterator.toArray(Iterator.scala:1157)[0m
[31m  	at org.apache.spark.sql.catalyst.trees.TreeNode.transformChildren(TreeNode.scala:279)[0m
[31m  	at org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:290)[0m
[31m  	at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$5.apply(TreeNode.scala:290)[0m
[31m  	at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$5.apply(TreeNode.scala:290)[0m
[31m  	at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:249)[0m
[31m  	at scala.collection.Iterator$$anon$11.next(Iterator.scala:328)[0m
[31m  	at scala.collection.Iterator$class.foreach(Iterator.scala:727)[0m
[31m  	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)[0m
[31m  	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:48)[0m
[31m  	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:103)[0m
[31m  	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:47)[0m
[31m  	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:273)[0m
[31m  	at scala.collection.AbstractIterator.to(Iterator.scala:1157)[0m
[31m  	at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:265)[0m
[31m  	at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1157)[0m
[31m  	at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:252)[0m
[31m  	at scala.collection.AbstractIterator.toArray(Iterator.scala:1157)[0m
[31m  	at org.apache.spark.sql.catalyst.trees.TreeNode.transformChildren(TreeNode.scala:279)[0m
[31m  	at org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:290)[0m
[31m  	at org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpressionUp$1(QueryPlan.scala:108)[0m
[31m  	at org.apache.spark.sql.catalyst.plans.QueryPlan.org$apache$spark$sql$catalyst$plans$QueryPlan$$recursiveTransform$2(QueryPlan.scala:118)[0m
[31m  	at org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$2.apply(QueryPlan.scala:126)[0m
[31m  	at scala.collection.Iterator$$anon$11.next(Iterator.scala:328)[0m
[31m  	at scala.collection.Iterator$class.foreach(Iterator.scala:727)[0m
[31m  	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)[0m
[31m  	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:48)[0m
[31m  	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:103)[0m
[31m  	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:47)[0m
[31m  	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:273)[0m
[31m  	at scala.collection.AbstractIterator.to(Iterator.scala:1157)[0m
[31m  	at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:265)[0m
[31m  	at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1157)[0m
[31m  	at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:252)[0m
[31m  	at scala.collection.AbstractIterator.toArray(Iterator.scala:1157)[0m
[31m  	at org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpressionsUp(QueryPlan.scala:126)[0m
[31m  	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1.apply(CheckAnalysis.scala:53)[0m
[31m  	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1.apply(CheckAnalysis.scala:49)[0m
[31m  	at org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:103)[0m
[31m  	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis$class.checkAnalysis(CheckAnalysis.scala:49)[0m
[31m  	at org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis(Analyzer.scala:44)[0m
[31m  	at org.apache.spark.sql.SQLContext$QueryExecution.assertAnalyzed(SQLContext.scala:908)[0m
[31m  	at org.apache.spark.sql.SQLContext$QueryExecution.withCachedData$lzycompute(SQLContext.scala:912)[0m
[31m  	at org.apache.spark.sql.SQLContext$QueryExecution.withCachedData(SQLContext.scala:911)[0m
[31m  	at org.apache.spark.sql.SQLContext$QueryExecution.optimizedPlan$lzycompute(SQLContext.scala:915)[0m
[31m  	at org.apache.spark.sql.SQLContext$QueryExecution.optimizedPlan(SQLContext.scala:915)[0m
[31m  	at org.apache.spark.sql.SQLContext$QueryExecution.sparkPlan$lzycompute(SQLContext.scala:920)[0m
[31m  	at org.apache.spark.sql.SQLContext$QueryExecution.sparkPlan(SQLContext.scala:918)[0m
[31m  	at org.apache.spark.sql.SQLContext$QueryExecution.executedPlan$lzycompute(SQLContext.scala:924)[0m
[31m  	at org.apache.spark.sql.SQLContext$QueryExecution.executedPlan(SQLContext.scala:924)[0m
[31m  	at org.apache.spark.sql.hive.HiveContext$QueryExecution.stringResult(HiveContext.scala:573)[0m
[31m  	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1$$anonfun$33.apply(HiveComparisonTest.scala:354)[0m
[31m  	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1$$anonfun$33.apply(HiveComparisonTest.scala:352)[0m
[31m  	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)[0m
[31m  	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)[0m
[31m  	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)[0m
[31m  	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)[0m
[31m  	at scala.collection.TraversableLike$class.map(TraversableLike.scala:244)[0m
[31m  	at scala.collection.AbstractTraversable.map(Traversable.scala:105)[0m
[31m  	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1.apply$mcV$sp(HiveComparisonTest.scala:352)[0m
[31m  	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1.apply(HiveComparisonTest.scala:240)[0m
[31m  	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1.apply(HiveComparisonTest.scala:240)[0m
[31m  	at org.scalatest.Transformer$$anonfun$apply$1.apply$mcV$sp(Transformer.scala:22)[0m
[31m  	at org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)[0m
[31m  	at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)[0m
[31m  	at org.scalatest.Transformer.apply(Transformer.scala:22)[0m
[31m  	at org.scalatest.Transformer.apply(Transformer.scala:20)[0m
[31m  	at org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:166)[0m
[31m  	at org.apache.spark.SparkFunSuite.withFixture(SparkFunSuite.scala:42)[0m
[31m  	at org.scalatest.FunSuiteLike$class.invokeWithFixture$1(FunSuiteLike.scala:163)[0m
[31m  	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)[0m
[31m  	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)[0m
[31m  	at org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)[0m
[31m  	at org.scalatest.FunSuiteLike$class.runTest(FunSuiteLike.scala:175)[0m
[31m  	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.org$scalatest$BeforeAndAfter$$super$runTest(HiveCompatibilitySuite.scala:32)[0m
[31m  	at org.scalatest.BeforeAndAfter$class.runTest(BeforeAndAfter.scala:200)[0m
[31m  	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.runTest(HiveCompatibilitySuite.scala:32)[0m
[31m  	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)[0m
[31m  	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)[0m
[31m  	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:413)[0m
[31m  	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:401)[0m
[31m  	at scala.collection.immutable.List.foreach(List.scala:318)[0m
[31m  	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)[0m
[31m  	at org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:396)[0m
[31m  	at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:483)[0m
[31m  	at org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:208)[0m
[31m  	at org.scalatest.FunSuite.runTests(FunSuite.scala:1555)[0m
[31m  	at org.scalatest.Suite$class.run(Suite.scala:1424)[0m
[31m  	at org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1555)[0m
[31m  	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)[0m
[31m  	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)[0m
[31m  	at org.scalatest.SuperEngine.runImpl(Engine.scala:545)[0m
[31m  	at org.scalatest.FunSuiteLike$class.run(FunSuiteLike.scala:212)[0m
[31m  	at org.apache.spark.sql.hive.execution.HiveComparisonTest.org$scalatest$BeforeAndAfterAll$$super$run(HiveComparisonTest.scala:44)[0m
[31m  	at org.scalatest.BeforeAndAfterAll$class.liftedTree1$1(BeforeAndAfterAll.scala:257)[0m
[31m  	at org.scalatest.BeforeAndAfterAll$class.run(BeforeAndAfterAll.scala:256)[0m
[31m  	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.org$scalatest$BeforeAndAfter$$super$run(HiveCompatibilitySuite.scala:32)[0m
[31m  	at org.scalatest.BeforeAndAfter$class.run(BeforeAndAfter.scala:241)[0m
[31m  	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.run(HiveCompatibilitySuite.scala:32)[0m
[31m  	at org.scalatest.Suite$class.callExecuteOnSuite$1(Suite.scala:1492)[0m
[31m  	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1528)[0m
[31m  	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1526)[0m
[31m  	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)[0m
[31m  	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)[0m
[31m  	at org.scalatest.Suite$class.runNestedSuites(Suite.scala:1526)[0m
[31m  	at org.scalatest.tools.DiscoverySuite.runNestedSuites(DiscoverySuite.scala:29)[0m
[31m  	at org.scalatest.Suite$class.run(Suite.scala:1421)[0m
[31m  	at org.scalatest.tools.DiscoverySuite.run(DiscoverySuite.scala:29)[0m
[31m  	at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:55)[0m
[31m  	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2563)[0m
[31m  	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2557)[0m
[31m  	at scala.collection.immutable.List.foreach(List.scala:318)[0m
[31m  	at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:2557)[0m
[31m  	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1044)[0m
[31m  	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1043)[0m
[31m  	at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:2722)[0m
[31m  	at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1043)[0m
[31m  	at org.scalatest.tools.Runner$.main(Runner.scala:860)[0m
[31m  	at org.scalatest.tools.Runner.main(Runner.scala)[0m
  
[31m  == Parsed Logical Plan ==[0m
[31m  'Filter ('AVG('BUDGET) > 21000)[0m
[31m   'Distinct[0m
[31m    'Aggregate ['PTYPE,'CITY], ['SUM('BUDGET) AS c0#63679][0m
[31m     'UnresolvedRelation [PROJ], None[0m
  
[31m  == Analyzed Logical Plan ==[0m
[31m  c0: double[0m
[31m  'Filter ('AVG('BUDGET) > 21000)[0m
[31m   Distinct[0m
[31m    Aggregate [PTYPE#63682,CITY#63684], [sum(BUDGET#63683) AS c0#63679][0m
[31m     MetastoreRelation HU, proj, None[0m
  
[31m  == Optimized Logical Plan ==[0m
[31m  org.apache.spark.sql.AnalysisException: cannot resolve 'BUDGET' given input columns c0;[0m
[31m  == Physical Plan ==[0m
[31m  org.apache.spark.sql.AnalysisException: cannot resolve 'BUDGET' given input columns c0;[0m
[31m  Code Generation: org.apache.spark.sql.AnalysisException: cannot resolve 'BUDGET' given input columns c0;[0m
[31m  == HIVE - 1 row(s) ==[0m
[31m  30000 (HiveComparisonTest.scala:366)[0m
Calcite parsing passed, start to transform. SELECT CHARTEST FROM BB
[32m- 0350[0m
Calcite parsing passed, start to transform. SELECT INTTEST FROM EE
Calcite parsing passed, start to transform. SELECT INTTEST FROM EE
Calcite parsing passed, start to transform. SELECT INTTEST FROM EE
[31m- 0351 *** FAILED ***[0m
[31m  Results do not match for 0351:[0m
[31m  == Parsed Logical Plan ==[0m
[31m  'Project ['INTTEST][0m
[31m   'UnresolvedRelation [EE], None[0m
  
[31m  == Analyzed Logical Plan ==[0m
[31m  INTTEST: double[0m
[31m  Project [INTTEST#63856][0m
[31m   MetastoreRelation HU, ee, None[0m
  
[31m  == Optimized Logical Plan ==[0m
[31m  Project [INTTEST#63856][0m
[31m   MetastoreRelation HU, ee, None[0m
  
[31m  == Physical Plan ==[0m
[31m  HiveTableScan [INTTEST#63856], (MetastoreRelation HU, ee, None)[0m
  
[31m  Code Generation: true[0m
[31m  INTTEST[0m
[31m  !== HIVE - 4 row(s) ==   == CATALYST - 4 row(s) ==[0m
[31m  !-999999999              -9.99999999E8[0m
[31m  !123456                  123456.0[0m
[31m  !999999999               9.99999999E8[0m
[31m   NULL                    NULL (HiveComparisonTest.scala:433)[0m
Calcite parsing passed, start to transform. SELECT REALTEST FROM GG
[32m- 0352[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM GG WHERE REALTEST IS NULL
[32m- 0353[0m
Calcite parsing passed, start to transform. SELECT SMALLTEST FROM HH
Calcite parsing passed, start to transform. SELECT SMALLTEST FROM HH
Calcite parsing passed, start to transform. SELECT SMALLTEST FROM HH
[31m- 0354 *** FAILED ***[0m
[31m  Results do not match for 0354:[0m
[31m  == Parsed Logical Plan ==[0m
[31m  'Project ['SMALLTEST][0m
[31m   'UnresolvedRelation [HH], None[0m
  
[31m  == Analyzed Logical Plan ==[0m
[31m  SMALLTEST: double[0m
[31m  Project [SMALLTEST#64211][0m
[31m   MetastoreRelation HU, hh, None[0m
  
[31m  == Optimized Logical Plan ==[0m
[31m  Project [SMALLTEST#64211][0m
[31m   MetastoreRelation HU, hh, None[0m
  
[31m  == Physical Plan ==[0m
[31m  HiveTableScan [SMALLTEST#64211], (MetastoreRelation HU, hh, None)[0m
  
[31m  Code Generation: true[0m
[31m  SMALLTEST[0m
[31m  !== HIVE - 4 row(s) ==   == CATALYST - 4 row(s) ==[0m
[31m  !-9999                   -9999.0[0m
[31m  !123                     123.0[0m
[31m  !9999                    9999.0[0m
[31m   NULL                    NULL (HiveComparisonTest.scala:433)[0m
Calcite parsing passed, start to transform. SELECT DOUBLETEST FROM II
Calcite parsing passed, start to transform. SELECT DOUBLETEST FROM II
Calcite parsing passed, start to transform. SELECT DOUBLETEST FROM II
[31m- 0355 *** FAILED ***[0m
[31m  Results do not match for 0355:[0m
[31m  == Parsed Logical Plan ==[0m
[31m  'Project ['DOUBLETEST][0m
[31m   'UnresolvedRelation [II], None[0m
  
[31m  == Analyzed Logical Plan ==[0m
[31m  DOUBLETEST: float[0m
[31m  Project [DOUBLETEST#64389][0m
[31m   MetastoreRelation HU, ii, None[0m
  
[31m  == Optimized Logical Plan ==[0m
[31m  Project [DOUBLETEST#64389][0m
[31m   MetastoreRelation HU, ii, None[0m
  
[31m  == Physical Plan ==[0m
[31m  HiveTableScan [DOUBLETEST#64389], (MetastoreRelation HU, ii, None)[0m
  
[31m  Code Generation: true[0m
[31m  DOUBLETEST[0m
[31m  !== HIVE - 3 row(s) ==   == CATALYST - 3 row(s) ==[0m
[31m  !-0.1073741823           -0.107374184[0m
[31m  !123456.123456           123456.125[0m
[31m   NULL                    NULL (HiveComparisonTest.scala:433)[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM II WHERE DOUBLETEST IS NULL
[32m- 0356[0m
Calcite parsing passed, start to transform. SELECT FLOATTEST FROM JJ
Calcite parsing passed, start to transform. SELECT FLOATTEST FROM JJ
Calcite parsing passed, start to transform. SELECT FLOATTEST FROM JJ
[31m- 0357 *** FAILED ***[0m
[31m  Results do not match for 0357:[0m
[31m  == Parsed Logical Plan ==[0m
[31m  'Project ['FLOATTEST][0m
[31m   'UnresolvedRelation [JJ], None[0m
  
[31m  == Analyzed Logical Plan ==[0m
[31m  FLOATTEST: float[0m
[31m  Project [FLOATTEST#64672][0m
[31m   MetastoreRelation HU, jj, None[0m
  
[31m  == Optimized Logical Plan ==[0m
[31m  Project [FLOATTEST#64672][0m
[31m   MetastoreRelation HU, jj, None[0m
  
[31m  == Physical Plan ==[0m
[31m  HiveTableScan [FLOATTEST#64672], (MetastoreRelation HU, jj, None)[0m
  
[31m  Code Generation: true[0m
[31m  FLOATTEST[0m
[31m  !== HIVE - 12 row(s) ==   == CATALYST - 12 row(s) ==[0m
[31m   -0.1048575               -0.1048575[0m
[31m   -123.456                 -123.456[0m
[31m   -44.5                    -44.5[0m
[31m   -66.25                   -66.25[0m
[31m  !-87                      -87.0[0m
[31m   0.2222                   0.2222[0m
[31m   12.345678                12.345678[0m
[31m   123.456                  123.456[0m
[31m  !123456                   123456.0[0m
[31m   66.2                     66.2[0m
[31m   66.3                     66.3[0m
[31m   NULL                     NULL (HiveComparisonTest.scala:433)[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM JJ WHERE FLOATTEST IS NULL
[32m- 0358[0m
Calcite parsing passed, start to transform. SELECT NUMTEST FROM MM
Calcite parsing passed, start to transform. SELECT NUMTEST FROM MM
Calcite parsing passed, start to transform. SELECT NUMTEST FROM MM
[31m- 0359 *** FAILED ***[0m
[31m  Results do not match for 0359:[0m
[31m  == Parsed Logical Plan ==[0m
[31m  'Project ['NUMTEST][0m
[31m   'UnresolvedRelation [MM], None[0m
  
[31m  == Analyzed Logical Plan ==[0m
[31m  NUMTEST: double[0m
[31m  Project [NUMTEST#64985][0m
[31m   MetastoreRelation HU, mm, None[0m
  
[31m  == Optimized Logical Plan ==[0m
[31m  Project [NUMTEST#64985][0m
[31m   MetastoreRelation HU, mm, None[0m
  
[31m  == Physical Plan ==[0m
[31m  HiveTableScan [NUMTEST#64985], (MetastoreRelation HU, mm, None)[0m
  
[31m  Code Generation: true[0m
[31m  NUMTEST[0m
[31m  !== HIVE - 38 row(s) ==   == CATALYST - 38 row(s) ==[0m
[31m  !7                        7.0[0m
[31m  !7                        7.0[0m
[31m  !7                        7.0[0m
[31m  !7                        7.0[0m
[31m  !7                        7.0[0m
[31m  !7                        7.0[0m
[31m  !7                        7.0[0m
[31m  !7                        7.0[0m
[31m  !7                        7.0[0m
[31m  !7                        7.0[0m
[31m  !7                        7.0[0m
[31m  !7                        7.0[0m
[31m  !7                        7.0[0m
[31m  !7                        7.0[0m
[31m  !7                        7.0[0m
[31m  !7                        7.0[0m
[31m  !7                        7.0[0m
[31m  !7                        7.0[0m
[31m  !7                        7.0[0m
[31m   NULL                     NULL[0m
[31m   NULL                     NULL[0m
[31m   NULL                     NULL[0m
[31m   NULL                     NULL[0m
[31m   NULL                     NULL[0m
[31m   NULL                     NULL[0m
[31m   NULL                     NULL[0m
[31m   NULL                     NULL[0m
[31m   NULL                     NULL[0m
[31m   NULL                     NULL[0m
[31m   NULL                     NULL[0m
[31m   NULL                     NULL[0m
[31m   NULL                     NULL[0m
[31m   NULL                     NULL[0m
[31m   NULL                     NULL[0m
[31m   NULL                     NULL[0m
[31m   NULL                     NULL[0m
[31m   NULL                     NULL[0m
[31m   NULL                     NULL (HiveComparisonTest.scala:433)[0m
Calcite parsing passed, start to transform. SELECT NUMTEST FROM SS
[32m- 0360[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM STAFF WHERE GRADE IS NULL
[32m- 0361[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM TEMP_SS
[32m- 0362[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM STAFF
[32m- 0363[0m
Calcite parsing passed, start to transform. SELECT * FROM STAFF
Calcite parsing passed, start to transform. SELECT * FROM STAFF
Calcite parsing passed, start to transform. SELECT * FROM STAFF
[31m- 0364 *** FAILED ***[0m
[31m  Results do not match for 0364:[0m
[31m  == Parsed Logical Plan ==[0m
[31m  'Project [*][0m
[31m   'UnresolvedRelation [STAFF], None[0m
  
[31m  == Analyzed Logical Plan ==[0m
[31m  empnum: string, empname: string, grade: double, city: string[0m
[31m  Project [empnum#65938,empname#65939,grade#65940,city#65941][0m
[31m   MetastoreRelation HU, staff, None[0m
  
[31m  == Optimized Logical Plan ==[0m
[31m  MetastoreRelation HU, staff, None[0m
  
[31m  == Physical Plan ==[0m
[31m  HiveTableScan [empnum#65938,empname#65939,grade#65940,city#65941], (MetastoreRelation HU, staff, None)[0m
  
[31m  Code Generation: true[0m
[31m  empnum	empname	grade	city[0m
[31m  !== HIVE - 7 row(s) ==      == CATALYST - 7 row(s) ==[0m
[31m   E1	NULL	NULL	NULL          E1	NULL	NULL	NULL[0m
[31m  !E36	Huyan	15	Xi_an%        E36	Huyan	15.0	Xi_an%[0m
[31m  !E6	ALICE	15	Gaithersburg   E6	ALICE	15.0	Gaithersburg[0m
[31m  !E7	yanping	15	China        E7	yanping	15.0	China[0m
[31m  !E8	Yang Ling	15	Xi'an      E8	Yang Ling	15.0	Xi'an[0m
[31m   E9	JOHNNY	NULL	NULL        E9	JOHNNY	NULL	NULL[0m
[31m   e1	NULL	NULL	NULL          e1	NULL	NULL	NULL (HiveComparisonTest.scala:433)[0m
Calcite parsing passed, start to transform. SELECT * FROM WORKS ORDER BY EMPNUM, PNUM
Calcite parsing passed, start to transform. SELECT * FROM WORKS ORDER BY EMPNUM, PNUM
Calcite parsing passed, start to transform. SELECT * FROM WORKS ORDER BY EMPNUM, PNUM
[31m- 0365 *** FAILED ***[0m
[31m  Results do not match for 0365:[0m
[31m  == Parsed Logical Plan ==[0m
[31m  'Sort ['EMPNUM ASC,'PNUM ASC], true[0m
[31m   'Project [*][0m
[31m    'UnresolvedRelation [WORKS], None[0m
  
[31m  == Analyzed Logical Plan ==[0m
[31m  empnum: string, pnum: string, hours: double[0m
[31m  Sort [EMPNUM#66339 ASC,PNUM#66340 ASC], true[0m
[31m   Project [empnum#66339,pnum#66340,hours#66341][0m
[31m    MetastoreRelation HU, works, None[0m
  
[31m  == Optimized Logical Plan ==[0m
[31m  Sort [EMPNUM#66339 ASC,PNUM#66340 ASC], true[0m
[31m   MetastoreRelation HU, works, None[0m
  
[31m  == Physical Plan ==[0m
[31m  TungstenSort [EMPNUM#66339 ASC,PNUM#66340 ASC], true, 0[0m
[31m   ConvertToUnsafe[0m
[31m    Exchange rangepartitioning(EMPNUM#66339 ASC,PNUM#66340 ASC)[0m
[31m     HiveTableScan [empnum#66339,pnum#66340,hours#66341], (MetastoreRelation HU, works, None)[0m
  
[31m  Code Generation: true[0m
[31m  empnum	pnum	hours[0m
[31m  !== HIVE - 24 row(s) ==   == CATALYST - 24 row(s) ==[0m
[31m   E1	P1	NULL               E1	P1	NULL[0m
[31m   E1	P2	NULL               E1	P2	NULL[0m
[31m   E1	P4	NULL               E1	P4	NULL[0m
[31m   E1	P5	NULL               E1	P5	NULL[0m
[31m   E1	P6	NULL               E1	P6	NULL[0m
[31m   E1	P7	NULL               E1	P7	NULL[0m
[31m   E1	p2	NULL               E1	p2	NULL[0m
[31m   E18	P18	NULL             E18	P18	NULL[0m
[31m   E2	P1	NULL               E2	P1	NULL[0m
[31m   E2	P2	NULL               E2	P2	NULL[0m
[31m   E22	P22	NULL             E22	P22	NULL[0m
[31m   E3	P6	NULL               E3	P6	NULL[0m
[31m   E4	P4	NULL               E4	P4	NULL[0m
[31m   E4	p4	NULL               E4	p4	NULL[0m
[31m   E5	P5	NULL               E5	P5	NULL[0m
[31m   E6	P6	NULL               E6	P6	NULL[0m
[31m   E7	P4	NULL               E7	P4	NULL[0m
[31m   E8	P8	NULL               E8	P8	NULL[0m
[31m  !E9	P7	10                 E9	P7	10.0[0m
[31m   E9	P9	NULL               E9	P9	NULL[0m
[31m   UPP	low	NULL             UPP	low	NULL[0m
[31m   e1	P2	NULL               e1	P2	NULL[0m
[31m   e1	P5	NULL               e1	P5	NULL[0m
[31m   e1	p2	NULL               e1	p2	NULL (HiveComparisonTest.scala:433)[0m
Calcite parsing passed, start to transform. SELECT EMPNAME FROM STAFF UNION SELECT EMPNAME FROM STAFF UNION ALL SELECT EMPNAME FROM STAFF
[32m- 0366[0m
Calcite parsing passed, start to transform. SELECT EMPNAME FROM STAFF UNION ALL SELECT EMPNAME FROM STAFF UNION SELECT EMPNAME FROM STAFF
[32m- 0367[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM PROJ WHERE CITY IS NULL
[32m- 0368[0m
NoViableAltException(231@[])
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.function(HiveParser_IdentifiersParser.java:3544)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.atomExpression(HiveParser_IdentifiersParser.java:6280)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceFieldExpression(HiveParser_IdentifiersParser.java:6383)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceUnaryPrefixExpression(HiveParser_IdentifiersParser.java:6768)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceUnarySuffixExpression(HiveParser_IdentifiersParser.java:6828)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceBitwiseXorExpression(HiveParser_IdentifiersParser.java:7012)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceStarExpression(HiveParser_IdentifiersParser.java:7172)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedencePlusExpression(HiveParser_IdentifiersParser.java:7332)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceAmpersandExpression(HiveParser_IdentifiersParser.java:7483)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceBitwiseOrExpression(HiveParser_IdentifiersParser.java:7634)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceEqualExpression(HiveParser_IdentifiersParser.java:8290)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceNotExpression(HiveParser_IdentifiersParser.java:9177)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceAndExpression(HiveParser_IdentifiersParser.java:9296)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceOrExpression(HiveParser_IdentifiersParser.java:9455)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.expression(HiveParser_IdentifiersParser.java:6105)
	at org.apache.hadoop.hive.ql.parse.HiveParser.expression(HiveParser.java:45846)
	at org.apache.hadoop.hive.ql.parse.HiveParser_FromClauseParser.searchCondition(HiveParser_FromClauseParser.java:6637)
	at org.apache.hadoop.hive.ql.parse.HiveParser_FromClauseParser.whereClause(HiveParser_FromClauseParser.java:6545)
	at org.apache.hadoop.hive.ql.parse.HiveParser.whereClause(HiveParser.java:45849)
	at org.apache.hadoop.hive.ql.parse.HiveParser.selectStatement(HiveParser.java:41543)
	at org.apache.hadoop.hive.ql.parse.HiveParser.regularBody(HiveParser.java:41402)
	at org.apache.hadoop.hive.ql.parse.HiveParser.queryStatementExpressionBody(HiveParser.java:40413)
	at org.apache.hadoop.hive.ql.parse.HiveParser.queryStatementExpression(HiveParser.java:40283)
	at org.apache.hadoop.hive.ql.parse.HiveParser.execStatement(HiveParser.java:1590)
	at org.apache.hadoop.hive.ql.parse.HiveParser.statement(HiveParser.java:1109)
	at org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:202)
	at org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:166)
	at org.apache.spark.sql.hive.HiveQl$.getAst(HiveQl.scala:258)
	at org.apache.spark.sql.hive.HiveQl$.createPlan(HiveQl.scala:283)
	at org.apache.spark.sql.hive.ExtendedHiveQlParser$$anonfun$hiveQl$1.apply(ExtendedHiveQlParser.scala:41)
	at org.apache.spark.sql.hive.ExtendedHiveQlParser$$anonfun$hiveQl$1.apply(ExtendedHiveQlParser.scala:40)
	at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)
	at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:135)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)
	at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Failure.append(Parsers.scala:202)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)
	at scala.util.parsing.combinator.Parsers$$anon$2$$anonfun$apply$14.apply(Parsers.scala:891)
	at scala.util.parsing.combinator.Parsers$$anon$2$$anonfun$apply$14.apply(Parsers.scala:891)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)
	at scala.util.parsing.combinator.Parsers$$anon$2.apply(Parsers.scala:890)
	at scala.util.parsing.combinator.PackratParsers$$anon$1.apply(PackratParsers.scala:110)
	at org.apache.spark.sql.catalyst.AbstractSparkSQLParser.parse(AbstractSparkSQLParser.scala:34)
	at org.apache.spark.sql.hive.HiveQl$.parseSql(HiveQl.scala:276)
	at org.apache.spark.sql.hive.HiveQLDialect.parse(HiveContext.scala:62)
	at com.intel.ssg.bdt.spark.sql.CalciteDialect.getLogicalPlan(CalciteDialect.scala:54)
	at com.intel.ssg.bdt.spark.sql.CalciteDialect.parse(CalciteDialect.scala:31)
	at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)
	at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)
	at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:115)
	at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:114)
	at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)
	at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:135)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)
	at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Failure.append(Parsers.scala:202)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)
	at scala.util.parsing.combinator.Parsers$$anon$2$$anonfun$apply$14.apply(Parsers.scala:891)
	at scala.util.parsing.combinator.Parsers$$anon$2$$anonfun$apply$14.apply(Parsers.scala:891)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)
	at scala.util.parsing.combinator.Parsers$$anon$2.apply(Parsers.scala:890)
	at scala.util.parsing.combinator.PackratParsers$$anon$1.apply(PackratParsers.scala:110)
	at org.apache.spark.sql.catalyst.AbstractSparkSQLParser.parse(AbstractSparkSQLParser.scala:34)
	at org.apache.spark.sql.SQLContext$$anonfun$2.apply(SQLContext.scala:166)
	at org.apache.spark.sql.SQLContext$$anonfun$2.apply(SQLContext.scala:166)
	at org.apache.spark.sql.execution.datasources.DDLParser.parse(DDLParser.scala:42)
	at org.apache.spark.sql.SQLContext.parseSql(SQLContext.scala:189)
	at org.apache.spark.sql.hive.HiveContext.parseSql(HiveContext.scala:280)
	at org.apache.spark.sql.hive.test.TestHiveContext$QueryExecution.<init>(TestHive.scala:179)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1$$anonfun$30.apply(HiveComparisonTest.scala:303)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1$$anonfun$30.apply(HiveComparisonTest.scala:303)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:34)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:244)
	at scala.collection.AbstractTraversable.map(Traversable.scala:105)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1.apply$mcV$sp(HiveComparisonTest.scala:303)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1.apply(HiveComparisonTest.scala:240)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1.apply(HiveComparisonTest.scala:240)
	at org.scalatest.Transformer$$anonfun$apply$1.apply$mcV$sp(Transformer.scala:22)
	at org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)
	at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
	at org.scalatest.Transformer.apply(Transformer.scala:22)
	at org.scalatest.Transformer.apply(Transformer.scala:20)
	at org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:166)
	at org.apache.spark.SparkFunSuite.withFixture(SparkFunSuite.scala:42)
	at org.scalatest.FunSuiteLike$class.invokeWithFixture$1(FunSuiteLike.scala:163)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)
	at org.scalatest.FunSuiteLike$class.runTest(FunSuiteLike.scala:175)
	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.org$scalatest$BeforeAndAfter$$super$runTest(HiveCompatibilitySuite.scala:32)
	at org.scalatest.BeforeAndAfter$class.runTest(BeforeAndAfter.scala:200)
	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.runTest(HiveCompatibilitySuite.scala:32)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:413)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:401)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)
	at org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:396)
	at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:483)
	at org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:208)
	at org.scalatest.FunSuite.runTests(FunSuite.scala:1555)
	at org.scalatest.Suite$class.run(Suite.scala:1424)
	at org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.SuperEngine.runImpl(Engine.scala:545)
	at org.scalatest.FunSuiteLike$class.run(FunSuiteLike.scala:212)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest.org$scalatest$BeforeAndAfterAll$$super$run(HiveComparisonTest.scala:44)
	at org.scalatest.BeforeAndAfterAll$class.liftedTree1$1(BeforeAndAfterAll.scala:257)
	at org.scalatest.BeforeAndAfterAll$class.run(BeforeAndAfterAll.scala:256)
	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.org$scalatest$BeforeAndAfter$$super$run(HiveCompatibilitySuite.scala:32)
	at org.scalatest.BeforeAndAfter$class.run(BeforeAndAfter.scala:241)
	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.run(HiveCompatibilitySuite.scala:32)
	at org.scalatest.Suite$class.callExecuteOnSuite$1(Suite.scala:1492)
	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1528)
	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1526)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.scalatest.Suite$class.runNestedSuites(Suite.scala:1526)
	at org.scalatest.tools.DiscoverySuite.runNestedSuites(DiscoverySuite.scala:29)
	at org.scalatest.Suite$class.run(Suite.scala:1421)
	at org.scalatest.tools.DiscoverySuite.run(DiscoverySuite.scala:29)
	at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:55)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2563)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2557)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:2557)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1044)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1043)
	at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:2722)
	at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1043)
	at org.scalatest.tools.Runner$.main(Runner.scala:860)
	at org.scalatest.tools.Runner.main(Runner.scala)
[31m- 0369 *** FAILED ***[0m
[31m  org.apache.spark.sql.AnalysisException: cannot recognize input near 'SELECT' 'CITY' 'FROM' in function specification; line 1 pos 44[0m
[31m  at org.apache.spark.sql.hive.HiveQl$.createPlan(HiveQl.scala:296)[0m
[31m  at org.apache.spark.sql.hive.ExtendedHiveQlParser$$anonfun$hiveQl$1.apply(ExtendedHiveQlParser.scala:41)[0m
[31m  at org.apache.spark.sql.hive.ExtendedHiveQlParser$$anonfun$hiveQl$1.apply(ExtendedHiveQlParser.scala:40)[0m
[31m  at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)[0m
[31m  at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:135)[0m
[31m  at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)[0m
[31m  at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)[0m
[31m  at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)[0m
[31m  at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)[0m
[31m  at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)[0m
[31m  ...[0m
NoViableAltException(231@[])
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.function(HiveParser_IdentifiersParser.java:3544)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.atomExpression(HiveParser_IdentifiersParser.java:6280)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceFieldExpression(HiveParser_IdentifiersParser.java:6383)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceUnaryPrefixExpression(HiveParser_IdentifiersParser.java:6768)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceUnarySuffixExpression(HiveParser_IdentifiersParser.java:6828)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceBitwiseXorExpression(HiveParser_IdentifiersParser.java:7012)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceStarExpression(HiveParser_IdentifiersParser.java:7172)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedencePlusExpression(HiveParser_IdentifiersParser.java:7332)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceAmpersandExpression(HiveParser_IdentifiersParser.java:7483)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceBitwiseOrExpression(HiveParser_IdentifiersParser.java:7634)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceEqualExpression(HiveParser_IdentifiersParser.java:8290)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceNotExpression(HiveParser_IdentifiersParser.java:9177)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceAndExpression(HiveParser_IdentifiersParser.java:9296)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceOrExpression(HiveParser_IdentifiersParser.java:9455)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.expression(HiveParser_IdentifiersParser.java:6105)
	at org.apache.hadoop.hive.ql.parse.HiveParser.expression(HiveParser.java:45846)
	at org.apache.hadoop.hive.ql.parse.HiveParser_FromClauseParser.searchCondition(HiveParser_FromClauseParser.java:6637)
	at org.apache.hadoop.hive.ql.parse.HiveParser_FromClauseParser.whereClause(HiveParser_FromClauseParser.java:6545)
	at org.apache.hadoop.hive.ql.parse.HiveParser.whereClause(HiveParser.java:45849)
	at org.apache.hadoop.hive.ql.parse.HiveParser.selectStatement(HiveParser.java:41543)
	at org.apache.hadoop.hive.ql.parse.HiveParser.regularBody(HiveParser.java:41402)
	at org.apache.hadoop.hive.ql.parse.HiveParser.queryStatementExpressionBody(HiveParser.java:40413)
	at org.apache.hadoop.hive.ql.parse.HiveParser.queryStatementExpression(HiveParser.java:40283)
	at org.apache.hadoop.hive.ql.parse.HiveParser.execStatement(HiveParser.java:1590)
	at org.apache.hadoop.hive.ql.parse.HiveParser.statement(HiveParser.java:1109)
	at org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:202)
	at org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:166)
	at org.apache.spark.sql.hive.HiveQl$.getAst(HiveQl.scala:258)
	at org.apache.spark.sql.hive.HiveQl$.createPlan(HiveQl.scala:283)
	at org.apache.spark.sql.hive.ExtendedHiveQlParser$$anonfun$hiveQl$1.apply(ExtendedHiveQlParser.scala:41)
	at org.apache.spark.sql.hive.ExtendedHiveQlParser$$anonfun$hiveQl$1.apply(ExtendedHiveQlParser.scala:40)
	at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)
	at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:135)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)
	at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Failure.append(Parsers.scala:202)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)
	at scala.util.parsing.combinator.Parsers$$anon$2$$anonfun$apply$14.apply(Parsers.scala:891)
	at scala.util.parsing.combinator.Parsers$$anon$2$$anonfun$apply$14.apply(Parsers.scala:891)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)
	at scala.util.parsing.combinator.Parsers$$anon$2.apply(Parsers.scala:890)
	at scala.util.parsing.combinator.PackratParsers$$anon$1.apply(PackratParsers.scala:110)
	at org.apache.spark.sql.catalyst.AbstractSparkSQLParser.parse(AbstractSparkSQLParser.scala:34)
	at org.apache.spark.sql.hive.HiveQl$.parseSql(HiveQl.scala:276)
	at org.apache.spark.sql.hive.HiveQLDialect.parse(HiveContext.scala:62)
	at com.intel.ssg.bdt.spark.sql.CalciteDialect.getLogicalPlan(CalciteDialect.scala:54)
	at com.intel.ssg.bdt.spark.sql.CalciteDialect.parse(CalciteDialect.scala:31)
	at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)
	at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)
	at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:115)
	at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:114)
	at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)
	at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:135)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)
	at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Failure.append(Parsers.scala:202)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)
	at scala.util.parsing.combinator.Parsers$$anon$2$$anonfun$apply$14.apply(Parsers.scala:891)
	at scala.util.parsing.combinator.Parsers$$anon$2$$anonfun$apply$14.apply(Parsers.scala:891)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)
	at scala.util.parsing.combinator.Parsers$$anon$2.apply(Parsers.scala:890)
	at scala.util.parsing.combinator.PackratParsers$$anon$1.apply(PackratParsers.scala:110)
	at org.apache.spark.sql.catalyst.AbstractSparkSQLParser.parse(AbstractSparkSQLParser.scala:34)
	at org.apache.spark.sql.SQLContext$$anonfun$2.apply(SQLContext.scala:166)
	at org.apache.spark.sql.SQLContext$$anonfun$2.apply(SQLContext.scala:166)
	at org.apache.spark.sql.execution.datasources.DDLParser.parse(DDLParser.scala:42)
	at org.apache.spark.sql.SQLContext.parseSql(SQLContext.scala:189)
	at org.apache.spark.sql.hive.HiveContext.parseSql(HiveContext.scala:280)
	at org.apache.spark.sql.hive.test.TestHiveContext$QueryExecution.<init>(TestHive.scala:179)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1$$anonfun$30.apply(HiveComparisonTest.scala:303)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1$$anonfun$30.apply(HiveComparisonTest.scala:303)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:34)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:244)
	at scala.collection.AbstractTraversable.map(Traversable.scala:105)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1.apply$mcV$sp(HiveComparisonTest.scala:303)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1.apply(HiveComparisonTest.scala:240)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1.apply(HiveComparisonTest.scala:240)
	at org.scalatest.Transformer$$anonfun$apply$1.apply$mcV$sp(Transformer.scala:22)
	at org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)
	at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
	at org.scalatest.Transformer.apply(Transformer.scala:22)
	at org.scalatest.Transformer.apply(Transformer.scala:20)
	at org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:166)
	at org.apache.spark.SparkFunSuite.withFixture(SparkFunSuite.scala:42)
	at org.scalatest.FunSuiteLike$class.invokeWithFixture$1(FunSuiteLike.scala:163)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)
	at org.scalatest.FunSuiteLike$class.runTest(FunSuiteLike.scala:175)
	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.org$scalatest$BeforeAndAfter$$super$runTest(HiveCompatibilitySuite.scala:32)
	at org.scalatest.BeforeAndAfter$class.runTest(BeforeAndAfter.scala:200)
	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.runTest(HiveCompatibilitySuite.scala:32)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:413)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:401)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)
	at org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:396)
	at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:483)
	at org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:208)
	at org.scalatest.FunSuite.runTests(FunSuite.scala:1555)
	at org.scalatest.Suite$class.run(Suite.scala:1424)
	at org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.SuperEngine.runImpl(Engine.scala:545)
	at org.scalatest.FunSuiteLike$class.run(FunSuiteLike.scala:212)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest.org$scalatest$BeforeAndAfterAll$$super$run(HiveComparisonTest.scala:44)
	at org.scalatest.BeforeAndAfterAll$class.liftedTree1$1(BeforeAndAfterAll.scala:257)
	at org.scalatest.BeforeAndAfterAll$class.run(BeforeAndAfterAll.scala:256)
	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.org$scalatest$BeforeAndAfter$$super$run(HiveCompatibilitySuite.scala:32)
	at org.scalatest.BeforeAndAfter$class.run(BeforeAndAfter.scala:241)
	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.run(HiveCompatibilitySuite.scala:32)
	at org.scalatest.Suite$class.callExecuteOnSuite$1(Suite.scala:1492)
	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1528)
	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1526)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.scalatest.Suite$class.runNestedSuites(Suite.scala:1526)
	at org.scalatest.tools.DiscoverySuite.runNestedSuites(DiscoverySuite.scala:29)
	at org.scalatest.Suite$class.run(Suite.scala:1421)
	at org.scalatest.tools.DiscoverySuite.run(DiscoverySuite.scala:29)
	at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:55)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2563)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2557)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:2557)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1044)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1043)
	at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:2722)
	at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1043)
	at org.scalatest.tools.Runner$.main(Runner.scala:860)
	at org.scalatest.tools.Runner.main(Runner.scala)
[31m- 0370 *** FAILED ***[0m
[31m  org.apache.spark.sql.AnalysisException: cannot recognize input near 'SELECT' 'CITY' 'FROM' in function specification; line 1 pos 45[0m
[31m  at org.apache.spark.sql.hive.HiveQl$.createPlan(HiveQl.scala:296)[0m
[31m  at org.apache.spark.sql.hive.ExtendedHiveQlParser$$anonfun$hiveQl$1.apply(ExtendedHiveQlParser.scala:41)[0m
[31m  at org.apache.spark.sql.hive.ExtendedHiveQlParser$$anonfun$hiveQl$1.apply(ExtendedHiveQlParser.scala:40)[0m
[31m  at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)[0m
[31m  at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:135)[0m
[31m  at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)[0m
[31m  at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)[0m
[31m  at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)[0m
[31m  at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)[0m
[31m  at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)[0m
[31m  ...[0m
NoViableAltException(231@[])
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.function(HiveParser_IdentifiersParser.java:3544)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.atomExpression(HiveParser_IdentifiersParser.java:6280)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceFieldExpression(HiveParser_IdentifiersParser.java:6383)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceUnaryPrefixExpression(HiveParser_IdentifiersParser.java:6768)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceUnarySuffixExpression(HiveParser_IdentifiersParser.java:6828)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceBitwiseXorExpression(HiveParser_IdentifiersParser.java:7012)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceStarExpression(HiveParser_IdentifiersParser.java:7172)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedencePlusExpression(HiveParser_IdentifiersParser.java:7332)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceAmpersandExpression(HiveParser_IdentifiersParser.java:7483)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceBitwiseOrExpression(HiveParser_IdentifiersParser.java:7634)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceEqualExpression(HiveParser_IdentifiersParser.java:8290)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceNotExpression(HiveParser_IdentifiersParser.java:9177)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceAndExpression(HiveParser_IdentifiersParser.java:9296)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceOrExpression(HiveParser_IdentifiersParser.java:9455)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.expression(HiveParser_IdentifiersParser.java:6105)
	at org.apache.hadoop.hive.ql.parse.HiveParser.expression(HiveParser.java:45846)
	at org.apache.hadoop.hive.ql.parse.HiveParser_FromClauseParser.searchCondition(HiveParser_FromClauseParser.java:6637)
	at org.apache.hadoop.hive.ql.parse.HiveParser_FromClauseParser.whereClause(HiveParser_FromClauseParser.java:6545)
	at org.apache.hadoop.hive.ql.parse.HiveParser.whereClause(HiveParser.java:45849)
	at org.apache.hadoop.hive.ql.parse.HiveParser.selectStatement(HiveParser.java:41543)
	at org.apache.hadoop.hive.ql.parse.HiveParser.regularBody(HiveParser.java:41402)
	at org.apache.hadoop.hive.ql.parse.HiveParser.queryStatementExpressionBody(HiveParser.java:40413)
	at org.apache.hadoop.hive.ql.parse.HiveParser.queryStatementExpression(HiveParser.java:40283)
	at org.apache.hadoop.hive.ql.parse.HiveParser.execStatement(HiveParser.java:1590)
	at org.apache.hadoop.hive.ql.parse.HiveParser.statement(HiveParser.java:1109)
	at org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:202)
	at org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:166)
	at org.apache.spark.sql.hive.HiveQl$.getAst(HiveQl.scala:258)
	at org.apache.spark.sql.hive.HiveQl$.createPlan(HiveQl.scala:283)
	at org.apache.spark.sql.hive.ExtendedHiveQlParser$$anonfun$hiveQl$1.apply(ExtendedHiveQlParser.scala:41)
	at org.apache.spark.sql.hive.ExtendedHiveQlParser$$anonfun$hiveQl$1.apply(ExtendedHiveQlParser.scala:40)
	at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)
	at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:135)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)
	at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Failure.append(Parsers.scala:202)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)
	at scala.util.parsing.combinator.Parsers$$anon$2$$anonfun$apply$14.apply(Parsers.scala:891)
	at scala.util.parsing.combinator.Parsers$$anon$2$$anonfun$apply$14.apply(Parsers.scala:891)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)
	at scala.util.parsing.combinator.Parsers$$anon$2.apply(Parsers.scala:890)
	at scala.util.parsing.combinator.PackratParsers$$anon$1.apply(PackratParsers.scala:110)
	at org.apache.spark.sql.catalyst.AbstractSparkSQLParser.parse(AbstractSparkSQLParser.scala:34)
	at org.apache.spark.sql.hive.HiveQl$.parseSql(HiveQl.scala:276)
	at org.apache.spark.sql.hive.HiveQLDialect.parse(HiveContext.scala:62)
	at com.intel.ssg.bdt.spark.sql.CalciteDialect.getLogicalPlan(CalciteDialect.scala:54)
	at com.intel.ssg.bdt.spark.sql.CalciteDialect.parse(CalciteDialect.scala:31)
	at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)
	at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)
	at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:115)
	at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:114)
	at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)
	at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:135)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)
	at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Failure.append(Parsers.scala:202)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)
	at scala.util.parsing.combinator.Parsers$$anon$2$$anonfun$apply$14.apply(Parsers.scala:891)
	at scala.util.parsing.combinator.Parsers$$anon$2$$anonfun$apply$14.apply(Parsers.scala:891)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)
	at scala.util.parsing.combinator.Parsers$$anon$2.apply(Parsers.scala:890)
	at scala.util.parsing.combinator.PackratParsers$$anon$1.apply(PackratParsers.scala:110)
	at org.apache.spark.sql.catalyst.AbstractSparkSQLParser.parse(AbstractSparkSQLParser.scala:34)
	at org.apache.spark.sql.SQLContext$$anonfun$2.apply(SQLContext.scala:166)
	at org.apache.spark.sql.SQLContext$$anonfun$2.apply(SQLContext.scala:166)
	at org.apache.spark.sql.execution.datasources.DDLParser.parse(DDLParser.scala:42)
	at org.apache.spark.sql.SQLContext.parseSql(SQLContext.scala:189)
	at org.apache.spark.sql.hive.HiveContext.parseSql(HiveContext.scala:280)
	at org.apache.spark.sql.hive.test.TestHiveContext$QueryExecution.<init>(TestHive.scala:179)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1$$anonfun$30.apply(HiveComparisonTest.scala:303)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1$$anonfun$30.apply(HiveComparisonTest.scala:303)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:34)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:244)
	at scala.collection.AbstractTraversable.map(Traversable.scala:105)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1.apply$mcV$sp(HiveComparisonTest.scala:303)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1.apply(HiveComparisonTest.scala:240)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1.apply(HiveComparisonTest.scala:240)
	at org.scalatest.Transformer$$anonfun$apply$1.apply$mcV$sp(Transformer.scala:22)
	at org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)
	at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
	at org.scalatest.Transformer.apply(Transformer.scala:22)
	at org.scalatest.Transformer.apply(Transformer.scala:20)
	at org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:166)
	at org.apache.spark.SparkFunSuite.withFixture(SparkFunSuite.scala:42)
	at org.scalatest.FunSuiteLike$class.invokeWithFixture$1(FunSuiteLike.scala:163)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)
	at org.scalatest.FunSuiteLike$class.runTest(FunSuiteLike.scala:175)
	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.org$scalatest$BeforeAndAfter$$super$runTest(HiveCompatibilitySuite.scala:32)
	at org.scalatest.BeforeAndAfter$class.runTest(BeforeAndAfter.scala:200)
	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.runTest(HiveCompatibilitySuite.scala:32)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:413)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:401)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)
	at org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:396)
	at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:483)
	at org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:208)
	at org.scalatest.FunSuite.runTests(FunSuite.scala:1555)
	at org.scalatest.Suite$class.run(Suite.scala:1424)
	at org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.SuperEngine.runImpl(Engine.scala:545)
	at org.scalatest.FunSuiteLike$class.run(FunSuiteLike.scala:212)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest.org$scalatest$BeforeAndAfterAll$$super$run(HiveComparisonTest.scala:44)
	at org.scalatest.BeforeAndAfterAll$class.liftedTree1$1(BeforeAndAfterAll.scala:257)
	at org.scalatest.BeforeAndAfterAll$class.run(BeforeAndAfterAll.scala:256)
	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.org$scalatest$BeforeAndAfter$$super$run(HiveCompatibilitySuite.scala:32)
	at org.scalatest.BeforeAndAfter$class.run(BeforeAndAfter.scala:241)
	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.run(HiveCompatibilitySuite.scala:32)
	at org.scalatest.Suite$class.callExecuteOnSuite$1(Suite.scala:1492)
	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1528)
	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1526)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.scalatest.Suite$class.runNestedSuites(Suite.scala:1526)
	at org.scalatest.tools.DiscoverySuite.runNestedSuites(DiscoverySuite.scala:29)
	at org.scalatest.Suite$class.run(Suite.scala:1421)
	at org.scalatest.tools.DiscoverySuite.run(DiscoverySuite.scala:29)
	at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:55)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2563)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2557)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:2557)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1044)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1043)
	at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:2722)
	at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1043)
	at org.scalatest.tools.Runner$.main(Runner.scala:860)
	at org.scalatest.tools.Runner.main(Runner.scala)
[31m- 0371 *** FAILED ***[0m
[31m  org.apache.spark.sql.AnalysisException: cannot recognize input near 'SELECT' 'CITY' 'FROM' in function specification; line 1 pos 44[0m
[31m  at org.apache.spark.sql.hive.HiveQl$.createPlan(HiveQl.scala:296)[0m
[31m  at org.apache.spark.sql.hive.ExtendedHiveQlParser$$anonfun$hiveQl$1.apply(ExtendedHiveQlParser.scala:41)[0m
[31m  at org.apache.spark.sql.hive.ExtendedHiveQlParser$$anonfun$hiveQl$1.apply(ExtendedHiveQlParser.scala:40)[0m
[31m  at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)[0m
[31m  at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:135)[0m
[31m  at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)[0m
[31m  at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)[0m
[31m  at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)[0m
[31m  at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)[0m
[31m  at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)[0m
[31m  ...[0m
NoViableAltException(231@[])
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.function(HiveParser_IdentifiersParser.java:3544)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.atomExpression(HiveParser_IdentifiersParser.java:6280)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceFieldExpression(HiveParser_IdentifiersParser.java:6383)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceUnaryPrefixExpression(HiveParser_IdentifiersParser.java:6768)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceUnarySuffixExpression(HiveParser_IdentifiersParser.java:6828)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceBitwiseXorExpression(HiveParser_IdentifiersParser.java:7012)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceStarExpression(HiveParser_IdentifiersParser.java:7172)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedencePlusExpression(HiveParser_IdentifiersParser.java:7332)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceAmpersandExpression(HiveParser_IdentifiersParser.java:7483)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceBitwiseOrExpression(HiveParser_IdentifiersParser.java:7634)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceEqualExpression(HiveParser_IdentifiersParser.java:8290)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceNotExpression(HiveParser_IdentifiersParser.java:9177)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceAndExpression(HiveParser_IdentifiersParser.java:9296)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceOrExpression(HiveParser_IdentifiersParser.java:9455)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.expression(HiveParser_IdentifiersParser.java:6105)
	at org.apache.hadoop.hive.ql.parse.HiveParser.expression(HiveParser.java:45846)
	at org.apache.hadoop.hive.ql.parse.HiveParser_FromClauseParser.searchCondition(HiveParser_FromClauseParser.java:6637)
	at org.apache.hadoop.hive.ql.parse.HiveParser_FromClauseParser.whereClause(HiveParser_FromClauseParser.java:6545)
	at org.apache.hadoop.hive.ql.parse.HiveParser.whereClause(HiveParser.java:45849)
	at org.apache.hadoop.hive.ql.parse.HiveParser.selectStatement(HiveParser.java:41543)
	at org.apache.hadoop.hive.ql.parse.HiveParser.regularBody(HiveParser.java:41402)
	at org.apache.hadoop.hive.ql.parse.HiveParser.queryStatementExpressionBody(HiveParser.java:40413)
	at org.apache.hadoop.hive.ql.parse.HiveParser.queryStatementExpression(HiveParser.java:40283)
	at org.apache.hadoop.hive.ql.parse.HiveParser.execStatement(HiveParser.java:1590)
	at org.apache.hadoop.hive.ql.parse.HiveParser.statement(HiveParser.java:1109)
	at org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:202)
	at org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:166)
	at org.apache.spark.sql.hive.HiveQl$.getAst(HiveQl.scala:258)
	at org.apache.spark.sql.hive.HiveQl$.createPlan(HiveQl.scala:283)
	at org.apache.spark.sql.hive.ExtendedHiveQlParser$$anonfun$hiveQl$1.apply(ExtendedHiveQlParser.scala:41)
	at org.apache.spark.sql.hive.ExtendedHiveQlParser$$anonfun$hiveQl$1.apply(ExtendedHiveQlParser.scala:40)
	at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)
	at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:135)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)
	at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Failure.append(Parsers.scala:202)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)
	at scala.util.parsing.combinator.Parsers$$anon$2$$anonfun$apply$14.apply(Parsers.scala:891)
	at scala.util.parsing.combinator.Parsers$$anon$2$$anonfun$apply$14.apply(Parsers.scala:891)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)
	at scala.util.parsing.combinator.Parsers$$anon$2.apply(Parsers.scala:890)
	at scala.util.parsing.combinator.PackratParsers$$anon$1.apply(PackratParsers.scala:110)
	at org.apache.spark.sql.catalyst.AbstractSparkSQLParser.parse(AbstractSparkSQLParser.scala:34)
	at org.apache.spark.sql.hive.HiveQl$.parseSql(HiveQl.scala:276)
	at org.apache.spark.sql.hive.HiveQLDialect.parse(HiveContext.scala:62)
	at com.intel.ssg.bdt.spark.sql.CalciteDialect.getLogicalPlan(CalciteDialect.scala:54)
	at com.intel.ssg.bdt.spark.sql.CalciteDialect.parse(CalciteDialect.scala:31)
	at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)
	at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)
	at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:115)
	at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:114)
	at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)
	at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:135)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)
	at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Failure.append(Parsers.scala:202)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)
	at scala.util.parsing.combinator.Parsers$$anon$2$$anonfun$apply$14.apply(Parsers.scala:891)
	at scala.util.parsing.combinator.Parsers$$anon$2$$anonfun$apply$14.apply(Parsers.scala:891)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)
	at scala.util.parsing.combinator.Parsers$$anon$2.apply(Parsers.scala:890)
	at scala.util.parsing.combinator.PackratParsers$$anon$1.apply(PackratParsers.scala:110)
	at org.apache.spark.sql.catalyst.AbstractSparkSQLParser.parse(AbstractSparkSQLParser.scala:34)
	at org.apache.spark.sql.SQLContext$$anonfun$2.apply(SQLContext.scala:166)
	at org.apache.spark.sql.SQLContext$$anonfun$2.apply(SQLContext.scala:166)
	at org.apache.spark.sql.execution.datasources.DDLParser.parse(DDLParser.scala:42)
	at org.apache.spark.sql.SQLContext.parseSql(SQLContext.scala:189)
	at org.apache.spark.sql.hive.HiveContext.parseSql(HiveContext.scala:280)
	at org.apache.spark.sql.hive.test.TestHiveContext$QueryExecution.<init>(TestHive.scala:179)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1$$anonfun$30.apply(HiveComparisonTest.scala:303)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1$$anonfun$30.apply(HiveComparisonTest.scala:303)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:34)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:244)
	at scala.collection.AbstractTraversable.map(Traversable.scala:105)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1.apply$mcV$sp(HiveComparisonTest.scala:303)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1.apply(HiveComparisonTest.scala:240)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1.apply(HiveComparisonTest.scala:240)
	at org.scalatest.Transformer$$anonfun$apply$1.apply$mcV$sp(Transformer.scala:22)
	at org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)
	at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
	at org.scalatest.Transformer.apply(Transformer.scala:22)
	at org.scalatest.Transformer.apply(Transformer.scala:20)
	at org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:166)
	at org.apache.spark.SparkFunSuite.withFixture(SparkFunSuite.scala:42)
	at org.scalatest.FunSuiteLike$class.invokeWithFixture$1(FunSuiteLike.scala:163)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)
	at org.scalatest.FunSuiteLike$class.runTest(FunSuiteLike.scala:175)
	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.org$scalatest$BeforeAndAfter$$super$runTest(HiveCompatibilitySuite.scala:32)
	at org.scalatest.BeforeAndAfter$class.runTest(BeforeAndAfter.scala:200)
	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.runTest(HiveCompatibilitySuite.scala:32)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:413)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:401)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)
	at org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:396)
	at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:483)
	at org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:208)
	at org.scalatest.FunSuite.runTests(FunSuite.scala:1555)
	at org.scalatest.Suite$class.run(Suite.scala:1424)
	at org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.SuperEngine.runImpl(Engine.scala:545)
	at org.scalatest.FunSuiteLike$class.run(FunSuiteLike.scala:212)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest.org$scalatest$BeforeAndAfterAll$$super$run(HiveComparisonTest.scala:44)
	at org.scalatest.BeforeAndAfterAll$class.liftedTree1$1(BeforeAndAfterAll.scala:257)
	at org.scalatest.BeforeAndAfterAll$class.run(BeforeAndAfterAll.scala:256)
	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.org$scalatest$BeforeAndAfter$$super$run(HiveCompatibilitySuite.scala:32)
	at org.scalatest.BeforeAndAfter$class.run(BeforeAndAfter.scala:241)
	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.run(HiveCompatibilitySuite.scala:32)
	at org.scalatest.Suite$class.callExecuteOnSuite$1(Suite.scala:1492)
	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1528)
	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1526)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.scalatest.Suite$class.runNestedSuites(Suite.scala:1526)
	at org.scalatest.tools.DiscoverySuite.runNestedSuites(DiscoverySuite.scala:29)
	at org.scalatest.Suite$class.run(Suite.scala:1421)
	at org.scalatest.tools.DiscoverySuite.run(DiscoverySuite.scala:29)
	at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:55)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2563)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2557)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:2557)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1044)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1043)
	at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:2722)
	at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1043)
	at org.scalatest.tools.Runner$.main(Runner.scala:860)
	at org.scalatest.tools.Runner.main(Runner.scala)
[31m- 0372 *** FAILED ***[0m
[31m  org.apache.spark.sql.AnalysisException: cannot recognize input near 'SELECT' 'CITY' 'FROM' in function specification; line 1 pos 45[0m
[31m  at org.apache.spark.sql.hive.HiveQl$.createPlan(HiveQl.scala:296)[0m
[31m  at org.apache.spark.sql.hive.ExtendedHiveQlParser$$anonfun$hiveQl$1.apply(ExtendedHiveQlParser.scala:41)[0m
[31m  at org.apache.spark.sql.hive.ExtendedHiveQlParser$$anonfun$hiveQl$1.apply(ExtendedHiveQlParser.scala:40)[0m
[31m  at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)[0m
[31m  at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:135)[0m
[31m  at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)[0m
[31m  at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)[0m
[31m  at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)[0m
[31m  at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)[0m
[31m  at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)[0m
[31m  ...[0m
NoViableAltException(231@[])
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.function(HiveParser_IdentifiersParser.java:3544)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.atomExpression(HiveParser_IdentifiersParser.java:6280)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceFieldExpression(HiveParser_IdentifiersParser.java:6383)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceUnaryPrefixExpression(HiveParser_IdentifiersParser.java:6768)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceUnarySuffixExpression(HiveParser_IdentifiersParser.java:6828)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceBitwiseXorExpression(HiveParser_IdentifiersParser.java:7012)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceStarExpression(HiveParser_IdentifiersParser.java:7172)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedencePlusExpression(HiveParser_IdentifiersParser.java:7332)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceAmpersandExpression(HiveParser_IdentifiersParser.java:7483)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceBitwiseOrExpression(HiveParser_IdentifiersParser.java:7634)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceEqualExpression(HiveParser_IdentifiersParser.java:8290)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceNotExpression(HiveParser_IdentifiersParser.java:9177)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceAndExpression(HiveParser_IdentifiersParser.java:9296)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceOrExpression(HiveParser_IdentifiersParser.java:9455)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.expression(HiveParser_IdentifiersParser.java:6105)
	at org.apache.hadoop.hive.ql.parse.HiveParser.expression(HiveParser.java:45846)
	at org.apache.hadoop.hive.ql.parse.HiveParser_FromClauseParser.searchCondition(HiveParser_FromClauseParser.java:6637)
	at org.apache.hadoop.hive.ql.parse.HiveParser_FromClauseParser.whereClause(HiveParser_FromClauseParser.java:6545)
	at org.apache.hadoop.hive.ql.parse.HiveParser.whereClause(HiveParser.java:45849)
	at org.apache.hadoop.hive.ql.parse.HiveParser.selectStatement(HiveParser.java:41543)
	at org.apache.hadoop.hive.ql.parse.HiveParser.regularBody(HiveParser.java:41402)
	at org.apache.hadoop.hive.ql.parse.HiveParser.queryStatementExpressionBody(HiveParser.java:40413)
	at org.apache.hadoop.hive.ql.parse.HiveParser.queryStatementExpression(HiveParser.java:40283)
	at org.apache.hadoop.hive.ql.parse.HiveParser.execStatement(HiveParser.java:1590)
	at org.apache.hadoop.hive.ql.parse.HiveParser.statement(HiveParser.java:1109)
	at org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:202)
	at org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:166)
	at org.apache.spark.sql.hive.HiveQl$.getAst(HiveQl.scala:258)
	at org.apache.spark.sql.hive.HiveQl$.createPlan(HiveQl.scala:283)
	at org.apache.spark.sql.hive.ExtendedHiveQlParser$$anonfun$hiveQl$1.apply(ExtendedHiveQlParser.scala:41)
	at org.apache.spark.sql.hive.ExtendedHiveQlParser$$anonfun$hiveQl$1.apply(ExtendedHiveQlParser.scala:40)
	at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)
	at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:135)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)
	at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Failure.append(Parsers.scala:202)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)
	at scala.util.parsing.combinator.Parsers$$anon$2$$anonfun$apply$14.apply(Parsers.scala:891)
	at scala.util.parsing.combinator.Parsers$$anon$2$$anonfun$apply$14.apply(Parsers.scala:891)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)
	at scala.util.parsing.combinator.Parsers$$anon$2.apply(Parsers.scala:890)
	at scala.util.parsing.combinator.PackratParsers$$anon$1.apply(PackratParsers.scala:110)
	at org.apache.spark.sql.catalyst.AbstractSparkSQLParser.parse(AbstractSparkSQLParser.scala:34)
	at org.apache.spark.sql.hive.HiveQl$.parseSql(HiveQl.scala:276)
	at org.apache.spark.sql.hive.HiveQLDialect.parse(HiveContext.scala:62)
	at com.intel.ssg.bdt.spark.sql.CalciteDialect.getLogicalPlan(CalciteDialect.scala:54)
	at com.intel.ssg.bdt.spark.sql.CalciteDialect.parse(CalciteDialect.scala:31)
	at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)
	at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)
	at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:115)
	at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:114)
	at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)
	at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:135)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)
	at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Failure.append(Parsers.scala:202)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)
	at scala.util.parsing.combinator.Parsers$$anon$2$$anonfun$apply$14.apply(Parsers.scala:891)
	at scala.util.parsing.combinator.Parsers$$anon$2$$anonfun$apply$14.apply(Parsers.scala:891)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)
	at scala.util.parsing.combinator.Parsers$$anon$2.apply(Parsers.scala:890)
	at scala.util.parsing.combinator.PackratParsers$$anon$1.apply(PackratParsers.scala:110)
	at org.apache.spark.sql.catalyst.AbstractSparkSQLParser.parse(AbstractSparkSQLParser.scala:34)
	at org.apache.spark.sql.SQLContext$$anonfun$2.apply(SQLContext.scala:166)
	at org.apache.spark.sql.SQLContext$$anonfun$2.apply(SQLContext.scala:166)
	at org.apache.spark.sql.execution.datasources.DDLParser.parse(DDLParser.scala:42)
	at org.apache.spark.sql.SQLContext.parseSql(SQLContext.scala:189)
	at org.apache.spark.sql.hive.HiveContext.parseSql(HiveContext.scala:280)
	at org.apache.spark.sql.hive.test.TestHiveContext$QueryExecution.<init>(TestHive.scala:179)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1$$anonfun$30.apply(HiveComparisonTest.scala:303)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1$$anonfun$30.apply(HiveComparisonTest.scala:303)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:34)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:244)
	at scala.collection.AbstractTraversable.map(Traversable.scala:105)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1.apply$mcV$sp(HiveComparisonTest.scala:303)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1.apply(HiveComparisonTest.scala:240)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1.apply(HiveComparisonTest.scala:240)
	at org.scalatest.Transformer$$anonfun$apply$1.apply$mcV$sp(Transformer.scala:22)
	at org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)
	at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
	at org.scalatest.Transformer.apply(Transformer.scala:22)
	at org.scalatest.Transformer.apply(Transformer.scala:20)
	at org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:166)
	at org.apache.spark.SparkFunSuite.withFixture(SparkFunSuite.scala:42)
	at org.scalatest.FunSuiteLike$class.invokeWithFixture$1(FunSuiteLike.scala:163)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)
	at org.scalatest.FunSuiteLike$class.runTest(FunSuiteLike.scala:175)
	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.org$scalatest$BeforeAndAfter$$super$runTest(HiveCompatibilitySuite.scala:32)
	at org.scalatest.BeforeAndAfter$class.runTest(BeforeAndAfter.scala:200)
	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.runTest(HiveCompatibilitySuite.scala:32)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:413)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:401)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)
	at org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:396)
	at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:483)
	at org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:208)
	at org.scalatest.FunSuite.runTests(FunSuite.scala:1555)
	at org.scalatest.Suite$class.run(Suite.scala:1424)
	at org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.SuperEngine.runImpl(Engine.scala:545)
	at org.scalatest.FunSuiteLike$class.run(FunSuiteLike.scala:212)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest.org$scalatest$BeforeAndAfterAll$$super$run(HiveComparisonTest.scala:44)
	at org.scalatest.BeforeAndAfterAll$class.liftedTree1$1(BeforeAndAfterAll.scala:257)
	at org.scalatest.BeforeAndAfterAll$class.run(BeforeAndAfterAll.scala:256)
	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.org$scalatest$BeforeAndAfter$$super$run(HiveCompatibilitySuite.scala:32)
	at org.scalatest.BeforeAndAfter$class.run(BeforeAndAfter.scala:241)
	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.run(HiveCompatibilitySuite.scala:32)
	at org.scalatest.Suite$class.callExecuteOnSuite$1(Suite.scala:1492)
	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1528)
	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1526)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.scalatest.Suite$class.runNestedSuites(Suite.scala:1526)
	at org.scalatest.tools.DiscoverySuite.runNestedSuites(DiscoverySuite.scala:29)
	at org.scalatest.Suite$class.run(Suite.scala:1421)
	at org.scalatest.tools.DiscoverySuite.run(DiscoverySuite.scala:29)
	at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:55)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2563)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2557)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:2557)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1044)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1043)
	at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:2722)
	at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1043)
	at org.scalatest.tools.Runner$.main(Runner.scala:860)
	at org.scalatest.tools.Runner.main(Runner.scala)
[31m- 0373 *** FAILED ***[0m
[31m  org.apache.spark.sql.AnalysisException: cannot recognize input near 'SELECT' 'CITY' 'FROM' in function specification; line 1 pos 45[0m
[31m  at org.apache.spark.sql.hive.HiveQl$.createPlan(HiveQl.scala:296)[0m
[31m  at org.apache.spark.sql.hive.ExtendedHiveQlParser$$anonfun$hiveQl$1.apply(ExtendedHiveQlParser.scala:41)[0m
[31m  at org.apache.spark.sql.hive.ExtendedHiveQlParser$$anonfun$hiveQl$1.apply(ExtendedHiveQlParser.scala:40)[0m
[31m  at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)[0m
[31m  at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:135)[0m
[31m  at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)[0m
[31m  at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)[0m
[31m  at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)[0m
[31m  at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)[0m
[31m  at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)[0m
[31m  ...[0m
NoViableAltException(231@[])
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.function(HiveParser_IdentifiersParser.java:3544)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.atomExpression(HiveParser_IdentifiersParser.java:6280)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceFieldExpression(HiveParser_IdentifiersParser.java:6383)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceUnaryPrefixExpression(HiveParser_IdentifiersParser.java:6768)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceUnarySuffixExpression(HiveParser_IdentifiersParser.java:6828)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceBitwiseXorExpression(HiveParser_IdentifiersParser.java:7012)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceStarExpression(HiveParser_IdentifiersParser.java:7172)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedencePlusExpression(HiveParser_IdentifiersParser.java:7332)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceAmpersandExpression(HiveParser_IdentifiersParser.java:7483)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceBitwiseOrExpression(HiveParser_IdentifiersParser.java:7634)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceEqualExpression(HiveParser_IdentifiersParser.java:8290)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceNotExpression(HiveParser_IdentifiersParser.java:9177)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceAndExpression(HiveParser_IdentifiersParser.java:9296)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceOrExpression(HiveParser_IdentifiersParser.java:9455)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.expression(HiveParser_IdentifiersParser.java:6105)
	at org.apache.hadoop.hive.ql.parse.HiveParser.expression(HiveParser.java:45846)
	at org.apache.hadoop.hive.ql.parse.HiveParser_FromClauseParser.searchCondition(HiveParser_FromClauseParser.java:6637)
	at org.apache.hadoop.hive.ql.parse.HiveParser_FromClauseParser.whereClause(HiveParser_FromClauseParser.java:6545)
	at org.apache.hadoop.hive.ql.parse.HiveParser.whereClause(HiveParser.java:45849)
	at org.apache.hadoop.hive.ql.parse.HiveParser.selectStatement(HiveParser.java:41543)
	at org.apache.hadoop.hive.ql.parse.HiveParser.regularBody(HiveParser.java:41402)
	at org.apache.hadoop.hive.ql.parse.HiveParser.queryStatementExpressionBody(HiveParser.java:40413)
	at org.apache.hadoop.hive.ql.parse.HiveParser.queryStatementExpression(HiveParser.java:40283)
	at org.apache.hadoop.hive.ql.parse.HiveParser.execStatement(HiveParser.java:1590)
	at org.apache.hadoop.hive.ql.parse.HiveParser.statement(HiveParser.java:1109)
	at org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:202)
	at org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:166)
	at org.apache.spark.sql.hive.HiveQl$.getAst(HiveQl.scala:258)
	at org.apache.spark.sql.hive.HiveQl$.createPlan(HiveQl.scala:283)
	at org.apache.spark.sql.hive.ExtendedHiveQlParser$$anonfun$hiveQl$1.apply(ExtendedHiveQlParser.scala:41)
	at org.apache.spark.sql.hive.ExtendedHiveQlParser$$anonfun$hiveQl$1.apply(ExtendedHiveQlParser.scala:40)
	at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)
	at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:135)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)
	at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Failure.append(Parsers.scala:202)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)
	at scala.util.parsing.combinator.Parsers$$anon$2$$anonfun$apply$14.apply(Parsers.scala:891)
	at scala.util.parsing.combinator.Parsers$$anon$2$$anonfun$apply$14.apply(Parsers.scala:891)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)
	at scala.util.parsing.combinator.Parsers$$anon$2.apply(Parsers.scala:890)
	at scala.util.parsing.combinator.PackratParsers$$anon$1.apply(PackratParsers.scala:110)
	at org.apache.spark.sql.catalyst.AbstractSparkSQLParser.parse(AbstractSparkSQLParser.scala:34)
	at org.apache.spark.sql.hive.HiveQl$.parseSql(HiveQl.scala:276)
	at org.apache.spark.sql.hive.HiveQLDialect.parse(HiveContext.scala:62)
	at com.intel.ssg.bdt.spark.sql.CalciteDialect.getLogicalPlan(CalciteDialect.scala:54)
	at com.intel.ssg.bdt.spark.sql.CalciteDialect.parse(CalciteDialect.scala:31)
	at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)
	at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)
	at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:115)
	at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:114)
	at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)
	at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:135)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)
	at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Failure.append(Parsers.scala:202)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)
	at scala.util.parsing.combinator.Parsers$$anon$2$$anonfun$apply$14.apply(Parsers.scala:891)
	at scala.util.parsing.combinator.Parsers$$anon$2$$anonfun$apply$14.apply(Parsers.scala:891)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)
	at scala.util.parsing.combinator.Parsers$$anon$2.apply(Parsers.scala:890)
	at scala.util.parsing.combinator.PackratParsers$$anon$1.apply(PackratParsers.scala:110)
	at org.apache.spark.sql.catalyst.AbstractSparkSQLParser.parse(AbstractSparkSQLParser.scala:34)
	at org.apache.spark.sql.SQLContext$$anonfun$2.apply(SQLContext.scala:166)
	at org.apache.spark.sql.SQLContext$$anonfun$2.apply(SQLContext.scala:166)
	at org.apache.spark.sql.execution.datasources.DDLParser.parse(DDLParser.scala:42)
	at org.apache.spark.sql.SQLContext.parseSql(SQLContext.scala:189)
	at org.apache.spark.sql.hive.HiveContext.parseSql(HiveContext.scala:280)
	at org.apache.spark.sql.hive.test.TestHiveContext$QueryExecution.<init>(TestHive.scala:179)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1$$anonfun$30.apply(HiveComparisonTest.scala:303)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1$$anonfun$30.apply(HiveComparisonTest.scala:303)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:34)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:244)
	at scala.collection.AbstractTraversable.map(Traversable.scala:105)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1.apply$mcV$sp(HiveComparisonTest.scala:303)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1.apply(HiveComparisonTest.scala:240)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1.apply(HiveComparisonTest.scala:240)
	at org.scalatest.Transformer$$anonfun$apply$1.apply$mcV$sp(Transformer.scala:22)
	at org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)
	at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
	at org.scalatest.Transformer.apply(Transformer.scala:22)
	at org.scalatest.Transformer.apply(Transformer.scala:20)
	at org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:166)
	at org.apache.spark.SparkFunSuite.withFixture(SparkFunSuite.scala:42)
	at org.scalatest.FunSuiteLike$class.invokeWithFixture$1(FunSuiteLike.scala:163)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)
	at org.scalatest.FunSuiteLike$class.runTest(FunSuiteLike.scala:175)
	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.org$scalatest$BeforeAndAfter$$super$runTest(HiveCompatibilitySuite.scala:32)
	at org.scalatest.BeforeAndAfter$class.runTest(BeforeAndAfter.scala:200)
	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.runTest(HiveCompatibilitySuite.scala:32)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:413)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:401)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)
	at org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:396)
	at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:483)
	at org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:208)
	at org.scalatest.FunSuite.runTests(FunSuite.scala:1555)
	at org.scalatest.Suite$class.run(Suite.scala:1424)
	at org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.SuperEngine.runImpl(Engine.scala:545)
	at org.scalatest.FunSuiteLike$class.run(FunSuiteLike.scala:212)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest.org$scalatest$BeforeAndAfterAll$$super$run(HiveComparisonTest.scala:44)
	at org.scalatest.BeforeAndAfterAll$class.liftedTree1$1(BeforeAndAfterAll.scala:257)
	at org.scalatest.BeforeAndAfterAll$class.run(BeforeAndAfterAll.scala:256)
	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.org$scalatest$BeforeAndAfter$$super$run(HiveCompatibilitySuite.scala:32)
	at org.scalatest.BeforeAndAfter$class.run(BeforeAndAfter.scala:241)
	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.run(HiveCompatibilitySuite.scala:32)
	at org.scalatest.Suite$class.callExecuteOnSuite$1(Suite.scala:1492)
	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1528)
	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1526)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.scalatest.Suite$class.runNestedSuites(Suite.scala:1526)
	at org.scalatest.tools.DiscoverySuite.runNestedSuites(DiscoverySuite.scala:29)
	at org.scalatest.Suite$class.run(Suite.scala:1421)
	at org.scalatest.tools.DiscoverySuite.run(DiscoverySuite.scala:29)
	at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:55)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2563)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2557)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:2557)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1044)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1043)
	at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:2722)
	at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1043)
	at org.scalatest.tools.Runner$.main(Runner.scala:860)
	at org.scalatest.tools.Runner.main(Runner.scala)
[31m- 0374 *** FAILED ***[0m
[31m  org.apache.spark.sql.AnalysisException: cannot recognize input near 'SELECT' 'CITY' 'FROM' in function specification; line 1 pos 46[0m
[31m  at org.apache.spark.sql.hive.HiveQl$.createPlan(HiveQl.scala:296)[0m
[31m  at org.apache.spark.sql.hive.ExtendedHiveQlParser$$anonfun$hiveQl$1.apply(ExtendedHiveQlParser.scala:41)[0m
[31m  at org.apache.spark.sql.hive.ExtendedHiveQlParser$$anonfun$hiveQl$1.apply(ExtendedHiveQlParser.scala:40)[0m
[31m  at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)[0m
[31m  at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:135)[0m
[31m  at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)[0m
[31m  at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)[0m
[31m  at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)[0m
[31m  at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)[0m
[31m  at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)[0m
[31m  ...[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM  WORKS WHERE EMPNUM = 'E9'
[32m- 0375[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM  WORKS WHERE HOURS > 85
[32m- 0376[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM WORKS WHERE HOURS = 222
[32m- 0377[0m
Calcite parsing passed, start to transform. SELECT MIN(PNAME) FROM PROJ, WORKS, STAFF WHERE PROJ.PNUM = WORKS.PNUM AND WORKS.EMPNUM = STAFF.EMPNUM AND BUDGET - GRADE * HOURS * 100 IN (-4400, -1000, 4000)
[32m- 0378[0m
Calcite parsing passed, start to transform. SELECT CITY, COUNT(*) FROM PROJ GROUP BY CITY HAVING (MAX(BUDGET) - MIN(BUDGET)) / 2 IN (2, 20000, 10000) ORDER BY CITY DESC
[32m- 0379[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM TEMP_OBSERV WHERE MAX_TEMP = 123.45 AND MAX_TEMP NOT BETWEEN 123.4516 AND 123.4518
[32m- 0380[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM PROJ WHERE 24 * 1000 BETWEEN BUDGET - 5000 AND 50000 / 1.7
[32m- 0381[0m
Calcite parsing passed, start to transform. SELECT PNAME FROM PROJ WHERE 'Tampa' NOT BETWEEN CITY AND 'Vienna' AND PNUM > 'P2'
[32m- 0382[0m
Calcite parsing passed, start to transform. SELECT CITY, COUNT(*) FROM PROJ GROUP BY CITY HAVING 50000 + 2 BETWEEN 33000 AND SUM(BUDGET) - 20
[32m- 0383[0m
NoViableAltException(231@[])
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.function(HiveParser_IdentifiersParser.java:3544)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.atomExpression(HiveParser_IdentifiersParser.java:6280)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceFieldExpression(HiveParser_IdentifiersParser.java:6383)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceUnaryPrefixExpression(HiveParser_IdentifiersParser.java:6768)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceUnarySuffixExpression(HiveParser_IdentifiersParser.java:6828)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceBitwiseXorExpression(HiveParser_IdentifiersParser.java:7012)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceStarExpression(HiveParser_IdentifiersParser.java:7172)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedencePlusExpression(HiveParser_IdentifiersParser.java:7332)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceAmpersandExpression(HiveParser_IdentifiersParser.java:7483)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceBitwiseOrExpression(HiveParser_IdentifiersParser.java:7634)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceEqualExpression(HiveParser_IdentifiersParser.java:8290)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceNotExpression(HiveParser_IdentifiersParser.java:9177)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceAndExpression(HiveParser_IdentifiersParser.java:9296)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.precedenceOrExpression(HiveParser_IdentifiersParser.java:9455)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.expression(HiveParser_IdentifiersParser.java:6105)
	at org.apache.hadoop.hive.ql.parse.HiveParser.expression(HiveParser.java:45846)
	at org.apache.hadoop.hive.ql.parse.HiveParser_FromClauseParser.searchCondition(HiveParser_FromClauseParser.java:6637)
	at org.apache.hadoop.hive.ql.parse.HiveParser_FromClauseParser.whereClause(HiveParser_FromClauseParser.java:6545)
	at org.apache.hadoop.hive.ql.parse.HiveParser.whereClause(HiveParser.java:45849)
	at org.apache.hadoop.hive.ql.parse.HiveParser.selectStatement(HiveParser.java:41543)
	at org.apache.hadoop.hive.ql.parse.HiveParser.regularBody(HiveParser.java:41402)
	at org.apache.hadoop.hive.ql.parse.HiveParser.queryStatementExpressionBody(HiveParser.java:40413)
	at org.apache.hadoop.hive.ql.parse.HiveParser.queryStatementExpression(HiveParser.java:40283)
	at org.apache.hadoop.hive.ql.parse.HiveParser.execStatement(HiveParser.java:1590)
	at org.apache.hadoop.hive.ql.parse.HiveParser.statement(HiveParser.java:1109)
	at org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:202)
	at org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:166)
	at org.apache.spark.sql.hive.HiveQl$.getAst(HiveQl.scala:258)
	at org.apache.spark.sql.hive.HiveQl$.createPlan(HiveQl.scala:283)
	at org.apache.spark.sql.hive.ExtendedHiveQlParser$$anonfun$hiveQl$1.apply(ExtendedHiveQlParser.scala:41)
	at org.apache.spark.sql.hive.ExtendedHiveQlParser$$anonfun$hiveQl$1.apply(ExtendedHiveQlParser.scala:40)
	at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)
	at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:135)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)
	at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Failure.append(Parsers.scala:202)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)
	at scala.util.parsing.combinator.Parsers$$anon$2$$anonfun$apply$14.apply(Parsers.scala:891)
	at scala.util.parsing.combinator.Parsers$$anon$2$$anonfun$apply$14.apply(Parsers.scala:891)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)
	at scala.util.parsing.combinator.Parsers$$anon$2.apply(Parsers.scala:890)
	at scala.util.parsing.combinator.PackratParsers$$anon$1.apply(PackratParsers.scala:110)
	at org.apache.spark.sql.catalyst.AbstractSparkSQLParser.parse(AbstractSparkSQLParser.scala:34)
	at org.apache.spark.sql.hive.HiveQl$.parseSql(HiveQl.scala:276)
	at org.apache.spark.sql.hive.HiveQLDialect.parse(HiveContext.scala:62)
	at com.intel.ssg.bdt.spark.sql.CalciteDialect.getLogicalPlan(CalciteDialect.scala:54)
	at com.intel.ssg.bdt.spark.sql.CalciteDialect.parse(CalciteDialect.scala:31)
	at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)
	at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)
	at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:115)
	at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:114)
	at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)
	at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:135)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)
	at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Failure.append(Parsers.scala:202)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1.apply(Parsers.scala:254)
	at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)
	at scala.util.parsing.combinator.Parsers$$anon$2$$anonfun$apply$14.apply(Parsers.scala:891)
	at scala.util.parsing.combinator.Parsers$$anon$2$$anonfun$apply$14.apply(Parsers.scala:891)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)
	at scala.util.parsing.combinator.Parsers$$anon$2.apply(Parsers.scala:890)
	at scala.util.parsing.combinator.PackratParsers$$anon$1.apply(PackratParsers.scala:110)
	at org.apache.spark.sql.catalyst.AbstractSparkSQLParser.parse(AbstractSparkSQLParser.scala:34)
	at org.apache.spark.sql.SQLContext$$anonfun$2.apply(SQLContext.scala:166)
	at org.apache.spark.sql.SQLContext$$anonfun$2.apply(SQLContext.scala:166)
	at org.apache.spark.sql.execution.datasources.DDLParser.parse(DDLParser.scala:42)
	at org.apache.spark.sql.SQLContext.parseSql(SQLContext.scala:189)
	at org.apache.spark.sql.hive.HiveContext.parseSql(HiveContext.scala:280)
	at org.apache.spark.sql.hive.test.TestHiveContext$QueryExecution.<init>(TestHive.scala:179)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1$$anonfun$30.apply(HiveComparisonTest.scala:303)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1$$anonfun$30.apply(HiveComparisonTest.scala:303)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:34)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:244)
	at scala.collection.AbstractTraversable.map(Traversable.scala:105)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1.apply$mcV$sp(HiveComparisonTest.scala:303)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1.apply(HiveComparisonTest.scala:240)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1.apply(HiveComparisonTest.scala:240)
	at org.scalatest.Transformer$$anonfun$apply$1.apply$mcV$sp(Transformer.scala:22)
	at org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)
	at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
	at org.scalatest.Transformer.apply(Transformer.scala:22)
	at org.scalatest.Transformer.apply(Transformer.scala:20)
	at org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:166)
	at org.apache.spark.SparkFunSuite.withFixture(SparkFunSuite.scala:42)
	at org.scalatest.FunSuiteLike$class.invokeWithFixture$1(FunSuiteLike.scala:163)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)
	at org.scalatest.FunSuiteLike$class.runTest(FunSuiteLike.scala:175)
	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.org$scalatest$BeforeAndAfter$$super$runTest(HiveCompatibilitySuite.scala:32)
	at org.scalatest.BeforeAndAfter$class.runTest(BeforeAndAfter.scala:200)
	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.runTest(HiveCompatibilitySuite.scala:32)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:413)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:401)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)
	at org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:396)
	at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:483)
	at org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:208)
	at org.scalatest.FunSuite.runTests(FunSuite.scala:1555)
	at org.scalatest.Suite$class.run(Suite.scala:1424)
	at org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.SuperEngine.runImpl(Engine.scala:545)
	at org.scalatest.FunSuiteLike$class.run(FunSuiteLike.scala:212)
	at org.apache.spark.sql.hive.execution.HiveComparisonTest.org$scalatest$BeforeAndAfterAll$$super$run(HiveComparisonTest.scala:44)
	at org.scalatest.BeforeAndAfterAll$class.liftedTree1$1(BeforeAndAfterAll.scala:257)
	at org.scalatest.BeforeAndAfterAll$class.run(BeforeAndAfterAll.scala:256)
	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.org$scalatest$BeforeAndAfter$$super$run(HiveCompatibilitySuite.scala:32)
	at org.scalatest.BeforeAndAfter$class.run(BeforeAndAfter.scala:241)
	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.run(HiveCompatibilitySuite.scala:32)
	at org.scalatest.Suite$class.callExecuteOnSuite$1(Suite.scala:1492)
	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1528)
	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1526)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at org.scalatest.Suite$class.runNestedSuites(Suite.scala:1526)
	at org.scalatest.tools.DiscoverySuite.runNestedSuites(DiscoverySuite.scala:29)
	at org.scalatest.Suite$class.run(Suite.scala:1421)
	at org.scalatest.tools.DiscoverySuite.run(DiscoverySuite.scala:29)
	at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:55)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2563)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2557)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:2557)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1044)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1043)
	at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:2722)
	at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1043)
	at org.scalatest.tools.Runner$.main(Runner.scala:860)
	at org.scalatest.tools.Runner.main(Runner.scala)
[31m- 0384 *** FAILED ***[0m
[31m  org.apache.spark.sql.AnalysisException: cannot recognize input near 'SELECT' 'SUM' '(' in function specification; line 1 pos 66[0m
[31m  at org.apache.spark.sql.hive.HiveQl$.createPlan(HiveQl.scala:296)[0m
[31m  at org.apache.spark.sql.hive.ExtendedHiveQlParser$$anonfun$hiveQl$1.apply(ExtendedHiveQlParser.scala:41)[0m
[31m  at org.apache.spark.sql.hive.ExtendedHiveQlParser$$anonfun$hiveQl$1.apply(ExtendedHiveQlParser.scala:40)[0m
[31m  at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)[0m
[31m  at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:135)[0m
[31m  at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)[0m
[31m  at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)[0m
[31m  at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)[0m
[31m  at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)[0m
[31m  at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)[0m
[31m  ...[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM FLATER.USIG
[32m- 0385[0m
Calcite parsing passed, start to transform. SELECT C1 FROM WHICH_SCHEMA1
[32m- 0386[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM STAFF1
[32m- 0387[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM PROJ1
[32m- 0388[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM PROJ1
[32m- 0389[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM  WORKS1
[32m- 0390[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM   WORKS1
[32m- 0391[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM STAFFV1
[32m- 0392[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM STAFFV2
[32m- 0393[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM STAFFV2
[32m- 0394[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM STAFF
[32m- 0395[0m
Calcite parsing passed, start to transform. SELECT COUNT(*),SUM(COST) FROM STAFF_WORKS_DESIGN
[32m- 0396[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM VTABLE
[32m- 0397[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM CUGINI.VTABLE
[32m- 0398[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM CUGINI.VTABLE
[32m- 0399[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM WORKS
[32m- 0400[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM WORKS
[32m- 0401[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM TEMP_S
[32m- 0402[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM TEMP_S
[32m- 0403[0m
Calcite parsing passed, start to transform. SELECT COUNT(DISTINCT EMPNUM) FROM TEMP_S
[32m- 0404[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM STAFFV2_VIEW
[32m- 0405[0m
Calcite parsing passed, start to transform. SELECT EMPNUM, GRADE FROM STAFFV2_VIEW WHERE EMPNUM = 'E3'
[32m- 0406[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM STAFFV2_VIEW
[32m- 0407[0m
Calcite parsing passed, start to transform. SELECT EMPNUM, HOURS FROM DOMAIN_VIEW WHERE PNUM = 'P3'
[32m- 0408[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM DOMAIN_VIEW
[32m- 0409[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM DOMAIN_VIEW
[32m- 0410[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM WORKS
[32m- 0411[0m
Calcite parsing passed, start to transform. SELECT X.CITY, X.MAX_C, Y.MAX_C, (X.MAX_C + Y.MAX_C) / 2 FROM CELSIUS_OBSERV X, CELSIUS_OBSERV Y WHERE X.YEAR_OBSERV = 1984 AND Y.YEAR_OBSERV = 1985 AND X.CITY = Y.CITY ORDER BY 4 DESC
Calcite parsing passed, start to transform. SELECT X.CITY, X.MAX_C, Y.MAX_C, (X.MAX_C + Y.MAX_C) / 2 FROM CELSIUS_OBSERV X, CELSIUS_OBSERV Y WHERE X.YEAR_OBSERV = 1984 AND Y.YEAR_OBSERV = 1985 AND X.CITY = Y.CITY ORDER BY 4 DESC
Calcite parsing passed, start to transform. SELECT X.CITY, X.MAX_C, Y.MAX_C, (X.MAX_C + Y.MAX_C) / 2 FROM CELSIUS_OBSERV X, CELSIUS_OBSERV Y WHERE X.YEAR_OBSERV = 1984 AND Y.YEAR_OBSERV = 1985 AND X.CITY = Y.CITY ORDER BY 4 DESC
[31m- 0412 *** FAILED ***[0m
[31m  Results do not match for 0412:[0m
[31m  == Parsed Logical Plan ==[0m
[31m  'Sort ['c3 DESC], true[0m
[31m   'Project ['X.CITY,'X.MAX_C,'Y.MAX_C,(('X.MAX_C + 'Y.MAX_C) / 2) AS c3#71996][0m
[31m    'Filter ((('X.YEAR_OBSERV = 1984) && ('Y.YEAR_OBSERV = 1985)) && ('X.CITY = 'Y.CITY))[0m
[31m     'Join Inner, None[0m
[31m      'UnresolvedRelation [CELSIUS_OBSERV], Some(X)[0m
[31m      'UnresolvedRelation [CELSIUS_OBSERV], Some(Y)[0m
  
[31m  == Analyzed Logical Plan ==[0m
[31m  CITY: string, MAX_C: double, MAX_C: double, c3: double[0m
[31m  Sort [c3#71996 DESC], true[0m
[31m   Project [CITY#71997,MAX_C#72000,MAX_C#72004,((MAX_C#72000 + MAX_C#72004) / cast(2 as double)) AS c3#71996][0m
[31m    Filter (((YEAR_OBSERV#71998 = cast(1984 as double)) && (YEAR_OBSERV#72002 = cast(1985 as double))) && (CITY#71997 = CITY#72001))[0m
[31m     Join Inner, None[0m
[31m      MetastoreRelation HU, celsius_observ, Some(X)[0m
[31m      MetastoreRelation HU, celsius_observ, Some(Y)[0m
  
[31m  == Optimized Logical Plan ==[0m
[31m  Sort [c3#71996 DESC], true[0m
[31m   Project [CITY#71997,MAX_C#72000,MAX_C#72004,((MAX_C#72000 + MAX_C#72004) / 2.0) AS c3#71996][0m
[31m    Join Inner, Some((CITY#71997 = CITY#72001))[0m
[31m     Project [CITY#71997,MAX_C#72000][0m
[31m      Filter (YEAR_OBSERV#71998 = 1984.0)[0m
[31m       MetastoreRelation HU, celsius_observ, Some(X)[0m
[31m     Project [MAX_C#72004,CITY#72001][0m
[31m      Filter (YEAR_OBSERV#72002 = 1985.0)[0m
[31m       MetastoreRelation HU, celsius_observ, Some(Y)[0m
  
[31m  == Physical Plan ==[0m
[31m  TungstenSort [c3#71996 DESC], true, 0[0m
[31m   ConvertToUnsafe[0m
[31m    Exchange rangepartitioning(c3#71996 DESC)[0m
[31m     ConvertToSafe[0m
[31m      TungstenProject [CITY#71997,MAX_C#72000,MAX_C#72004,((MAX_C#72000 + MAX_C#72004) / 2.0) AS c3#71996][0m
[31m       BroadcastHashJoin [CITY#71997], [CITY#72001], BuildRight[0m
[31m        ConvertToUnsafe[0m
[31m         Project [CITY#71997,MAX_C#72000][0m
[31m          Filter (YEAR_OBSERV#71998 = 1984.0)[0m
[31m           HiveTableScan [CITY#71997,MAX_C#72000,YEAR_OBSERV#71998], (MetastoreRelation HU, celsius_observ, Some(X))[0m
[31m        ConvertToUnsafe[0m
[31m         Project [MAX_C#72004,CITY#72001][0m
[31m          Filter (YEAR_OBSERV#72002 = 1985.0)[0m
[31m           HiveTableScan [MAX_C#72004,CITY#72001,YEAR_OBSERV#72002], (MetastoreRelation HU, celsius_observ, Some(Y))[0m
  
[31m  Code Generation: true[0m
[31m  CITY	MAX_C	MAX_C	c3[0m
[31m  !== HIVE - 3 row(s) ==                                                                                                                    == CATALYST - 3 row(s) ==[0m
[31m  !Sun City	43.33333333333333333333333333333333333333	40.55555555555555555555555555555555555556	41.94444444444444444444444444444444444445   Sun City	43.333333333333336	40.55555555555556	41.94444444444444[0m
[31m  !Abeland	38.33333333333333333333333333333333333333	36.66666666666666666666666666666666666667	37.5                                         Abeland	38.333333333333336	36.666666666666664	37.5[0m
[31m  !Iceburg	7.22222222222222222222222222222222222222	8.33333333333333333333333333333333333333	7.77777777777777777777777777777777777778       Iceburg	7.222222222222222	8.333333333333334	7.777777777777779 (HiveComparisonTest.scala:433)[0m
Calcite parsing passed, start to transform. SELECT CITY, YEAR_OBSERV, MIN_C, MAX_C FROM CELSIUS_OBSERV WHERE YEAR_OBSERV = 1984 AND MIN_C > 5
Calcite parsing passed, start to transform. SELECT CITY, YEAR_OBSERV, MIN_C, MAX_C FROM CELSIUS_OBSERV WHERE YEAR_OBSERV = 1984 AND MIN_C > 5
Calcite parsing passed, start to transform. SELECT CITY, YEAR_OBSERV, MIN_C, MAX_C FROM CELSIUS_OBSERV WHERE YEAR_OBSERV = 1984 AND MIN_C > 5
[31m- 0413 *** FAILED ***[0m
[31m  Results do not match for 0413:[0m
[31m  == Parsed Logical Plan ==[0m
[31m  'Project ['CITY,'YEAR_OBSERV,'MIN_C,'MAX_C][0m
[31m   'Filter (('YEAR_OBSERV = 1984) && ('MIN_C > 5))[0m
[31m    'UnresolvedRelation [CELSIUS_OBSERV], None[0m
  
[31m  == Analyzed Logical Plan ==[0m
[31m  CITY: string, YEAR_OBSERV: double, MIN_C: double, MAX_C: double[0m
[31m  Project [CITY#72198,YEAR_OBSERV#72199,MIN_C#72200,MAX_C#72201][0m
[31m   Filter ((YEAR_OBSERV#72199 = cast(1984 as double)) && (MIN_C#72200 > cast(5 as double)))[0m
[31m    MetastoreRelation HU, celsius_observ, None[0m
  
[31m  == Optimized Logical Plan ==[0m
[31m  Project [CITY#72198,YEAR_OBSERV#72199,MIN_C#72200,MAX_C#72201][0m
[31m   Filter ((YEAR_OBSERV#72199 = 1984.0) && (MIN_C#72200 > 5.0))[0m
[31m    MetastoreRelation HU, celsius_observ, None[0m
  
[31m  == Physical Plan ==[0m
[31m  Filter ((YEAR_OBSERV#72199 = 1984.0) && (MIN_C#72200 > 5.0))[0m
[31m   HiveTableScan [CITY#72198,YEAR_OBSERV#72199,MIN_C#72200,MAX_C#72201], (MetastoreRelation HU, celsius_observ, None)[0m
  
[31m  Code Generation: true[0m
[31m  CITY	YEAR_OBSERV	MIN_C	MAX_C[0m
[31m  !== HIVE - 1 row(s) ==                                                                              == CATALYST - 1 row(s) ==[0m
[31m  !Sun City	1984	6.66666666666666666666666666666666666667	43.33333333333333333333333333333333333333   Sun City	1984.0	6.666666666666667	43.333333333333336 (HiveComparisonTest.scala:433)[0m
Calcite parsing passed, start to transform. SELECT CITY, HIGH, LOW FROM MULTI_YEAR_OBSERV ORDER BY CITY ASC
Calcite parsing passed, start to transform. SELECT CITY, HIGH, LOW FROM MULTI_YEAR_OBSERV ORDER BY CITY ASC
Calcite parsing passed, start to transform. SELECT CITY, HIGH, LOW FROM MULTI_YEAR_OBSERV ORDER BY CITY ASC
[31m- 0414 *** FAILED ***[0m
[31m  Results do not match for 0414:[0m
[31m  == Parsed Logical Plan ==[0m
[31m  'Sort ['CITY ASC], true[0m
[31m   'Project ['CITY,'HIGH,'LOW][0m
[31m    'UnresolvedRelation [MULTI_YEAR_OBSERV], None[0m
  
[31m  == Analyzed Logical Plan ==[0m
[31m  CITY: string, HIGH: double, LOW: double[0m
[31m  Sort [CITY#72385 ASC], true[0m
[31m   Project [CITY#72385,HIGH#72386,LOW#72387][0m
[31m    MetastoreRelation HU, multi_year_observ, None[0m
  
[31m  == Optimized Logical Plan ==[0m
[31m  Sort [CITY#72385 ASC], true[0m
[31m   Project [CITY#72385,HIGH#72386,LOW#72387][0m
[31m    MetastoreRelation HU, multi_year_observ, None[0m
  
[31m  == Physical Plan ==[0m
[31m  TungstenSort [CITY#72385 ASC], true, 0[0m
[31m   ConvertToUnsafe[0m
[31m    Exchange rangepartitioning(CITY#72385 ASC)[0m
[31m     HiveTableScan [CITY#72385,HIGH#72386,LOW#72387], (MetastoreRelation HU, multi_year_observ, None)[0m
  
[31m  Code Generation: true[0m
[31m  CITY	HIGH	LOW[0m
[31m  !== HIVE - 3 row(s) ==   == CATALYST - 3 row(s) ==[0m
[31m   Abeland	99.5	3.5        Abeland	99.5	3.5[0m
[31m  !Iceburg	46	-86          Iceburg	46.0	-86.0[0m
[31m  !Sun City	107.5	47       Sun City	107.5	47.0 (HiveComparisonTest.scala:433)[0m
Calcite parsing passed, start to transform. SELECT HIGH, YEAR_OBSERV, LOW FROM EXTREME_TEMPS ORDER BY YEAR_OBSERV DESC
Calcite parsing passed, start to transform. SELECT HIGH, YEAR_OBSERV, LOW FROM EXTREME_TEMPS ORDER BY YEAR_OBSERV DESC
Calcite parsing passed, start to transform. SELECT HIGH, YEAR_OBSERV, LOW FROM EXTREME_TEMPS ORDER BY YEAR_OBSERV DESC
[31m- 0415 *** FAILED ***[0m
[31m  Results do not match for 0415:[0m
[31m  == Parsed Logical Plan ==[0m
[31m  'Sort ['YEAR_OBSERV DESC], true[0m
[31m   'Project ['HIGH,'YEAR_OBSERV,'LOW][0m
[31m    'UnresolvedRelation [EXTREME_TEMPS], None[0m
  
[31m  == Analyzed Logical Plan ==[0m
[31m  HIGH: double, YEAR_OBSERV: double, LOW: double[0m
[31m  Sort [YEAR_OBSERV#72569 DESC], true[0m
[31m   Project [HIGH#72570,YEAR_OBSERV#72569,LOW#72571][0m
[31m    MetastoreRelation HU, extreme_temps, None[0m
  
[31m  == Optimized Logical Plan ==[0m
[31m  Sort [YEAR_OBSERV#72569 DESC], true[0m
[31m   Project [HIGH#72570,YEAR_OBSERV#72569,LOW#72571][0m
[31m    MetastoreRelation HU, extreme_temps, None[0m
  
[31m  == Physical Plan ==[0m
[31m  TungstenSort [YEAR_OBSERV#72569 DESC], true, 0[0m
[31m   ConvertToUnsafe[0m
[31m    Exchange rangepartitioning(YEAR_OBSERV#72569 DESC)[0m
[31m     HiveTableScan [HIGH#72570,YEAR_OBSERV#72569,LOW#72571], (MetastoreRelation HU, extreme_temps, None)[0m
  
[31m  Code Generation: true[0m
[31m  HIGH	YEAR_OBSERV	LOW[0m
[31m  !== HIVE - 2 row(s) ==   == CATALYST - 2 row(s) ==[0m
[31m  !105	1985	-82            105.0	1985.0	-82.0[0m
[31m  !110	1984	-90            110.0	1984.0	-90.0 (HiveComparisonTest.scala:433)[0m
Calcite parsing passed, start to transform. SELECT EMP1, EMP_AVG, EMP_MAX FROM SET_TEST ORDER BY EMP1
Calcite parsing passed, start to transform. SELECT EMP1, EMP_AVG, EMP_MAX FROM SET_TEST ORDER BY EMP1
Calcite parsing passed, start to transform. SELECT EMP1, EMP_AVG, EMP_MAX FROM SET_TEST ORDER BY EMP1
[31m- 0416 *** FAILED ***[0m
[31m  Results do not match for 0416:[0m
[31m  == Parsed Logical Plan ==[0m
[31m  'Sort ['EMP1 ASC], true[0m
[31m   'Project ['EMP1,'EMP_AVG,'EMP_MAX][0m
[31m    'UnresolvedRelation [SET_TEST], None[0m
  
[31m  == Analyzed Logical Plan ==[0m
[31m  EMP1: string, EMP_AVG: double, EMP_MAX: double[0m
[31m  Sort [EMP1#72753 ASC], true[0m
[31m   Project [EMP1#72753,EMP_AVG#72754,EMP_MAX#72755][0m
[31m    MetastoreRelation HU, set_test, None[0m
  
[31m  == Optimized Logical Plan ==[0m
[31m  Sort [EMP1#72753 ASC], true[0m
[31m   Project [EMP1#72753,EMP_AVG#72754,EMP_MAX#72755][0m
[31m    MetastoreRelation HU, set_test, None[0m
  
[31m  == Physical Plan ==[0m
[31m  TungstenSort [EMP1#72753 ASC], true, 0[0m
[31m   ConvertToUnsafe[0m
[31m    Exchange rangepartitioning(EMP1#72753 ASC)[0m
[31m     HiveTableScan [EMP1#72753,EMP_AVG#72754,EMP_MAX#72755], (MetastoreRelation HU, set_test, None)[0m
  
[31m  Code Generation: true[0m
[31m  EMP1	EMP_AVG	EMP_MAX[0m
[31m  !== HIVE - 7 row(s) ==   == CATALYST - 7 row(s) ==[0m
[31m  !E1	66.25	100            E1	66.25	100.0[0m
[31m  !E36	66.25	100           E36	66.25	100.0[0m
[31m  !E6	66.25	100            E6	66.25	100.0[0m
[31m  !E7	66.25	100            E7	66.25	100.0[0m
[31m  !E8	66.25	100            E8	66.25	100.0[0m
[31m  !E9	66.25	100            E9	66.25	100.0[0m
[31m  !e1	66.25	100            e1	66.25	100.0 (HiveComparisonTest.scala:433)[0m
Calcite parsing passed, start to transform. SELECT EMP1, HOURS, HOURS_2 FROM DUP_COL WHERE EMP1 = 'E3'
Calcite parsing passed, start to transform. SELECT EMP1, HOURS, HOURS_2 FROM DUP_COL WHERE EMP1 = 'E3'
Calcite parsing passed, start to transform. SELECT EMP1, HOURS, HOURS_2 FROM DUP_COL WHERE EMP1 = 'E3'
[31m- 0417 *** FAILED ***[0m
[31m  Results do not match for 0417:[0m
[31m  == Parsed Logical Plan ==[0m
[31m  'Project ['EMP1,'HOURS,'HOURS_2][0m
[31m   'Filter ('EMP1 = E3)[0m
[31m    'UnresolvedRelation [DUP_COL], None[0m
  
[31m  == Analyzed Logical Plan ==[0m
[31m  EMP1: string, HOURS: double, HOURS_2: double[0m
[31m  Project [EMP1#72937,HOURS#72939,HOURS_2#72940][0m
[31m   Filter (EMP1#72937 = E3)[0m
[31m    MetastoreRelation HU, dup_col, None[0m
  
[31m  == Optimized Logical Plan ==[0m
[31m  Project [EMP1#72937,HOURS#72939,HOURS_2#72940][0m
[31m   Filter (EMP1#72937 = E3)[0m
[31m    MetastoreRelation HU, dup_col, None[0m
  
[31m  == Physical Plan ==[0m
[31m  Filter (EMP1#72937 = E3)[0m
[31m   HiveTableScan [EMP1#72937,HOURS#72939,HOURS_2#72940], (MetastoreRelation HU, dup_col, None)[0m
  
[31m  Code Generation: true[0m
[31m  EMP1	HOURS	HOURS_2[0m
[31m  !== HIVE - 3 row(s) ==   == CATALYST - 3 row(s) ==[0m
[31m  !E3	100	200              E3	100.0	200.0[0m
[31m  !E3	100	200              E3	100.0	200.0[0m
[31m   E3	NULL	NULL            E3	NULL	NULL (HiveComparisonTest.scala:433)[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM CPBASE, CPREF
[32m- 0418[0m
Calcite parsing passed, start to transform. SELECT KC, JUNK2 FROM CPBASE, CPREF ORDER BY JUNK2, KC
Calcite parsing passed, start to transform. SELECT KC, JUNK2 FROM CPBASE, CPREF ORDER BY JUNK2, KC
Calcite parsing passed, start to transform. SELECT KC, JUNK2 FROM CPBASE, CPREF ORDER BY JUNK2, KC
[31m- 0419 *** FAILED ***[0m
[31m  Results do not match for 0419:[0m
[31m  == Parsed Logical Plan ==[0m
[31m  'Sort ['JUNK2 ASC,'KC ASC], true[0m
[31m   'Project ['KC,'JUNK2][0m
[31m    'Join Inner, None[0m
[31m     'UnresolvedRelation [CPBASE], None[0m
[31m     'UnresolvedRelation [CPREF], None[0m
  
[31m  == Analyzed Logical Plan ==[0m
[31m  KC: double, JUNK2: string[0m
[31m  Sort [JUNK2#73249 ASC,KC#73246 ASC], true[0m
[31m   Project [KC#73246,JUNK2#73249][0m
[31m    Join Inner, None[0m
[31m     MetastoreRelation SCHANZLE, cpbase, None[0m
[31m     MetastoreRelation SCHANZLE, cpref, None[0m
  
[31m  == Optimized Logical Plan ==[0m
[31m  Sort [JUNK2#73249 ASC,KC#73246 ASC], true[0m
[31m   Project [KC#73246,JUNK2#73249][0m
[31m    Join Inner, None[0m
[31m     Project [KC#73246][0m
[31m      MetastoreRelation SCHANZLE, cpbase, None[0m
[31m     Project [JUNK2#73249][0m
[31m      MetastoreRelation SCHANZLE, cpref, None[0m
  
[31m  == Physical Plan ==[0m
[31m  TungstenSort [JUNK2#73249 ASC,KC#73246 ASC], true, 0[0m
[31m   ConvertToUnsafe[0m
[31m    Exchange rangepartitioning(JUNK2#73249 ASC,KC#73246 ASC)[0m
[31m     ConvertToSafe[0m
[31m      TungstenProject [KC#73246,JUNK2#73249][0m
[31m       CartesianProduct[0m
[31m        HiveTableScan [KC#73246], (MetastoreRelation SCHANZLE, cpbase, None)[0m
[31m        HiveTableScan [JUNK2#73249], (MetastoreRelation SCHANZLE, cpref, None)[0m
  
[31m  Code Generation: true[0m
[31m  KC	JUNK2[0m
[31m  !== HIVE - 4 row(s) ==   == CATALYST - 4 row(s) ==[0m
[31m  !0	One 2                 0.0	One 2[0m
[31m  !1	One 2                 1.0	One 2[0m
[31m  !0	Zero 2                0.0	Zero 2[0m
[31m  !1	Zero 2                1.0	Zero 2 (HiveComparisonTest.scala:433)[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM RET_CATALOG
[32m- 0420[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM RET_CATALOG
[32m- 0421[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM RET_CATALOG WHERE PRODUCT_ID = 0
[32m- 0422[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM RET_CATALOG
[32m- 0423[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM RET_CATALOG WHERE PRODUCT_ID = 0
[32m- 0424[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM RET_CATALOG
[32m- 0425[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM RET_CATALOG WHERE PRODUCT_ID = 0
[32m- 0426[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM RET_CATALOG
[32m- 0427[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM RET_CATALOG WHERE PRODUCT_ID = 0
[32m- 0428[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM RET_CATALOG
[32m- 0429[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM RET_CATALOG
[32m- 0430[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM RET_CATALOG
[32m- 0431[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM HU.WORKS
[32m- 0432[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM HU.WORKS WHERE PNUM = (SELECT PNUM FROM HU.WORKS WHERE HOURS = 80)
error SELECT COUNT(*) FROM HU.WORKS WHERE PNUM = (SELECT PNUM FROM HU.WORKS WHERE HOURS = 80)[31m- 0433 ***  ***[0m
[31m  java.lang.RuntimeException: Parse failed.[0m
[31m  at scala.sys.package$.error(package.scala:27)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect$$anonfun$parse$1.apply(CalciteDialect.scala:33)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect$$anonfun$parse$1.apply(CalciteDialect.scala:32)[0m
[31m  at scala.Option.getOrElse(Option.scala:120)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect.parse(CalciteDialect.scala:31)[0m
[31m  at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)[0m
[31m  at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)[0m
[31m  at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:115)[0m
[31m  at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:114)[0m
[31m  at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)[0m
[31m  ...[0m
Calcite parsing passed, start to transform. SELECT GRADE FROM HU.STAFF WHERE EMPNUM = 'xx'
[32m- 0434[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM HU.STAFF WHERE CITY LIKE '%XX%X_%' ESCAPE 'X'
[32m- 0435[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM HU.STAFF WHERE CITY LIKE '%XX_%' ESCAPE 'X'
[32m- 0436[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM CPBASE WHERE JUNK1 LIKE 'P%X%%' ESCAPE 'X'
[32m- 0437[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM HU.STAFF
[32m- 0438[0m
Calcite parsing passed, start to transform. SELECT AVG(SMALLTEST) FROM HU.HH
Calcite parsing passed, start to transform. SELECT AVG(SMALLTEST) FROM HU.HH
Calcite parsing passed, start to transform. SELECT AVG(SMALLTEST) FROM HU.HH
[31m- 0439 *** FAILED ***[0m
[31m  Results do not match for 0439:[0m
[31m  == Parsed Logical Plan ==[0m
[31m  'Project ['AVG('SMALLTEST) AS c0#75919][0m
[31m   'UnresolvedRelation [HU,HH], None[0m
  
[31m  == Analyzed Logical Plan ==[0m
[31m  c0: double[0m
[31m  Aggregate [avg(SMALLTEST#75920) AS c0#75919][0m
[31m   MetastoreRelation hu, hh, None[0m
  
[31m  == Optimized Logical Plan ==[0m
[31m  Aggregate [avg(SMALLTEST#75920) AS c0#75919][0m
[31m   MetastoreRelation hu, hh, None[0m
  
[31m  == Physical Plan ==[0m
[31m  TungstenAggregate(key=[], functions=[(average(SMALLTEST#75920),mode=Final,isDistinct=false)], output=[c0#75919])[0m
[31m   TungstenExchange SinglePartition[0m
[31m    TungstenAggregate(key=[], functions=[(average(SMALLTEST#75920),mode=Partial,isDistinct=false)], output=[currentSum#75925,currentCount#75926L])[0m
[31m     HiveTableScan [smalltest#75920], (MetastoreRelation hu, hh, None)[0m
  
[31m  Code Generation: true[0m
[31m  c0[0m
[31m  !== HIVE - 1 row(s) ==   == CATALYST - 1 row(s) ==[0m
[31m  !3                       3.0 (HiveComparisonTest.scala:433)[0m
Calcite parsing passed, start to transform. SELECT AVG(GRADE) FROM HU.STAFF WHERE CITY = 'Vienna'
[32m- 0440[0m
Calcite parsing passed, start to transform. SELECT SUM(DISTINCT GRADE) FROM HU.STAFF
Calcite parsing passed, start to transform. SELECT SUM(DISTINCT GRADE) FROM HU.STAFF
Calcite parsing passed, start to transform. SELECT SUM(DISTINCT GRADE) FROM HU.STAFF
[31m- 0441 *** FAILED ***[0m
[31m  Results do not match for 0441:[0m
[31m  == Parsed Logical Plan ==[0m
[31m  'Project [SUM(DISTINCT 'GRADE) AS c0#76536][0m
[31m   'UnresolvedRelation [HU,STAFF], None[0m
  
[31m  == Analyzed Logical Plan ==[0m
[31m  c0: double[0m
[31m  Aggregate [SUM(DISTINCT GRADE#76539) AS c0#76536][0m
[31m   MetastoreRelation hu, staff, None[0m
  
[31m  == Optimized Logical Plan ==[0m
[31m  Aggregate [SUM(DISTINCT GRADE#76539) AS c0#76536][0m
[31m   Project [GRADE#76539][0m
[31m    MetastoreRelation hu, staff, None[0m
  
[31m  == Physical Plan ==[0m
[31m  TungstenAggregate(key=[], functions=[(sum(GRADE#76539),mode=Complete,isDistinct=true)], output=[c0#76536])[0m
[31m   TungstenAggregate(key=[GRADE#76539], functions=[], output=[GRADE#76539])[0m
[31m    TungstenExchange SinglePartition[0m
[31m     TungstenAggregate(key=[GRADE#76539], functions=[], output=[GRADE#76539])[0m
[31m      HiveTableScan [GRADE#76539], (MetastoreRelation hu, staff, None)[0m
  
[31m  Code Generation: true[0m
[31m  c0[0m
[31m  !== HIVE - 1 row(s) ==   == CATALYST - 1 row(s) ==[0m
[31m  !82                      82.0 (HiveComparisonTest.scala:433)[0m
Calcite parsing passed, start to transform. SELECT CITY, COUNT(DISTINCT GRADE) FROM HU.STAFF GROUP BY CITY ORDER BY CITY DESC
[32m- 0442[0m
Calcite parsing passed, start to transform. SELECT COL2 FROM HU.UPUNIQ WHERE NUMKEY = 1
[32m- 0443[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM HU.STAFF WHERE GRADE < (SELECT MAX(HOURS) FROM HU.WORKS) OR    GRADE > (SELECT MAX(NUMKEY) FROM HU.UPUNIQ) OR    GRADE + 100 > (SELECT MIN(HOURS) FROM HU.WORKS)
error SELECT COUNT(*) FROM HU.STAFF WHERE GRADE < (SELECT MAX(HOURS) FROM HU.WORKS) OR    GRADE > (SELECT MAX(NUMKEY) FROM HU.UPUNIQ) OR    GRADE + 100 > (SELECT MIN(HOURS) FROM HU.WORKS)[31m- 0444 ***  ***[0m
[31m  java.lang.RuntimeException: Parse failed.[0m
[31m  at scala.sys.package$.error(package.scala:27)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect$$anonfun$parse$1.apply(CalciteDialect.scala:33)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect$$anonfun$parse$1.apply(CalciteDialect.scala:32)[0m
[31m  at scala.Option.getOrElse(Option.scala:120)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect.parse(CalciteDialect.scala:31)[0m
[31m  at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)[0m
[31m  at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)[0m
[31m  at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:115)[0m
[31m  at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:114)[0m
[31m  at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)[0m
[31m  ...[0m
Calcite parsing passed, start to transform. SELECT COL2 FROM HU.UPUNIQ WHERE NUMKEY = 1
[32m- 0445[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM HU.STAFF WHERE GRADE < (SELECT MAX(HOURS) FROM HU.WORKS) OR    GRADE > (SELECT MAX(NUMKEY) FROM HU.UPUNIQ) OR    GRADE + 100 > (SELECT MIN(HOURS) FROM HU.WORKS)
error SELECT COUNT(*) FROM HU.STAFF WHERE GRADE < (SELECT MAX(HOURS) FROM HU.WORKS) OR    GRADE > (SELECT MAX(NUMKEY) FROM HU.UPUNIQ) OR    GRADE + 100 > (SELECT MIN(HOURS) FROM HU.WORKS)[31m- 0446 ***  ***[0m
[31m  java.lang.RuntimeException: Parse failed.[0m
[31m  at scala.sys.package$.error(package.scala:27)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect$$anonfun$parse$1.apply(CalciteDialect.scala:33)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect$$anonfun$parse$1.apply(CalciteDialect.scala:32)[0m
[31m  at scala.Option.getOrElse(Option.scala:120)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect.parse(CalciteDialect.scala:31)[0m
[31m  at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)[0m
[31m  at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)[0m
[31m  at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:115)[0m
[31m  at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:114)[0m
[31m  at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)[0m
[31m  ...[0m
Calcite parsing passed, start to transform. SELECT "A < a".CITY FROM HU.STAFF "A < a" WHERE EMPNUM = 'E5'
[32m- 0449[0m
Calcite parsing passed, start to transform. SELECT "0".CITY FROM HU.STAFF "0" WHERE EMPNUM = 'E5'
[32m- 0450[0m
Calcite parsing passed, start to transform. SELECT "%".CITY FROM HU.STAFF  "%" WHERE EMPNUM = 'E5'
[32m- 0451[0m
Calcite parsing passed, start to transform. SELECT "&".CITY FROM HU.STAFF  "&" WHERE EMPNUM = 'E5'
[32m- 0452[0m
Calcite parsing passed, start to transform. SELECT "'".CITY FROM HU.STAFF  "'" WHERE EMPNUM = 'E5'
[32m- 0453[0m
Calcite parsing passed, start to transform. SELECT "(".CITY FROM HU.STAFF  "(" WHERE EMPNUM = 'E5'
[32m- 0454[0m
Calcite parsing passed, start to transform. SELECT ")".CITY FROM HU.STAFF  ")" WHERE EMPNUM = 'E5'
[32m- 0455[0m
Calcite parsing passed, start to transform. SELECT "*".CITY FROM HU.STAFF  "*" WHERE EMPNUM = 'E5'
error SELECT "*".CITY FROM HU.STAFF  "*" WHERE EMPNUM = 'E5'[31m- 0456 ***  ***[0m
[31m  java.lang.RuntimeException: Parse failed.[0m
[31m  at scala.sys.package$.error(package.scala:27)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect$$anonfun$parse$1.apply(CalciteDialect.scala:33)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect$$anonfun$parse$1.apply(CalciteDialect.scala:32)[0m
[31m  at scala.Option.getOrElse(Option.scala:120)[0m
[31m  at com.intel.ssg.bdt.spark.sql.CalciteDialect.parse(CalciteDialect.scala:31)[0m
[31m  at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)[0m
[31m  at org.apache.spark.sql.SQLContext$$anonfun$3.apply(SQLContext.scala:169)[0m
[31m  at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:115)[0m
[31m  at org.apache.spark.sql.SparkSQLParser$$anonfun$org$apache$spark$sql$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:114)[0m
[31m  at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)[0m
[31m  ...[0m
Calcite parsing passed, start to transform. SELECT "+".CITY FROM HU.STAFF  "+" WHERE EMPNUM = 'E5'
[32m- 0457[0m
Calcite parsing passed, start to transform. SELECT ",".CITY FROM HU.STAFF  "," WHERE EMPNUM = 'E5'
[32m- 0458[0m
Calcite parsing passed, start to transform. SELECT "-".CITY FROM HU.STAFF  "-" WHERE EMPNUM = 'E5'
[32m- 0459[0m
Calcite parsing passed, start to transform. SELECT ".".CITY FROM HU.STAFF  "." WHERE EMPNUM = 'E5'
[31m- 0460 *** FAILED ***[0m
[31m  Failed to execute query using catalyst:[0m
[31m  Error: cannot resolve '..CITY' given input columns empnum, empname, grade, city;[0m
[31m  org.apache.spark.sql.AnalysisException: cannot resolve '..CITY' given input columns empnum, empname, grade, city;[0m
[31m  	at org.apache.spark.sql.catalyst.analysis.package$AnalysisErrorAt.failAnalysis(package.scala:42)[0m
[31m  	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$apply$2.applyOrElse(CheckAnalysis.scala:56)[0m
[31m  	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$apply$2.applyOrElse(CheckAnalysis.scala:53)[0m
[31m  	at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformUp$1.apply(TreeNode.scala:293)[0m
[31m  	at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformUp$1.apply(TreeNode.scala:293)[0m
[31m  	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:51)[0m
[31m  	at org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:292)[0m
[31m  	at org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpressionUp$1(QueryPlan.scala:108)[0m
[31m  	at org.apache.spark.sql.catalyst.plans.QueryPlan.org$apache$spark$sql$catalyst$plans$QueryPlan$$recursiveTransform$2(QueryPlan.scala:118)[0m
[31m  	at org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$org$apache$spark$sql$catalyst$plans$QueryPlan$$recursiveTransform$2$1.apply(QueryPlan.scala:122)[0m
[31m  	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)[0m
[31m  	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)[0m
[31m  	at scala.collection.immutable.List.foreach(List.scala:318)[0m
[31m  	at scala.collection.TraversableLike$class.map(TraversableLike.scala:244)[0m
[31m  	at scala.collection.AbstractTraversable.map(Traversable.scala:105)[0m
[31m  	at org.apache.spark.sql.catalyst.plans.QueryPlan.org$apache$spark$sql$catalyst$plans$QueryPlan$$recursiveTransform$2(QueryPlan.scala:122)[0m
[31m  	at org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$2.apply(QueryPlan.scala:126)[0m
[31m  	at scala.collection.Iterator$$anon$11.next(Iterator.scala:328)[0m
[31m  	at scala.collection.Iterator$class.foreach(Iterator.scala:727)[0m
[31m  	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)[0m
[31m  	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:48)[0m
[31m  	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:103)[0m
[31m  	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:47)[0m
[31m  	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:273)[0m
[31m  	at scala.collection.AbstractIterator.to(Iterator.scala:1157)[0m
[31m  	at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:265)[0m
[31m  	at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1157)[0m
[31m  	at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:252)[0m
[31m  	at scala.collection.AbstractIterator.toArray(Iterator.scala:1157)[0m
[31m  	at org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpressionsUp(QueryPlan.scala:126)[0m
[31m  	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1.apply(CheckAnalysis.scala:53)[0m
[31m  	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1.apply(CheckAnalysis.scala:49)[0m
[31m  	at org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:103)[0m
[31m  	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis$class.checkAnalysis(CheckAnalysis.scala:49)[0m
[31m  	at org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis(Analyzer.scala:44)[0m
[31m  	at org.apache.spark.sql.SQLContext$QueryExecution.assertAnalyzed(SQLContext.scala:908)[0m
[31m  	at org.apache.spark.sql.SQLContext$QueryExecution.withCachedData$lzycompute(SQLContext.scala:912)[0m
[31m  	at org.apache.spark.sql.SQLContext$QueryExecution.withCachedData(SQLContext.scala:911)[0m
[31m  	at org.apache.spark.sql.SQLContext$QueryExecution.optimizedPlan$lzycompute(SQLContext.scala:915)[0m
[31m  	at org.apache.spark.sql.SQLContext$QueryExecution.optimizedPlan(SQLContext.scala:915)[0m
[31m  	at org.apache.spark.sql.SQLContext$QueryExecution.sparkPlan$lzycompute(SQLContext.scala:920)[0m
[31m  	at org.apache.spark.sql.SQLContext$QueryExecution.sparkPlan(SQLContext.scala:918)[0m
[31m  	at org.apache.spark.sql.SQLContext$QueryExecution.executedPlan$lzycompute(SQLContext.scala:924)[0m
[31m  	at org.apache.spark.sql.SQLContext$QueryExecution.executedPlan(SQLContext.scala:924)[0m
[31m  	at org.apache.spark.sql.hive.HiveContext$QueryExecution.stringResult(HiveContext.scala:573)[0m
[31m  	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1$$anonfun$33.apply(HiveComparisonTest.scala:354)[0m
[31m  	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1$$anonfun$33.apply(HiveComparisonTest.scala:352)[0m
[31m  	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)[0m
[31m  	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)[0m
[31m  	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)[0m
[31m  	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)[0m
[31m  	at scala.collection.TraversableLike$class.map(TraversableLike.scala:244)[0m
[31m  	at scala.collection.AbstractTraversable.map(Traversable.scala:105)[0m
[31m  	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1.apply$mcV$sp(HiveComparisonTest.scala:352)[0m
[31m  	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1.apply(HiveComparisonTest.scala:240)[0m
[31m  	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1.apply(HiveComparisonTest.scala:240)[0m
[31m  	at org.scalatest.Transformer$$anonfun$apply$1.apply$mcV$sp(Transformer.scala:22)[0m
[31m  	at org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)[0m
[31m  	at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)[0m
[31m  	at org.scalatest.Transformer.apply(Transformer.scala:22)[0m
[31m  	at org.scalatest.Transformer.apply(Transformer.scala:20)[0m
[31m  	at org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:166)[0m
[31m  	at org.apache.spark.SparkFunSuite.withFixture(SparkFunSuite.scala:42)[0m
[31m  	at org.scalatest.FunSuiteLike$class.invokeWithFixture$1(FunSuiteLike.scala:163)[0m
[31m  	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)[0m
[31m  	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)[0m
[31m  	at org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)[0m
[31m  	at org.scalatest.FunSuiteLike$class.runTest(FunSuiteLike.scala:175)[0m
[31m  	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.org$scalatest$BeforeAndAfter$$super$runTest(HiveCompatibilitySuite.scala:32)[0m
[31m  	at org.scalatest.BeforeAndAfter$class.runTest(BeforeAndAfter.scala:200)[0m
[31m  	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.runTest(HiveCompatibilitySuite.scala:32)[0m
[31m  	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)[0m
[31m  	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)[0m
[31m  	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:413)[0m
[31m  	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:401)[0m
[31m  	at scala.collection.immutable.List.foreach(List.scala:318)[0m
[31m  	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)[0m
[31m  	at org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:396)[0m
[31m  	at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:483)[0m
[31m  	at org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:208)[0m
[31m  	at org.scalatest.FunSuite.runTests(FunSuite.scala:1555)[0m
[31m  	at org.scalatest.Suite$class.run(Suite.scala:1424)[0m
[31m  	at org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1555)[0m
[31m  	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)[0m
[31m  	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)[0m
[31m  	at org.scalatest.SuperEngine.runImpl(Engine.scala:545)[0m
[31m  	at org.scalatest.FunSuiteLike$class.run(FunSuiteLike.scala:212)[0m
[31m  	at org.apache.spark.sql.hive.execution.HiveComparisonTest.org$scalatest$BeforeAndAfterAll$$super$run(HiveComparisonTest.scala:44)[0m
[31m  	at org.scalatest.BeforeAndAfterAll$class.liftedTree1$1(BeforeAndAfterAll.scala:257)[0m
[31m  	at org.scalatest.BeforeAndAfterAll$class.run(BeforeAndAfterAll.scala:256)[0m
[31m  	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.org$scalatest$BeforeAndAfter$$super$run(HiveCompatibilitySuite.scala:32)[0m
[31m  	at org.scalatest.BeforeAndAfter$class.run(BeforeAndAfter.scala:241)[0m
[31m  	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.run(HiveCompatibilitySuite.scala:32)[0m
[31m  	at org.scalatest.Suite$class.callExecuteOnSuite$1(Suite.scala:1492)[0m
[31m  	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1528)[0m
[31m  	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1526)[0m
[31m  	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)[0m
[31m  	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)[0m
[31m  	at org.scalatest.Suite$class.runNestedSuites(Suite.scala:1526)[0m
[31m  	at org.scalatest.tools.DiscoverySuite.runNestedSuites(DiscoverySuite.scala:29)[0m
[31m  	at org.scalatest.Suite$class.run(Suite.scala:1421)[0m
[31m  	at org.scalatest.tools.DiscoverySuite.run(DiscoverySuite.scala:29)[0m
[31m  	at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:55)[0m
[31m  	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2563)[0m
[31m  	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2557)[0m
[31m  	at scala.collection.immutable.List.foreach(List.scala:318)[0m
[31m  	at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:2557)[0m
[31m  	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1044)[0m
[31m  	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1043)[0m
[31m  	at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:2722)[0m
[31m  	at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1043)[0m
[31m  	at org.scalatest.tools.Runner$.main(Runner.scala:860)[0m
[31m  	at org.scalatest.tools.Runner.main(Runner.scala)[0m
  
[31m  == Parsed Logical Plan ==[0m
[31m  'Project ['..CITY][0m
[31m   'Filter ('EMPNUM = E5)[0m
[31m    'UnresolvedRelation [HU,STAFF], Some(.)[0m
  
[31m  == Analyzed Logical Plan ==[0m
[31m  org.apache.spark.sql.catalyst.analysis.UnresolvedException: Invalid call to dataType on unresolved object, tree: '..CITY[0m
[31m  'Project ['..CITY][0m
[31m   Filter (EMPNUM#80020 = E5)[0m
[31m    MetastoreRelation hu, staff, Some(.)[0m
  
[31m  == Optimized Logical Plan ==[0m
[31m  org.apache.spark.sql.AnalysisException: cannot resolve '..CITY' given input columns empnum, empname, grade, city;[0m
[31m  == Physical Plan ==[0m
[31m  org.apache.spark.sql.AnalysisException: cannot resolve '..CITY' given input columns empnum, empname, grade, city;[0m
[31m  Code Generation: org.apache.spark.sql.AnalysisException: cannot resolve '..CITY' given input columns empnum, empname, grade, city;[0m
[31m  == HIVE - 0 row(s) == (HiveComparisonTest.scala:366)[0m
Calcite parsing passed, start to transform. SELECT "/".CITY FROM HU.STAFF  "/" WHERE EMPNUM = 'E5'
[32m- 0461[0m
Calcite parsing passed, start to transform. SELECT ":".CITY FROM HU.STAFF  ":" WHERE EMPNUM = 'E5'
[32m- 0462[0m
Calcite parsing passed, start to transform. SELECT "<".CITY FROM HU.STAFF  "<" WHERE EMPNUM = 'E5'
[32m- 0463[0m
Calcite parsing passed, start to transform. SELECT "=".CITY FROM HU.STAFF  "=" WHERE EMPNUM = 'E5'
[32m- 0464[0m
Calcite parsing passed, start to transform. SELECT ">".CITY FROM HU.STAFF  ">" WHERE EMPNUM = 'E5'
[32m- 0465[0m
Calcite parsing passed, start to transform. SELECT "_".CITY FROM HU.STAFF  "_" WHERE EMPNUM = 'E5'
[32m- 0466[0m
Calcite parsing passed, start to transform. SELECT "|".CITY FROM HU.STAFF  "|" WHERE EMPNUM = 'E5'
[32m- 0467[0m
Calcite parsing passed, start to transform. SELECT GRADE AS PROVOLONE, EMPNAME AS EDAM FROM HU.STAFF ORDER BY PROVOLONE, EDAM DESC
Calcite parsing passed, start to transform. SELECT GRADE AS PROVOLONE, EMPNAME AS EDAM FROM HU.STAFF ORDER BY PROVOLONE, EDAM DESC
Calcite parsing passed, start to transform. SELECT GRADE AS PROVOLONE, EMPNAME AS EDAM FROM HU.STAFF ORDER BY PROVOLONE, EDAM DESC
[31m- 0468 *** FAILED ***[0m
[31m  Results do not match for 0468:[0m
[31m  == Parsed Logical Plan ==[0m
[31m  'Sort ['PROVOLONE ASC,'EDAM DESC], true[0m
[31m   'Project ['GRADE AS PROVOLONE#81908,'EMPNAME AS EDAM#81909][0m
[31m    'UnresolvedRelation [HU,STAFF], None[0m
  
[31m  == Analyzed Logical Plan ==[0m
[31m  PROVOLONE: double, EDAM: string[0m
[31m  Sort [PROVOLONE#81908 ASC,EDAM#81909 DESC], true[0m
[31m   Project [GRADE#81912 AS PROVOLONE#81908,EMPNAME#81911 AS EDAM#81909][0m
[31m    MetastoreRelation hu, staff, None[0m
  
[31m  == Optimized Logical Plan ==[0m
[31m  Sort [PROVOLONE#81908 ASC,EDAM#81909 DESC], true[0m
[31m   Project [GRADE#81912 AS PROVOLONE#81908,EMPNAME#81911 AS EDAM#81909][0m
[31m    MetastoreRelation hu, staff, None[0m
  
[31m  == Physical Plan ==[0m
[31m  TungstenSort [PROVOLONE#81908 ASC,EDAM#81909 DESC], true, 0[0m
[31m   ConvertToUnsafe[0m
[31m    Exchange rangepartitioning(PROVOLONE#81908 ASC,EDAM#81909 DESC)[0m
[31m     Project [GRADE#81912 AS PROVOLONE#81908,EMPNAME#81911 AS EDAM#81909][0m
[31m      HiveTableScan [GRADE#81912,EMPNAME#81911], (MetastoreRelation hu, staff, None)[0m
  
[31m  Code Generation: true[0m
[31m  PROVOLONE	EDAM[0m
[31m  !== HIVE - 2 row(s) ==   == CATALYST - 2 row(s) ==[0m
[31m  !0	Fidel                 0.0	Fidel[0m
[31m  !82	ff                   82.0	ff (HiveComparisonTest.scala:433)[0m
Calcite parsing passed, start to transform. SELECT HU.PROJ.CITY AS PCITY, HU.STAFF.CITY SCITY, BUDGET + GRADE * HOURS * 100  REAL_BUDGET FROM HU.STAFF, HU.PROJ, HU.WORKS WHERE HU.WORKS.EMPNUM = HU.STAFF.EMPNUM AND HU.WORKS.PNUM = HU.PROJ.PNUM AND EMPNAME = 'Alice' AND HU.PROJ.PNUM = 'P3'
[31m- 0469 *** FAILED ***[0m
[31m  Failed to execute query using catalyst:[0m
[31m  Error: cannot resolve 'HU.WORKS.EMPNUM' given input columns empnum, city, hours, city, pnum, empname, pname, pnum, empnum, budget, grade, ptype;[0m
[31m  org.apache.spark.sql.AnalysisException: cannot resolve 'HU.WORKS.EMPNUM' given input columns empnum, city, hours, city, pnum, empname, pname, pnum, empnum, budget, grade, ptype;[0m
[31m  	at org.apache.spark.sql.catalyst.analysis.package$AnalysisErrorAt.failAnalysis(package.scala:42)[0m
[31m  	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$apply$2.applyOrElse(CheckAnalysis.scala:56)[0m
[31m  	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$apply$2.applyOrElse(CheckAnalysis.scala:53)[0m
[31m  	at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformUp$1.apply(TreeNode.scala:293)[0m
[31m  	at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformUp$1.apply(TreeNode.scala:293)[0m
[31m  	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:51)[0m
[31m  	at org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:292)[0m
[31m  	at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$5.apply(TreeNode.scala:290)[0m
[31m  	at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$5.apply(TreeNode.scala:290)[0m
[31m  	at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:249)[0m
[31m  	at scala.collection.Iterator$$anon$11.next(Iterator.scala:328)[0m
[31m  	at scala.collection.Iterator$class.foreach(Iterator.scala:727)[0m
[31m  	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)[0m
[31m  	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:48)[0m
[31m  	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:103)[0m
[31m  	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:47)[0m
[31m  	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:273)[0m
[31m  	at scala.collection.AbstractIterator.to(Iterator.scala:1157)[0m
[31m  	at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:265)[0m
[31m  	at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1157)[0m
[31m  	at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:252)[0m
[31m  	at scala.collection.AbstractIterator.toArray(Iterator.scala:1157)[0m
[31m  	at org.apache.spark.sql.catalyst.trees.TreeNode.transformChildren(TreeNode.scala:279)[0m
[31m  	at org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:290)[0m
[31m  	at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$5.apply(TreeNode.scala:290)[0m
[31m  	at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$5.apply(TreeNode.scala:290)[0m
[31m  	at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:249)[0m
[31m  	at scala.collection.Iterator$$anon$11.next(Iterator.scala:328)[0m
[31m  	at scala.collection.Iterator$class.foreach(Iterator.scala:727)[0m
[31m  	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)[0m
[31m  	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:48)[0m
[31m  	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:103)[0m
[31m  	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:47)[0m
[31m  	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:273)[0m
[31m  	at scala.collection.AbstractIterator.to(Iterator.scala:1157)[0m
[31m  	at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:265)[0m
[31m  	at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1157)[0m
[31m  	at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:252)[0m
[31m  	at scala.collection.AbstractIterator.toArray(Iterator.scala:1157)[0m
[31m  	at org.apache.spark.sql.catalyst.trees.TreeNode.transformChildren(TreeNode.scala:279)[0m
[31m  	at org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:290)[0m
[31m  	at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$5.apply(TreeNode.scala:290)[0m
[31m  	at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$5.apply(TreeNode.scala:290)[0m
[31m  	at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:249)[0m
[31m  	at scala.collection.Iterator$$anon$11.next(Iterator.scala:328)[0m
[31m  	at scala.collection.Iterator$class.foreach(Iterator.scala:727)[0m
[31m  	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)[0m
[31m  	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:48)[0m
[31m  	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:103)[0m
[31m  	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:47)[0m
[31m  	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:273)[0m
[31m  	at scala.collection.AbstractIterator.to(Iterator.scala:1157)[0m
[31m  	at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:265)[0m
[31m  	at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1157)[0m
[31m  	at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:252)[0m
[31m  	at scala.collection.AbstractIterator.toArray(Iterator.scala:1157)[0m
[31m  	at org.apache.spark.sql.catalyst.trees.TreeNode.transformChildren(TreeNode.scala:279)[0m
[31m  	at org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:290)[0m
[31m  	at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$5.apply(TreeNode.scala:290)[0m
[31m  	at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$5.apply(TreeNode.scala:290)[0m
[31m  	at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:249)[0m
[31m  	at scala.collection.Iterator$$anon$11.next(Iterator.scala:328)[0m
[31m  	at scala.collection.Iterator$class.foreach(Iterator.scala:727)[0m
[31m  	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)[0m
[31m  	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:48)[0m
[31m  	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:103)[0m
[31m  	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:47)[0m
[31m  	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:273)[0m
[31m  	at scala.collection.AbstractIterator.to(Iterator.scala:1157)[0m
[31m  	at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:265)[0m
[31m  	at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1157)[0m
[31m  	at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:252)[0m
[31m  	at scala.collection.AbstractIterator.toArray(Iterator.scala:1157)[0m
[31m  	at org.apache.spark.sql.catalyst.trees.TreeNode.transformChildren(TreeNode.scala:279)[0m
[31m  	at org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:290)[0m
[31m  	at org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpressionUp$1(QueryPlan.scala:108)[0m
[31m  	at org.apache.spark.sql.catalyst.plans.QueryPlan.org$apache$spark$sql$catalyst$plans$QueryPlan$$recursiveTransform$2(QueryPlan.scala:118)[0m
[31m  	at org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$2.apply(QueryPlan.scala:126)[0m
[31m  	at scala.collection.Iterator$$anon$11.next(Iterator.scala:328)[0m
[31m  	at scala.collection.Iterator$class.foreach(Iterator.scala:727)[0m
[31m  	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)[0m
[31m  	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:48)[0m
[31m  	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:103)[0m
[31m  	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:47)[0m
[31m  	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:273)[0m
[31m  	at scala.collection.AbstractIterator.to(Iterator.scala:1157)[0m
[31m  	at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:265)[0m
[31m  	at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1157)[0m
[31m  	at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:252)[0m
[31m  	at scala.collection.AbstractIterator.toArray(Iterator.scala:1157)[0m
[31m  	at org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpressionsUp(QueryPlan.scala:126)[0m
[31m  	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1.apply(CheckAnalysis.scala:53)[0m
[31m  	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1.apply(CheckAnalysis.scala:49)[0m
[31m  	at org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:103)[0m
[31m  	at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$foreachUp$1.apply(TreeNode.scala:102)[0m
[31m  	at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$foreachUp$1.apply(TreeNode.scala:102)[0m
[31m  	at scala.collection.immutable.List.foreach(List.scala:318)[0m
[31m  	at org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:102)[0m
[31m  	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis$class.checkAnalysis(CheckAnalysis.scala:49)[0m
[31m  	at org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis(Analyzer.scala:44)[0m
[31m  	at org.apache.spark.sql.SQLContext$QueryExecution.assertAnalyzed(SQLContext.scala:908)[0m
[31m  	at org.apache.spark.sql.SQLContext$QueryExecution.withCachedData$lzycompute(SQLContext.scala:912)[0m
[31m  	at org.apache.spark.sql.SQLContext$QueryExecution.withCachedData(SQLContext.scala:911)[0m
[31m  	at org.apache.spark.sql.SQLContext$QueryExecution.optimizedPlan$lzycompute(SQLContext.scala:915)[0m
[31m  	at org.apache.spark.sql.SQLContext$QueryExecution.optimizedPlan(SQLContext.scala:915)[0m
[31m  	at org.apache.spark.sql.SQLContext$QueryExecution.sparkPlan$lzycompute(SQLContext.scala:920)[0m
[31m  	at org.apache.spark.sql.SQLContext$QueryExecution.sparkPlan(SQLContext.scala:918)[0m
[31m  	at org.apache.spark.sql.SQLContext$QueryExecution.executedPlan$lzycompute(SQLContext.scala:924)[0m
[31m  	at org.apache.spark.sql.SQLContext$QueryExecution.executedPlan(SQLContext.scala:924)[0m
[31m  	at org.apache.spark.sql.hive.HiveContext$QueryExecution.stringResult(HiveContext.scala:573)[0m
[31m  	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1$$anonfun$33.apply(HiveComparisonTest.scala:354)[0m
[31m  	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1$$anonfun$33.apply(HiveComparisonTest.scala:352)[0m
[31m  	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)[0m
[31m  	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)[0m
[31m  	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)[0m
[31m  	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)[0m
[31m  	at scala.collection.TraversableLike$class.map(TraversableLike.scala:244)[0m
[31m  	at scala.collection.AbstractTraversable.map(Traversable.scala:105)[0m
[31m  	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1.apply$mcV$sp(HiveComparisonTest.scala:352)[0m
[31m  	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1.apply(HiveComparisonTest.scala:240)[0m
[31m  	at org.apache.spark.sql.hive.execution.HiveComparisonTest$$anonfun$createQueryTest$1.apply(HiveComparisonTest.scala:240)[0m
[31m  	at org.scalatest.Transformer$$anonfun$apply$1.apply$mcV$sp(Transformer.scala:22)[0m
[31m  	at org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)[0m
[31m  	at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)[0m
[31m  	at org.scalatest.Transformer.apply(Transformer.scala:22)[0m
[31m  	at org.scalatest.Transformer.apply(Transformer.scala:20)[0m
[31m  	at org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:166)[0m
[31m  	at org.apache.spark.SparkFunSuite.withFixture(SparkFunSuite.scala:42)[0m
[31m  	at org.scalatest.FunSuiteLike$class.invokeWithFixture$1(FunSuiteLike.scala:163)[0m
[31m  	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)[0m
[31m  	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)[0m
[31m  	at org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)[0m
[31m  	at org.scalatest.FunSuiteLike$class.runTest(FunSuiteLike.scala:175)[0m
[31m  	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.org$scalatest$BeforeAndAfter$$super$runTest(HiveCompatibilitySuite.scala:32)[0m
[31m  	at org.scalatest.BeforeAndAfter$class.runTest(BeforeAndAfter.scala:200)[0m
[31m  	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.runTest(HiveCompatibilitySuite.scala:32)[0m
[31m  	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)[0m
[31m  	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)[0m
[31m  	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:413)[0m
[31m  	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:401)[0m
[31m  	at scala.collection.immutable.List.foreach(List.scala:318)[0m
[31m  	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)[0m
[31m  	at org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:396)[0m
[31m  	at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:483)[0m
[31m  	at org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:208)[0m
[31m  	at org.scalatest.FunSuite.runTests(FunSuite.scala:1555)[0m
[31m  	at org.scalatest.Suite$class.run(Suite.scala:1424)[0m
[31m  	at org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1555)[0m
[31m  	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)[0m
[31m  	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)[0m
[31m  	at org.scalatest.SuperEngine.runImpl(Engine.scala:545)[0m
[31m  	at org.scalatest.FunSuiteLike$class.run(FunSuiteLike.scala:212)[0m
[31m  	at org.apache.spark.sql.hive.execution.HiveComparisonTest.org$scalatest$BeforeAndAfterAll$$super$run(HiveComparisonTest.scala:44)[0m
[31m  	at org.scalatest.BeforeAndAfterAll$class.liftedTree1$1(BeforeAndAfterAll.scala:257)[0m
[31m  	at org.scalatest.BeforeAndAfterAll$class.run(BeforeAndAfterAll.scala:256)[0m
[31m  	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.org$scalatest$BeforeAndAfter$$super$run(HiveCompatibilitySuite.scala:32)[0m
[31m  	at org.scalatest.BeforeAndAfter$class.run(BeforeAndAfter.scala:241)[0m
[31m  	at org.apache.spark.sql.hive.execution.HiveCompatibilitySuite.run(HiveCompatibilitySuite.scala:32)[0m
[31m  	at org.scalatest.Suite$class.callExecuteOnSuite$1(Suite.scala:1492)[0m
[31m  	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1528)[0m
[31m  	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1526)[0m
[31m  	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)[0m
[31m  	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)[0m
[31m  	at org.scalatest.Suite$class.runNestedSuites(Suite.scala:1526)[0m
[31m  	at org.scalatest.tools.DiscoverySuite.runNestedSuites(DiscoverySuite.scala:29)[0m
[31m  	at org.scalatest.Suite$class.run(Suite.scala:1421)[0m
[31m  	at org.scalatest.tools.DiscoverySuite.run(DiscoverySuite.scala:29)[0m
[31m  	at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:55)[0m
[31m  	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2563)[0m
[31m  	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2557)[0m
[31m  	at scala.collection.immutable.List.foreach(List.scala:318)[0m
[31m  	at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:2557)[0m
[31m  	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1044)[0m
[31m  	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1043)[0m
[31m  	at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:2722)[0m
[31m  	at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1043)[0m
[31m  	at org.scalatest.tools.Runner$.main(Runner.scala:860)[0m
[31m  	at org.scalatest.tools.Runner.main(Runner.scala)[0m
  
[31m  == Parsed Logical Plan ==[0m
[31m  'Project ['HU.PROJ.CITY AS PCITY#82514,'HU.STAFF.CITY AS SCITY#82515,('BUDGET + (('GRADE * 'HOURS) * 100)) AS REAL_BUDGET#82516][0m
[31m   'Filter (((('HU.WORKS.EMPNUM = 'HU.STAFF.EMPNUM) && ('HU.WORKS.PNUM = 'HU.PROJ.PNUM)) && ('EMPNAME = Alice)) && ('HU.PROJ.PNUM = P3))[0m
[31m    'Join Inner, None[0m
[31m     'Join Inner, None[0m
[31m      'UnresolvedRelation [HU,STAFF], None[0m
[31m      'UnresolvedRelation [HU,PROJ], None[0m
[31m     'UnresolvedRelation [HU,WORKS], None[0m
  
[31m  == Analyzed Logical Plan ==[0m
[31m  org.apache.spark.sql.catalyst.analysis.UnresolvedException: Invalid call to dataType on unresolved object, tree: 'PCITY[0m
[31m  'Project ['HU.PROJ.CITY AS PCITY#82514,'HU.STAFF.CITY AS SCITY#82515,('BUDGET + (('GRADE * 'HOURS) * 100)) AS REAL_BUDGET#82516][0m
[31m   'Filter (((('HU.WORKS.EMPNUM = 'HU.STAFF.EMPNUM) && ('HU.WORKS.PNUM = 'HU.PROJ.PNUM)) && (EMPNAME#82518 = Alice)) && ('HU.PROJ.PNUM = P3))[0m
[31m    Join Inner, None[0m
[31m     Join Inner, None[0m
[31m      MetastoreRelation hu, staff, None[0m
[31m      MetastoreRelation hu, proj, None[0m
[31m     MetastoreRelation hu, works, None[0m
  
[31m  == Optimized Logical Plan ==[0m
[31m  org.apache.spark.sql.AnalysisException: cannot resolve 'HU.WORKS.EMPNUM' given input columns empnum, city, hours, city, pnum, empname, pname, pnum, empnum, budget, grade, ptype;[0m
[31m  == Physical Plan ==[0m
[31m  org.apache.spark.sql.AnalysisException: cannot resolve 'HU.WORKS.EMPNUM' given input columns empnum, city, hours, city, pnum, empname, pname, pnum, empnum, budget, grade, ptype;[0m
[31m  Code Generation: org.apache.spark.sql.AnalysisException: cannot resolve 'HU.WORKS.EMPNUM' given input columns empnum, city, hours, city, pnum, empname, pname, pnum, empnum, budget, grade, ptype;[0m
[31m  == HIVE - 0 row(s) == (HiveComparisonTest.scala:366)[0m
Calcite parsing passed, start to transform. SELECT T_DECIMAL / .000000001 FROM FOUR_TYPES WHERE T_CHAR = 'X'
Calcite parsing passed, start to transform. SELECT T_DECIMAL / .000000001 FROM FOUR_TYPES WHERE T_CHAR = 'X'
Calcite parsing passed, start to transform. SELECT T_DECIMAL / .000000001 FROM FOUR_TYPES WHERE T_CHAR = 'X'
[31m- 0470 *** FAILED ***[0m
[31m  Results do not match for 0470:[0m
[31m  == Parsed Logical Plan ==[0m
[31m  'Project [('T_DECIMAL / 1E-9) AS c0#82614][0m
[31m   'Filter ('T_CHAR = X)[0m
[31m    'UnresolvedRelation [FOUR_TYPES], None[0m
  
[31m  == Analyzed Logical Plan ==[0m
[31m  c0: double[0m
[31m  Project [(T_DECIMAL#82617 / cast(1E-9 as double)) AS c0#82614][0m
[31m   Filter (T_CHAR#82616 = X)[0m
[31m    MetastoreRelation SCHANZLE, four_types, None[0m
  
[31m  == Optimized Logical Plan ==[0m
[31m  Project [(T_DECIMAL#82617 / 1.0E-9) AS c0#82614][0m
[31m   Filter (T_CHAR#82616 = X)[0m
[31m    MetastoreRelation SCHANZLE, four_types, None[0m
  
[31m  == Physical Plan ==[0m
[31m  Project [(T_DECIMAL#82617 / 1.0E-9) AS c0#82614][0m
[31m   Filter (T_CHAR#82616 = X)[0m
[31m    HiveTableScan [T_DECIMAL#82617,T_CHAR#82616], (MetastoreRelation SCHANZLE, four_types, None)[0m
  
[31m  Code Generation: true[0m
[31m  c0[0m
[31m  !== HIVE - 1 row(s) ==   == CATALYST - 1 row(s) ==[0m
[31m  !11112222000000000       1.1112222E16 (HiveComparisonTest.scala:433)[0m
Calcite parsing passed, start to transform. SELECT SUM(T_REAL) FROM FOUR_TYPES
[32m- 0471[0m
Calcite parsing passed, start to transform. SELECT EMPNUM,EMPNAME FROM HU.STAFF WHERE EMPNUM='E8'
[32m- 0473[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM HU.STAFF4
[32m- 0475[0m
Calcite parsing passed, start to transform. SELECT CHARTEST FROM CUGINI.AA
[32m- 0476[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM CUGINI.AA
[32m- 0477[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM CUGINI.AA WHERE CHARTEST <> 'Twenty Characters...'
[32m- 0478[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM CUGINI.AA
[32m- 0479[0m
Calcite parsing passed, start to transform. SELECT CHARTEST FROM CUGINI.BB
[32m- 0480[0m
Calcite parsing passed, start to transform. SELECT CHARTEST FROM CUGINI.CC
[32m- 0481[0m
Calcite parsing passed, start to transform. SELECT CHARTEST FROM CUGINI.DD
[32m- 0482[0m
Calcite parsing passed, start to transform. SELECT INTTEST FROM CUGINI.EE
Calcite parsing passed, start to transform. SELECT INTTEST FROM CUGINI.EE
Calcite parsing passed, start to transform. SELECT INTTEST FROM CUGINI.EE
[31m- 0483 *** FAILED ***[0m
[31m  Results do not match for 0483:[0m
[31m  == Parsed Logical Plan ==[0m
[31m  'Project ['INTTEST][0m
[31m   'UnresolvedRelation [CUGINI,EE], None[0m
  
[31m  == Analyzed Logical Plan ==[0m
[31m  INTTEST: double[0m
[31m  Project [INTTEST#84132][0m
[31m   MetastoreRelation cugini, ee, None[0m
  
[31m  == Optimized Logical Plan ==[0m
[31m  Project [INTTEST#84132][0m
[31m   MetastoreRelation cugini, ee, None[0m
  
[31m  == Physical Plan ==[0m
[31m  HiveTableScan [INTTEST#84132], (MetastoreRelation cugini, ee, None)[0m
  
[31m  Code Generation: true[0m
[31m  INTTEST[0m
[31m  !== HIVE - 1 row(s) ==   == CATALYST - 1 row(s) ==[0m
[31m  !0                       0.0 (HiveComparisonTest.scala:433)[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM CUGINI.EE
[32m- 0484[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM CUGINI.EE WHERE INTTEST = 1
[32m- 0485[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM CUGINI.EE
[32m- 0486[0m
Calcite parsing passed, start to transform. SELECT INTTEST FROM CUGINI.FF
Calcite parsing passed, start to transform. SELECT INTTEST FROM CUGINI.FF
Calcite parsing passed, start to transform. SELECT INTTEST FROM CUGINI.FF
[31m- 0487 *** FAILED ***[0m
[31m  Results do not match for 0487:[0m
[31m  == Parsed Logical Plan ==[0m
[31m  'Project ['INTTEST][0m
[31m   'UnresolvedRelation [CUGINI,FF], None[0m
  
[31m  == Analyzed Logical Plan ==[0m
[31m  INTTEST: double[0m
[31m  Project [INTTEST#84691][0m
[31m   MetastoreRelation cugini, ff, None[0m
  
[31m  == Optimized Logical Plan ==[0m
[31m  Project [INTTEST#84691][0m
[31m   MetastoreRelation cugini, ff, None[0m
  
[31m  == Physical Plan ==[0m
[31m  HiveTableScan [INTTEST#84691], (MetastoreRelation cugini, ff, None)[0m
  
[31m  Code Generation: true[0m
[31m  INTTEST[0m
[31m  !== HIVE - 1 row(s) ==   == CATALYST - 1 row(s) ==[0m
[31m  !-99                     -99.0 (HiveComparisonTest.scala:433)[0m
Calcite parsing passed, start to transform. SELECT C1 FROM CUGINI.GG
Calcite parsing passed, start to transform. SELECT C1 FROM CUGINI.GG
Calcite parsing passed, start to transform. SELECT C1 FROM CUGINI.GG
[31m- 0488 *** FAILED ***[0m
[31m  Results do not match for 0488:[0m
[31m  == Parsed Logical Plan ==[0m
[31m  'Project ['C1][0m
[31m   'UnresolvedRelation [CUGINI,GG], None[0m
  
[31m  == Analyzed Logical Plan ==[0m
[31m  C1: double[0m
[31m  Project [C1#84914][0m
[31m   MetastoreRelation cugini, gg, None[0m
  
[31m  == Optimized Logical Plan ==[0m
[31m  Project [C1#84914][0m
[31m   MetastoreRelation cugini, gg, None[0m
  
[31m  == Physical Plan ==[0m
[31m  HiveTableScan [C1#84914], (MetastoreRelation cugini, gg, None)[0m
  
[31m  Code Generation: true[0m
[31m  C1[0m
[31m  !== HIVE - 1 row(s) ==   == CATALYST - 1 row(s) ==[0m
[31m  !3                       3.0 (HiveComparisonTest.scala:433)[0m
Calcite parsing passed, start to transform. SELECT SMALLTEST FROM CUGINI.HH
Calcite parsing passed, start to transform. SELECT SMALLTEST FROM CUGINI.HH
Calcite parsing passed, start to transform. SELECT SMALLTEST FROM CUGINI.HH
[31m- 0489 *** FAILED ***[0m
[31m  Results do not match for 0489:[0m
[31m  == Parsed Logical Plan ==[0m
[31m  'Project ['SMALLTEST][0m
[31m   'UnresolvedRelation [CUGINI,HH], None[0m
  
[31m  == Analyzed Logical Plan ==[0m
[31m  SMALLTEST: double[0m
[31m  Project [SMALLTEST#85137][0m
[31m   MetastoreRelation cugini, hh, None[0m
  
[31m  == Optimized Logical Plan ==[0m
[31m  Project [SMALLTEST#85137][0m
[31m   MetastoreRelation cugini, hh, None[0m
  
[31m  == Physical Plan ==[0m
[31m  HiveTableScan [SMALLTEST#85137], (MetastoreRelation cugini, hh, None)[0m
  
[31m  Code Generation: true[0m
[31m  SMALLTEST[0m
[31m  !== HIVE - 1 row(s) ==   == CATALYST - 1 row(s) ==[0m
[31m  !99                      99.0 (HiveComparisonTest.scala:433)[0m
Calcite parsing passed, start to transform. SELECT COL2 FROM CUGINI.VTABLE WHERE COL1 = 0
Calcite parsing passed, start to transform. SELECT COL2 FROM CUGINI.VTABLE WHERE COL1 = 0
Calcite parsing passed, start to transform. SELECT COL2 FROM CUGINI.VTABLE WHERE COL1 = 0
[31m- 0490 *** FAILED ***[0m
[31m  Results do not match for 0490:[0m
[31m  == Parsed Logical Plan ==[0m
[31m  'Project ['COL2][0m
[31m   'Filter ('COL1 = 0)[0m
[31m    'UnresolvedRelation [CUGINI,VTABLE], None[0m
  
[31m  == Analyzed Logical Plan ==[0m
[31m  COL2: double[0m
[31m  Project [COL2#85375][0m
[31m   Filter (COL1#85374 = cast(0 as double))[0m
[31m    MetastoreRelation cugini, vtable, None[0m
  
[31m  == Optimized Logical Plan ==[0m
[31m  Project [COL2#85375][0m
[31m   Filter (COL1#85374 = 0.0)[0m
[31m    MetastoreRelation cugini, vtable, None[0m
  
[31m  == Physical Plan ==[0m
[31m  Project [COL2#85375][0m
[31m   Filter (COL1#85374 = 0.0)[0m
[31m    HiveTableScan [COL2#85375,COL1#85374], (MetastoreRelation cugini, vtable, None)[0m
  
[31m  Code Generation: true[0m
[31m  COL2[0m
[31m  !== HIVE - 1 row(s) ==   == CATALYST - 1 row(s) ==[0m
[31m  !1                       1.0 (HiveComparisonTest.scala:433)[0m
Calcite parsing passed, start to transform. SELECT C1 FROM CUGINI.II
Calcite parsing passed, start to transform. SELECT C1 FROM CUGINI.II
Calcite parsing passed, start to transform. SELECT C1 FROM CUGINI.II
[31m- 0491 *** FAILED ***[0m
[31m  Results do not match for 0491:[0m
[31m  == Parsed Logical Plan ==[0m
[31m  'Project ['C1][0m
[31m   'UnresolvedRelation [CUGINI,II], None[0m
  
[31m  == Analyzed Logical Plan ==[0m
[31m  C1: double[0m
[31m  Project [C1#85639][0m
[31m   MetastoreRelation cugini, ii, None[0m
  
[31m  == Optimized Logical Plan ==[0m
[31m  Project [C1#85639][0m
[31m   MetastoreRelation cugini, ii, None[0m
  
[31m  == Physical Plan ==[0m
[31m  HiveTableScan [C1#85639], (MetastoreRelation cugini, ii, None)[0m
  
[31m  Code Generation: true[0m
[31m  C1[0m
[31m  !== HIVE - 1 row(s) ==   == CATALYST - 1 row(s) ==[0m
[31m  !3                       3.0 (HiveComparisonTest.scala:433)[0m
Calcite parsing passed, start to transform. SELECT C1 FROM CUGINI.JJ
Calcite parsing passed, start to transform. SELECT C1 FROM CUGINI.JJ
Calcite parsing passed, start to transform. SELECT C1 FROM CUGINI.JJ
[31m- 0492 *** FAILED ***[0m
[31m  Results do not match for 0492:[0m
[31m  == Parsed Logical Plan ==[0m
[31m  'Project ['C1][0m
[31m   'UnresolvedRelation [CUGINI,JJ], None[0m
  
[31m  == Analyzed Logical Plan ==[0m
[31m  C1: double[0m
[31m  Project [C1#85878][0m
[31m   MetastoreRelation cugini, jj, None[0m
  
[31m  == Optimized Logical Plan ==[0m
[31m  Project [C1#85878][0m
[31m   MetastoreRelation cugini, jj, None[0m
  
[31m  == Physical Plan ==[0m
[31m  HiveTableScan [C1#85878], (MetastoreRelation cugini, jj, None)[0m
  
[31m  Code Generation: true[0m
[31m  C1[0m
[31m  !== HIVE - 1 row(s) ==   == CATALYST - 1 row(s) ==[0m
[31m  !3                       3.0 (HiveComparisonTest.scala:433)[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM FLATER.VS1
[32m- 0493[0m
Calcite parsing passed, start to transform. SELECT C1, C2 FROM FLATER.VS1 WHERE C2 = 0
Calcite parsing passed, start to transform. SELECT C1, C2 FROM FLATER.VS1 WHERE C2 = 0
Calcite parsing passed, start to transform. SELECT C1, C2 FROM FLATER.VS1 WHERE C2 = 0
[31m- 0494 *** FAILED ***[0m
[31m  Results do not match for 0494:[0m
[31m  == Parsed Logical Plan ==[0m
[31m  'Project ['C1,'C2][0m
[31m   'Filter ('C2 = 0)[0m
[31m    'UnresolvedRelation [FLATER,VS1], None[0m
  
[31m  == Analyzed Logical Plan ==[0m
[31m  C1: double, C2: double[0m
[31m  Project [C1#86242,C2#86243][0m
[31m   Filter (C2#86243 = cast(0 as double))[0m
[31m    MetastoreRelation flater, vs1, None[0m
  
[31m  == Optimized Logical Plan ==[0m
[31m  Project [C1#86242,C2#86243][0m
[31m   Filter (C2#86243 = 0.0)[0m
[31m    MetastoreRelation flater, vs1, None[0m
  
[31m  == Physical Plan ==[0m
[31m  Filter (C2#86243 = 0.0)[0m
[31m   HiveTableScan [C1#86242,C2#86243], (MetastoreRelation flater, vs1, None)[0m
  
[31m  Code Generation: true[0m
[31m  C1	C2[0m
[31m  !== HIVE - 1 row(s) ==   == CATALYST - 1 row(s) ==[0m
[31m  !0	0                     0.0	0.0 (HiveComparisonTest.scala:433)[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM FLATER.VS1
[32m- 0495[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM FLATER.VS1
[32m- 0496[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM FLATER.VS1 WHERE C2 = 1
[32m- 0497[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM FLATER.BASE_VS1
[32m- 0498[0m
Calcite parsing passed, start to transform. SELECT COUNT(*) FROM CUGINI.BADG1
[32m- 0499[0m
[33m- 0500 !!! IGNORED !!![0m
[33m- 0501 !!! IGNORED !!![0m
[33m- 0502 !!! IGNORED !!![0m
[33m- 0503 !!! IGNORED !!![0m
[33m- 0504 !!! IGNORED !!![0m
[33m- 0505 !!! IGNORED !!![0m
[33m- 0506 !!! IGNORED !!![0m
[33m- 0507 !!! IGNORED !!![0m
[33m- 0508 !!! IGNORED !!![0m
[33m- 0509 !!! IGNORED !!![0m
[33m- 0510 !!! IGNORED !!![0m
[33m- 0511 !!! IGNORED !!![0m
[33m- 0512 !!! IGNORED !!![0m
[33m- 0513 !!! IGNORED !!![0m
[33m- 0514 !!! IGNORED !!![0m
[33m- 0515 !!! IGNORED !!![0m
[33m- 0517 !!! IGNORED !!![0m
[33m- 0519 !!! IGNORED !!![0m
[33m- 0521 !!! IGNORED !!![0m
[33m- 0523 !!! IGNORED !!![0m
[33m- 0524 !!! IGNORED !!![0m
[33m- 0525 !!! IGNORED !!![0m
[33m- 0528 !!! IGNORED !!![0m
[33m- 0529 !!! IGNORED !!![0m
[33m- 0530 !!! IGNORED !!![0m
[33m- 0531 !!! IGNORED !!![0m
[33m- 0532 !!! IGNORED !!![0m
[33m- 0534 !!! IGNORED !!![0m
[33m- 0535 !!! IGNORED !!![0m
[33m- 0536 !!! IGNORED !!![0m
[33m- 0537 !!! IGNORED !!![0m
[33m- 0538 !!! IGNORED !!![0m
[33m- 0539 !!! IGNORED !!![0m
[33m- 0540 !!! IGNORED !!![0m
[33m- 0541 !!! IGNORED !!![0m
[33m- 0542 !!! IGNORED !!![0m
[33m- 0543 !!! IGNORED !!![0m
[33m- 0544 !!! IGNORED !!![0m
[33m- 0545 !!! IGNORED !!![0m
[33m- 0546 !!! IGNORED !!![0m
[33m- 0547 !!! IGNORED !!![0m
[33m- 0548 !!! IGNORED !!![0m
[33m- 0549 !!! IGNORED !!![0m
[33m- 0550 !!! IGNORED !!![0m
[33m- 0551 !!! IGNORED !!![0m
[33m- 0552 !!! IGNORED !!![0m
[33m- 0553 !!! IGNORED !!![0m
[33m- 0554 !!! IGNORED !!![0m
[33m- 0555 !!! IGNORED !!![0m
[33m- 0556 !!! IGNORED !!![0m
[33m- 0557 !!! IGNORED !!![0m
[33m- 0558 !!! IGNORED !!![0m
[33m- 0559 !!! IGNORED !!![0m
[33m- 0560 !!! IGNORED !!![0m
[33m- 0561 !!! IGNORED !!![0m
[33m- 0562 !!! IGNORED !!![0m
[33m- 0563 !!! IGNORED !!![0m
[33m- 0564 !!! IGNORED !!![0m
[33m- 0565 !!! IGNORED !!![0m
[33m- 0566 !!! IGNORED !!![0m
[33m- 0567 !!! IGNORED !!![0m
[33m- 0568 !!! IGNORED !!![0m
[33m- 0569 !!! IGNORED !!![0m
[33m- 0570 !!! IGNORED !!![0m
[33m- 0571 !!! IGNORED !!![0m
[33m- 0572 !!! IGNORED !!![0m
[33m- 0573 !!! IGNORED !!![0m
[33m- 0574 !!! IGNORED !!![0m
[33m- 0575 !!! IGNORED !!![0m
[33m- 0576 !!! IGNORED !!![0m
[33m- 0577 !!! IGNORED !!![0m
[33m- 0578 !!! IGNORED !!![0m
[33m- 0579 !!! IGNORED !!![0m
[33m- 0580 !!! IGNORED !!![0m
[33m- 0581 !!! IGNORED !!![0m
[33m- 0582 !!! IGNORED !!![0m
[33m- 0583 !!! IGNORED !!![0m
[33m- 0584 !!! IGNORED !!![0m
[33m- 0585 !!! IGNORED !!![0m
[33m- 0586 !!! IGNORED !!![0m
[33m- 0587 !!! IGNORED !!![0m
[33m- 0588 !!! IGNORED !!![0m
[33m- 0589 !!! IGNORED !!![0m
[33m- 0590 !!! IGNORED !!![0m
[33m- 0591 !!! IGNORED !!![0m
[33m- 0592 !!! IGNORED !!![0m
[33m- 0593 !!! IGNORED !!![0m
[33m- 0594 !!! IGNORED !!![0m
[33m- 0595 !!! IGNORED !!![0m
[33m- 0596 !!! IGNORED !!![0m
[33m- 0597 !!! IGNORED !!![0m
[33m- 0598 !!! IGNORED !!![0m
[33m- 0599 !!! IGNORED !!![0m
[33m- 0600 !!! IGNORED !!![0m
[33m- 0601 !!! IGNORED !!![0m
[33m- 0602 !!! IGNORED !!![0m
[33m- 0603 !!! IGNORED !!![0m
[33m- 0604 !!! IGNORED !!![0m
[33m- 0605 !!! IGNORED !!![0m
[33m- 0606 !!! IGNORED !!![0m
[33m- 0607 !!! IGNORED !!![0m
[33m- 0608 !!! IGNORED !!![0m
[33m- 0609 !!! IGNORED !!![0m
[33m- 0610 !!! IGNORED !!![0m
[33m- 0611 !!! IGNORED !!![0m
[33m- 0612 !!! IGNORED !!![0m
[33m- 0613 !!! IGNORED !!![0m
[33m- 0614 !!! IGNORED !!![0m
[33m- 0615 !!! IGNORED !!![0m
[33m- 0616 !!! IGNORED !!![0m
[33m- 0617 !!! IGNORED !!![0m
[33m- 0618 !!! IGNORED !!![0m
[33m- 0619 !!! IGNORED !!![0m
[33m- 0620 !!! IGNORED !!![0m
[33m- 0621 !!! IGNORED !!![0m
[33m- 0622 !!! IGNORED !!![0m
[33m- 0623 !!! IGNORED !!![0m
[33m- 0624 !!! IGNORED !!![0m
[33m- 0625 !!! IGNORED !!![0m
[33m- 0626 !!! IGNORED !!![0m
[33m- 0627 !!! IGNORED !!![0m
[33m- 0628 !!! IGNORED !!![0m
[33m- 0629 !!! IGNORED !!![0m
[33m- 0630 !!! IGNORED !!![0m
[33m- 0631 !!! IGNORED !!![0m
[33m- 0632 !!! IGNORED !!![0m
[33m- 0633 !!! IGNORED !!![0m
[33m- 0634 !!! IGNORED !!![0m
[33m- 0635 !!! IGNORED !!![0m
[33m- 0636 !!! IGNORED !!![0m
[33m- 0637 !!! IGNORED !!![0m
[33m- 0638 !!! IGNORED !!![0m
[33m- 0639 !!! IGNORED !!![0m
[33m- 0640 !!! IGNORED !!![0m
[33m- 0641 !!! IGNORED !!![0m
[33m- 0642 !!! IGNORED !!![0m
[33m- 0643 !!! IGNORED !!![0m
[33m- 0644 !!! IGNORED !!![0m
[33m- 0645 !!! IGNORED !!![0m
[33m- 0646 !!! IGNORED !!![0m
[33m- 0647 !!! IGNORED !!![0m
[33m- 0648 !!! IGNORED !!![0m
[33m- 0649 !!! IGNORED !!![0m
[33m- 0650 !!! IGNORED !!![0m
[33m- 0651 !!! IGNORED !!![0m
[33m- 0652 !!! IGNORED !!![0m
[33m- 0653 !!! IGNORED !!![0m
[33m- 0654 !!! IGNORED !!![0m
[33m- 0655 !!! IGNORED !!![0m
[33m- 0656 !!! IGNORED !!![0m
[33m- 0657 !!! IGNORED !!![0m
[33m- 0658 !!! IGNORED !!![0m
[33m- 0659 !!! IGNORED !!![0m
[33m- 0660 !!! IGNORED !!![0m
[33m- 0661 !!! IGNORED !!![0m
[33m- 0662 !!! IGNORED !!![0m
[33m- 0663 !!! IGNORED !!![0m
[33m- 0664 !!! IGNORED !!![0m
[33m- 0665 !!! IGNORED !!![0m
[33m- 0666 !!! IGNORED !!![0m
[33m- 0667 !!! IGNORED !!![0m
[33m- 0668 !!! IGNORED !!![0m
[33m- 0669 !!! IGNORED !!![0m
[33m- 0670 !!! IGNORED !!![0m
[33m- 0671 !!! IGNORED !!![0m
[33m- 0672 !!! IGNORED !!![0m
[33m- 0673 !!! IGNORED !!![0m
[33m- 0674 !!! IGNORED !!![0m
[33m- 0675 !!! IGNORED !!![0m
[33m- 0676 !!! IGNORED !!![0m
[33m- 0677 !!! IGNORED !!![0m
[33m- 0678 !!! IGNORED !!![0m
[33m- 0679 !!! IGNORED !!![0m
[33m- 0680 !!! IGNORED !!![0m
[33m- 0681 !!! IGNORED !!![0m
[33m- 0682 !!! IGNORED !!![0m
[33m- 0683 !!! IGNORED !!![0m
[33m- 0684 !!! IGNORED !!![0m
[33m- 0685 !!! IGNORED !!![0m
[33m- 0686 !!! IGNORED !!![0m
[33m- 0687 !!! IGNORED !!![0m
[33m- 0688 !!! IGNORED !!![0m
[33m- 0689 !!! IGNORED !!![0m
[33m- 0690 !!! IGNORED !!![0m
[33m- 0691 !!! IGNORED !!![0m
[33m- 0692 !!! IGNORED !!![0m
[33m- 0693 !!! IGNORED !!![0m
[33m- 0694 !!! IGNORED !!![0m
[33m- 0695 !!! IGNORED !!![0m
[33m- 0696 !!! IGNORED !!![0m
[33m- 0697 !!! IGNORED !!![0m
[33m- 0698 !!! IGNORED !!![0m
[33m- 0699 !!! IGNORED !!![0m
[33m- 0700 !!! IGNORED !!![0m
[33m- 0701 !!! IGNORED !!![0m
[33m- 0702 !!! IGNORED !!![0m
[33m- 0703 !!! IGNORED !!![0m
[33m- 0704 !!! IGNORED !!![0m
[33m- 0705 !!! IGNORED !!![0m
[33m- 0706 !!! IGNORED !!![0m
[33m- 0707 !!! IGNORED !!![0m
[33m- 0708 !!! IGNORED !!![0m
[33m- 0709 !!! IGNORED !!![0m
[33m- 0710 !!! IGNORED !!![0m
[33m- 0711 !!! IGNORED !!![0m
[33m- 0712 !!! IGNORED !!![0m
[33m- 0713 !!! IGNORED !!![0m
[33m- 0714 !!! IGNORED !!![0m
[33m- 0715 !!! IGNORED !!![0m
[33m- 0716 !!! IGNORED !!![0m
[33m- 0717 !!! IGNORED !!![0m
[33m- 0718 !!! IGNORED !!![0m
[33m- 0719 !!! IGNORED !!![0m
[33m- 0720 !!! IGNORED !!![0m
[33m- 0721 !!! IGNORED !!![0m
[33m- 0722 !!! IGNORED !!![0m
[33m- 0723 !!! IGNORED !!![0m
[33m- 0724 !!! IGNORED !!![0m
[33m- 0725 !!! IGNORED !!![0m
[33m- 0726 !!! IGNORED !!![0m
[33m- 0727 !!! IGNORED !!![0m
[33m- 0728 !!! IGNORED !!![0m
[33m- 0729 !!! IGNORED !!![0m
[33m- 0730 !!! IGNORED !!![0m
[33m- 0731 !!! IGNORED !!![0m
[33m- 0732 !!! IGNORED !!![0m
[33m- 0733 !!! IGNORED !!![0m
[33m- 0734 !!! IGNORED !!![0m
[33m- 0735 !!! IGNORED !!![0m
[33m- 0736 !!! IGNORED !!![0m
[33m- 0737 !!! IGNORED !!![0m
[33m- 0738 !!! IGNORED !!![0m
[33m- 0739 !!! IGNORED !!![0m
[33m- 0740 !!! IGNORED !!![0m
[33m- 0741 !!! IGNORED !!![0m
[33m- 0742 !!! IGNORED !!![0m
[33m- 0743 !!! IGNORED !!![0m
[33m- 0744 !!! IGNORED !!![0m
[33m- 0745 !!! IGNORED !!![0m
[33m- 0746 !!! IGNORED !!![0m
[33m- 0747 !!! IGNORED !!![0m
[33m- 0748 !!! IGNORED !!![0m
[33m- 0749 !!! IGNORED !!![0m
[33m- 0750 !!! IGNORED !!![0m
[33m- 0751 !!! IGNORED !!![0m
[33m- 0752 !!! IGNORED !!![0m
[33m- 0753 !!! IGNORED !!![0m
[33m- 0754 !!! IGNORED !!![0m
[33m- 0755 !!! IGNORED !!![0m
[33m- 0756 !!! IGNORED !!![0m
[33m- 0757 !!! IGNORED !!![0m
[33m- 0758 !!! IGNORED !!![0m
[33m- 0759 !!! IGNORED !!![0m
[33m- 0760 !!! IGNORED !!![0m
[33m- 0761 !!! IGNORED !!![0m
[33m- 0762 !!! IGNORED !!![0m
[33m- 0763 !!! IGNORED !!![0m
[33m- 0764 !!! IGNORED !!![0m
[33m- 0765 !!! IGNORED !!![0m
[33m- 0766 !!! IGNORED !!![0m
[33m- 0767 !!! IGNORED !!![0m
[33m- 0768 !!! IGNORED !!![0m
[33m- 0769 !!! IGNORED !!![0m
[33m- 0770 !!! IGNORED !!![0m
[33m- 0771 !!! IGNORED !!![0m
[33m- 0772 !!! IGNORED !!![0m
[33m- 0773 !!! IGNORED !!![0m
[33m- 0774 !!! IGNORED !!![0m
[33m- 0775 !!! IGNORED !!![0m
[33m- 0776 !!! IGNORED !!![0m
[33m- 0777 !!! IGNORED !!![0m
[33m- 0778 !!! IGNORED !!![0m
[33m- 0779 !!! IGNORED !!![0m
[33m- 0780 !!! IGNORED !!![0m
[33m- 0781 !!! IGNORED !!![0m
[33m- 0782 !!! IGNORED !!![0m
[33m- 0784 !!! IGNORED !!![0m
[33m- 0785 !!! IGNORED !!![0m
[33m- 0786 !!! IGNORED !!![0m
[33m- 0787 !!! IGNORED !!![0m
[33m- 0788 !!! IGNORED !!![0m
[33m- 0789 !!! IGNORED !!![0m
[33m- 0790 !!! IGNORED !!![0m
[33m- 0791 !!! IGNORED !!![0m
[33m- 0792 !!! IGNORED !!![0m
[33m- 0793 !!! IGNORED !!![0m
[33m- 0794 !!! IGNORED !!![0m
[33m- 0795 !!! IGNORED !!![0m
[33m- 0796 !!! IGNORED !!![0m
[33m- 0797 !!! IGNORED !!![0m
[33m- 0798 !!! IGNORED !!![0m
[33m- 0799 !!! IGNORED !!![0m
[33m- 0800 !!! IGNORED !!![0m
[33m- 0801 !!! IGNORED !!![0m
[33m- 0802 !!! IGNORED !!![0m
[33m- 0803 !!! IGNORED !!![0m
[33m- 0804 !!! IGNORED !!![0m
[33m- 0805 !!! IGNORED !!![0m
[33m- 0806 !!! IGNORED !!![0m
[33m- 0807 !!! IGNORED !!![0m
[33m- 0808 !!! IGNORED !!![0m
[33m- 0809 !!! IGNORED !!![0m
[33m- 0810 !!! IGNORED !!![0m
[33m- 0811 !!! IGNORED !!![0m
[33m- 0812 !!! IGNORED !!![0m
[33m- 0813 !!! IGNORED !!![0m
[33m- 0815 !!! IGNORED !!![0m
[33m- 0816 !!! IGNORED !!![0m
[33m- 0817 !!! IGNORED !!![0m
[33m- 0818 !!! IGNORED !!![0m
[33m- 0819 !!! IGNORED !!![0m
[33m- 0820 !!! IGNORED !!![0m
[33m- 0821 !!! IGNORED !!![0m
[33m- 0822 !!! IGNORED !!![0m
[33m- 0823 !!! IGNORED !!![0m
[33m- 0824 !!! IGNORED !!![0m
[33m- 0825 !!! IGNORED !!![0m
[33m- 0826 !!! IGNORED !!![0m
[33m- 0827 !!! IGNORED !!![0m
[33m- 0828 !!! IGNORED !!![0m
[33m- 0829 !!! IGNORED !!![0m
[33m- 0830 !!! IGNORED !!![0m
[33m- 0831 !!! IGNORED !!![0m
[33m- 0832 !!! IGNORED !!![0m
[33m- 0833 !!! IGNORED !!![0m
[33m- 0834 !!! IGNORED !!![0m
[33m- 0835 !!! IGNORED !!![0m
[33m- 0836 !!! IGNORED !!![0m
[33m- 0837 !!! IGNORED !!![0m
[33m- 0838 !!! IGNORED !!![0m
[33m- 0839 !!! IGNORED !!![0m
[33m- 0840 !!! IGNORED !!![0m
[33m- 0841 !!! IGNORED !!![0m
[33m- 0842 !!! IGNORED !!![0m
[33m- 0843 !!! IGNORED !!![0m
[33m- 0844 !!! IGNORED !!![0m
[33m- 0845 !!! IGNORED !!![0m
[33m- 0846 !!! IGNORED !!![0m
[33m- 0847 !!! IGNORED !!![0m
[33m- 0848 !!! IGNORED !!![0m
[33m- 0849 !!! IGNORED !!![0m
[33m- 0850 !!! IGNORED !!![0m
[33m- 0851 !!! IGNORED !!![0m
[33m- 0852 !!! IGNORED !!![0m
[33m- 0853 !!! IGNORED !!![0m
[33m- 0854 !!! IGNORED !!![0m
[33m- 0855 !!! IGNORED !!![0m
[33m- 0856 !!! IGNORED !!![0m
[33m- 0857 !!! IGNORED !!![0m
[33m- 0858 !!! IGNORED !!![0m
[33m- 0859 !!! IGNORED !!![0m
[33m- 0860 !!! IGNORED !!![0m
[33m- 0861 !!! IGNORED !!![0m
[33m- 0862 !!! IGNORED !!![0m
[33m- 0863 !!! IGNORED !!![0m
[33m- 0864 !!! IGNORED !!![0m
[33m- 0865 !!! IGNORED !!![0m
[33m- 0866 !!! IGNORED !!![0m
[33m- 0867 !!! IGNORED !!![0m
[33m- 0868 !!! IGNORED !!![0m
[33m- 0869 !!! IGNORED !!![0m
[33m- 0871 !!! IGNORED !!![0m
[33m- 0872 !!! IGNORED !!![0m
[33m- 0873 !!! IGNORED !!![0m
[33m- 0874 !!! IGNORED !!![0m
[33m- 0875 !!! IGNORED !!![0m
[33m- 0876 !!! IGNORED !!![0m
[33m- 0877 !!! IGNORED !!![0m
[33m- 0878 !!! IGNORED !!![0m
[33m- 0879 !!! IGNORED !!![0m
[33m- 0880 !!! IGNORED !!![0m
[33m- 0881 !!! IGNORED !!![0m
[33m- 0882 !!! IGNORED !!![0m
[33m- 0883 !!! IGNORED !!![0m
[33m- 0884 !!! IGNORED !!![0m
[33m- 0885 !!! IGNORED !!![0m
[33m- 0886 !!! IGNORED !!![0m
[33m- 0887 !!! IGNORED !!![0m
[33m- 0888 !!! IGNORED !!![0m
[33m- 0889 !!! IGNORED !!![0m
[33m- 0890 !!! IGNORED !!![0m
[33m- 0891 !!! IGNORED !!![0m
[33m- 0892 !!! IGNORED !!![0m
[33m- 0893 !!! IGNORED !!![0m
[33m- 0894 !!! IGNORED !!![0m
[33m- 0895 !!! IGNORED !!![0m
[33m- 0896 !!! IGNORED !!![0m
[33m- 0897 !!! IGNORED !!![0m
[33m- 0898 !!! IGNORED !!![0m
[33m- 0899 !!! IGNORED !!![0m
[33m- 0900 !!! IGNORED !!![0m
[33m- 0901 !!! IGNORED !!![0m
[33m- 0902 !!! IGNORED !!![0m
[33m- 0903 !!! IGNORED !!![0m
[33m- 0904 !!! IGNORED !!![0m
[33m- 0905 !!! IGNORED !!![0m
[33m- 0906 !!! IGNORED !!![0m
[33m- 0912 !!! IGNORED !!![0m
[33m- 0913 !!! IGNORED !!![0m
[33m- 0914 !!! IGNORED !!![0m
[33m- 0915 !!! IGNORED !!![0m
[33m- 0916 !!! IGNORED !!![0m
[33m- 0917 !!! IGNORED !!![0m
[33m- 0918 !!! IGNORED !!![0m
[33m- 0919 !!! IGNORED !!![0m
[33m- 0920 !!! IGNORED !!![0m
[33m- 0921 !!! IGNORED !!![0m
[33m- 0922 !!! IGNORED !!![0m
[33m- 0923 !!! IGNORED !!![0m
[33m- 0924 !!! IGNORED !!![0m
[33m- 0925 !!! IGNORED !!![0m
[33m- 0926 !!! IGNORED !!![0m
[33m- 0927 !!! IGNORED !!![0m
[33m- 0928 !!! IGNORED !!![0m
[33m- 0929 !!! IGNORED !!![0m
[33m- 0930 !!! IGNORED !!![0m
[33m- 0931 !!! IGNORED !!![0m
[33m- 0932 !!! IGNORED !!![0m
[33m- 0933 !!! IGNORED !!![0m
[33m- 0934 !!! IGNORED !!![0m
[33m- 0935 !!! IGNORED !!![0m
[33m- 0936 !!! IGNORED !!![0m
[33m- 0937 !!! IGNORED !!![0m
[33m- 0938 !!! IGNORED !!![0m
[33m- 0939 !!! IGNORED !!![0m
[33m- 0940 !!! IGNORED !!![0m
[33m- 0941 !!! IGNORED !!![0m
[33m- 0942 !!! IGNORED !!![0m
[33m- 0943 !!! IGNORED !!![0m
[33m- 0944 !!! IGNORED !!![0m
[33m- 0945 !!! IGNORED !!![0m
[33m- 0946 !!! IGNORED !!![0m
[33m- 0947 !!! IGNORED !!![0m
[33m- 0948 !!! IGNORED !!![0m
[33m- 0949 !!! IGNORED !!![0m
[33m- 0950 !!! IGNORED !!![0m
[33m- 0951 !!! IGNORED !!![0m
[33m- 0952 !!! IGNORED !!![0m
[33m- 0953 !!! IGNORED !!![0m
[33m- 0954 !!! IGNORED !!![0m
[33m- 0955 !!! IGNORED !!![0m
[33m- 0956 !!! IGNORED !!![0m
[33m- 0957 !!! IGNORED !!![0m
[33m- 0958 !!! IGNORED !!![0m
[33m- 0959 !!! IGNORED !!![0m
[33m- 0960 !!! IGNORED !!![0m
[33m- 0961 !!! IGNORED !!![0m
[33m- 0962 !!! IGNORED !!![0m
[33m- 0963 !!! IGNORED !!![0m
[33m- 0964 !!! IGNORED !!![0m
[33m- 0965 !!! IGNORED !!![0m
[33m- 0966 !!! IGNORED !!![0m
[33m- 0967 !!! IGNORED !!![0m
[33m- 0968 !!! IGNORED !!![0m
[33m- 0969 !!! IGNORED !!![0m
[33m- 0970 !!! IGNORED !!![0m
[33m- 0971 !!! IGNORED !!![0m
[33m- 0972 !!! IGNORED !!![0m
[33m- 0973 !!! IGNORED !!![0m
[33m- 0974 !!! IGNORED !!![0m
[33m- 0975 !!! IGNORED !!![0m
[33m- 0976 !!! IGNORED !!![0m
[33m- 0977 !!! IGNORED !!![0m
[33m- 0978 !!! IGNORED !!![0m
[33m- 0979 !!! IGNORED !!![0m
[33m- 0980 !!! IGNORED !!![0m
[33m- 0981 !!! IGNORED !!![0m
[33m- 0982 !!! IGNORED !!![0m
[33m- 0983 !!! IGNORED !!![0m
[33m- 0984 !!! IGNORED !!![0m
[33m- 0985 !!! IGNORED !!![0m
[33m- 0986 !!! IGNORED !!![0m
[33m- 0987 !!! IGNORED !!![0m
[33m- 0988 !!! IGNORED !!![0m
[33m- 0989 !!! IGNORED !!![0m
[33m- 0990 !!! IGNORED !!![0m
[33m- 0991 !!! IGNORED !!![0m
[33m- 0992 !!! IGNORED !!![0m
[33m- 0993 !!! IGNORED !!![0m
[33m- 0994 !!! IGNORED !!![0m
[33m- 0995 !!! IGNORED !!![0m
[33m- 0996 !!! IGNORED !!![0m
[33m- 0997 !!! IGNORED !!![0m
[33m- 0998 !!! IGNORED !!![0m
[33m- 0999 !!! IGNORED !!![0m
[33m- 1001 !!! IGNORED !!![0m
[33m- 1003 !!! IGNORED !!![0m
[33m- 1004 !!! IGNORED !!![0m
[33m- 1005 !!! IGNORED !!![0m
[33m- 1006 !!! IGNORED !!![0m
[33m- 1007 !!! IGNORED !!![0m
[33m- 1008 !!! IGNORED !!![0m
[33m- 1009 !!! IGNORED !!![0m
[33m- 1010 !!! IGNORED !!![0m
[33m- 1011 !!! IGNORED !!![0m
[33m- 1012 !!! IGNORED !!![0m
[33m- 1013 !!! IGNORED !!![0m
[33m- 1014 !!! IGNORED !!![0m
[33m- 1015 !!! IGNORED !!![0m
[33m- 1016 !!! IGNORED !!![0m
[33m- 1017 !!! IGNORED !!![0m
[33m- 1018 !!! IGNORED !!![0m
[33m- 1019 !!! IGNORED !!![0m
[33m- 1020 !!! IGNORED !!![0m
[33m- 1021 !!! IGNORED !!![0m
[33m- 1022 !!! IGNORED !!![0m
[33m- 1023 !!! IGNORED !!![0m
[33m- 1024 !!! IGNORED !!![0m
[33m- 1025 !!! IGNORED !!![0m
[33m- 1026 !!! IGNORED !!![0m
[33m- 1027 !!! IGNORED !!![0m
[33m- 1028 !!! IGNORED !!![0m
[33m- 1029 !!! IGNORED !!![0m
[33m- 1030 !!! IGNORED !!![0m
[33m- 1031 !!! IGNORED !!![0m
[33m- 1032 !!! IGNORED !!![0m
[33m- 1033 !!! IGNORED !!![0m
[33m- 1034 !!! IGNORED !!![0m
[33m- 1035 !!! IGNORED !!![0m
[33m- 1036 !!! IGNORED !!![0m
[33m- 1037 !!! IGNORED !!![0m
[33m- 1038 !!! IGNORED !!![0m
[33m- 1039 !!! IGNORED !!![0m
[33m- 1051 !!! IGNORED !!![0m
[33m- 1052 !!! IGNORED !!![0m
[33m- 1053 !!! IGNORED !!![0m
[33m- 1054 !!! IGNORED !!![0m
[33m- 1055 !!! IGNORED !!![0m
[33m- 1056 !!! IGNORED !!![0m
[33m- 1057 !!! IGNORED !!![0m
[33m- 1058 !!! IGNORED !!![0m
[33m- 1059 !!! IGNORED !!![0m
[33m- 1060 !!! IGNORED !!![0m
[33m- 1061 !!! IGNORED !!![0m
[33m- 1062 !!! IGNORED !!![0m
[33m- 1063 !!! IGNORED !!![0m
[33m- 1064 !!! IGNORED !!![0m
[33m- 1065 !!! IGNORED !!![0m
[33m- 1066 !!! IGNORED !!![0m
[33m- 1067 !!! IGNORED !!![0m
[33m- 1068 !!! IGNORED !!![0m
[33m- 1069 !!! IGNORED !!![0m
[33m- 1070 !!! IGNORED !!![0m
[33m- 1071 !!! IGNORED !!![0m
[33m- 1072 !!! IGNORED !!![0m
[33m- 2030 !!! IGNORED !!![0m
[33m- 2031 !!! IGNORED !!![0m
[33m- 2032 !!! IGNORED !!![0m
[33m- 2033 !!! IGNORED !!![0m
[33m- 2034 !!! IGNORED !!![0m
[33m- 2035 !!! IGNORED !!![0m
[33m- 2036 !!! IGNORED !!![0m
[33m- 2037 !!! IGNORED !!![0m
[33m- 2038 !!! IGNORED !!![0m
[33m- 2039 !!! IGNORED !!![0m
[33m- 5000 !!! IGNORED !!![0m
[33m- 5001 !!! IGNORED !!![0m
[33m- 5002 !!! IGNORED !!![0m
[33m- 5003 !!! IGNORED !!![0m
[33m- 5004 !!! IGNORED !!![0m
[33m- 5005 !!! IGNORED !!![0m
[33m- 5006 !!! IGNORED !!![0m
[33m- 5007 !!! IGNORED !!![0m
[33m- 5008 !!! IGNORED !!![0m
[33m- 5009 !!! IGNORED !!![0m
[33m- 5010 !!! IGNORED !!![0m
[33m- 5011 !!! IGNORED !!![0m
[33m- 5012 !!! IGNORED !!![0m
[33m- 5013 !!! IGNORED !!![0m
[33m- 5014 !!! IGNORED !!![0m
[33m- 5015 !!! IGNORED !!![0m
[33m- 5016 !!! IGNORED !!![0m
[33m- 5017 !!! IGNORED !!![0m
[33m- 5018 !!! IGNORED !!![0m
[33m- 5019 !!! IGNORED !!![0m
[33m- 5020 !!! IGNORED !!![0m
[33m- 5021 !!! IGNORED !!![0m
[33m- 5022 !!! IGNORED !!![0m
[33m- 5023 !!! IGNORED !!![0m
[33m- 5024 !!! IGNORED !!![0m
[33m- 5025 !!! IGNORED !!![0m
[33m- 5026 !!! IGNORED !!![0m
[33m- 5027 !!! IGNORED !!![0m
[33m- 5028 !!! IGNORED !!![0m
[33m- 5029 !!! IGNORED !!![0m
[33m- 5030 !!! IGNORED !!![0m
[33m- 5031 !!! IGNORED !!![0m
[33m- 5032 !!! IGNORED !!![0m
[33m- 5033 !!! IGNORED !!![0m
[33m- 5034 !!! IGNORED !!![0m
[33m- 5035 !!! IGNORED !!![0m
[33m- 5036 !!! IGNORED !!![0m
[33m- 5037 !!! IGNORED !!![0m
[33m- 5038 !!! IGNORED !!![0m
[33m- 5039 !!! IGNORED !!![0m
[33m- 5040 !!! IGNORED !!![0m
[33m- 5041 !!! IGNORED !!![0m
[33m- 5042 !!! IGNORED !!![0m
[33m- 5043 !!! IGNORED !!![0m
[33m- 5044 !!! IGNORED !!![0m
[33m- 5045 !!! IGNORED !!![0m
[33m- 5046 !!! IGNORED !!![0m
[33m- 5047 !!! IGNORED !!![0m
[33m- 5048 !!! IGNORED !!![0m
[33m- 5049 !!! IGNORED !!![0m
[33m- 5050 !!! IGNORED !!![0m
[33m- 5051 !!! IGNORED !!![0m
[33m- 5052 !!! IGNORED !!![0m
[33m- 5053 !!! IGNORED !!![0m
[33m- 5054 !!! IGNORED !!![0m
[33m- 5055 !!! IGNORED !!![0m
[33m- 5056 !!! IGNORED !!![0m
[33m- 5057 !!! IGNORED !!![0m
[33m- 5058 !!! IGNORED !!![0m
[33m- 5059 !!! IGNORED !!![0m
[33m- 5060 !!! IGNORED !!![0m
[33m- 5061 !!! IGNORED !!![0m
[33m- 5062 !!! IGNORED !!![0m
[33m- 5063 !!! IGNORED !!![0m
[33m- 5064 !!! IGNORED !!![0m
[33m- 5065 !!! IGNORED !!![0m
[33m- 5066 !!! IGNORED !!![0m
[33m- 5067 !!! IGNORED !!![0m
[33m- 5068 !!! IGNORED !!![0m
[33m- 5069 !!! IGNORED !!![0m
[33m- 5070 !!! IGNORED !!![0m
[33m- 5071 !!! IGNORED !!![0m
[33m- 5072 !!! IGNORED !!![0m
[33m- 5073 !!! IGNORED !!![0m
[33m- 5074 !!! IGNORED !!![0m
[33m- 5075 !!! IGNORED !!![0m
[33m- 5076 !!! IGNORED !!![0m
[33m- 5077 !!! IGNORED !!![0m
[33m- 5078 !!! IGNORED !!![0m
[33m- 5079 !!! IGNORED !!![0m
[33m- 5080 !!! IGNORED !!![0m
[33m- 5081 !!! IGNORED !!![0m
[33m- 5082 !!! IGNORED !!![0m
[33m- 5083 !!! IGNORED !!![0m
[33m- 5084 !!! IGNORED !!![0m
[33m- 5085 !!! IGNORED !!![0m
[33m- 5086 !!! IGNORED !!![0m
[33m- 5087 !!! IGNORED !!![0m
[33m- 5088 !!! IGNORED !!![0m
[33m- 5089 !!! IGNORED !!![0m
[33m- 5090 !!! IGNORED !!![0m
[33m- 5091 !!! IGNORED !!![0m
[33m- 5092 !!! IGNORED !!![0m
[33m- 5093 !!! IGNORED !!![0m
[33m- 5094 !!! IGNORED !!![0m
[33m- 5095 !!! IGNORED !!![0m
[33m- 5096 !!! IGNORED !!![0m
[33m- 5097 !!! IGNORED !!![0m
[33m- 5098 !!! IGNORED !!![0m
[33m- 5099 !!! IGNORED !!![0m
[33m- 5100 !!! IGNORED !!![0m
[33m- 5101 !!! IGNORED !!![0m
[33m- 5102 !!! IGNORED !!![0m
[33m- 5103 !!! IGNORED !!![0m
[33m- 5104 !!! IGNORED !!![0m
[33m- 5105 !!! IGNORED !!![0m
[33m- 5106 !!! IGNORED !!![0m
[33m- 5107 !!! IGNORED !!![0m
[33m- 5108 !!! IGNORED !!![0m
[33m- 5109 !!! IGNORED !!![0m
[33m- 5110 !!! IGNORED !!![0m
[33m- 5111 !!! IGNORED !!![0m
[33m- 5112 !!! IGNORED !!![0m
[33m- 5113 !!! IGNORED !!![0m
[33m- 5114 !!! IGNORED !!![0m
[33m- 5115 !!! IGNORED !!![0m
[33m- 5116 !!! IGNORED !!![0m
[33m- 5117 !!! IGNORED !!![0m
[33m- 5118 !!! IGNORED !!![0m
[33m- 5119 !!! IGNORED !!![0m
[33m- 5120 !!! IGNORED !!![0m
[33m- 5121 !!! IGNORED !!![0m
[33m- 5122 !!! IGNORED !!![0m
[33m- 5123 !!! IGNORED !!![0m
[33m- 5124 !!! IGNORED !!![0m
[33m- 5125 !!! IGNORED !!![0m
[33m- 5126 !!! IGNORED !!![0m
[33m- 5127 !!! IGNORED !!![0m
[33m- 5128 !!! IGNORED !!![0m
[33m- 5129 !!! IGNORED !!![0m
[33m- 5130 !!! IGNORED !!![0m
[33m- 5131 !!! IGNORED !!![0m
[33m- 5132 !!! IGNORED !!![0m
[33m- 5133 !!! IGNORED !!![0m
[33m- 5134 !!! IGNORED !!![0m
[33m- 5135 !!! IGNORED !!![0m
[33m- 5136 !!! IGNORED !!![0m
[33m- 5137 !!! IGNORED !!![0m
[33m- 5138 !!! IGNORED !!![0m
[33m- 5139 !!! IGNORED !!![0m
[33m- 5140 !!! IGNORED !!![0m
[33m- 5141 !!! IGNORED !!![0m
[33m- 5142 !!! IGNORED !!![0m
[33m- 5143 !!! IGNORED !!![0m
[33m- 5144 !!! IGNORED !!![0m
[33m- 5145 !!! IGNORED !!![0m
[33m- 5146 !!! IGNORED !!![0m
[33m- 5147 !!! IGNORED !!![0m
[33m- 5148 !!! IGNORED !!![0m
[33m- 5149 !!! IGNORED !!![0m
[33m- 5150 !!! IGNORED !!![0m
[33m- 5151 !!! IGNORED !!![0m
[33m- 5152 !!! IGNORED !!![0m
[33m- 5153 !!! IGNORED !!![0m
[33m- 5154 !!! IGNORED !!![0m
[33m- 5155 !!! IGNORED !!![0m
[33m- 5156 !!! IGNORED !!![0m
[33m- 5157 !!! IGNORED !!![0m
[33m- 5158 !!! IGNORED !!![0m
[33m- 5159 !!! IGNORED !!![0m
[33m- 5160 !!! IGNORED !!![0m
[33m- 5161 !!! IGNORED !!![0m
[33m- 5162 !!! IGNORED !!![0m
[33m- 5163 !!! IGNORED !!![0m
[33m- 5164 !!! IGNORED !!![0m
[33m- 5165 !!! IGNORED !!![0m
[33m- 5166 !!! IGNORED !!![0m
[33m- 5167 !!! IGNORED !!![0m
[33m- 5168 !!! IGNORED !!![0m
[33m- 5169 !!! IGNORED !!![0m
[33m- 5170 !!! IGNORED !!![0m
[33m- 5171 !!! IGNORED !!![0m
[33m- 5172 !!! IGNORED !!![0m
[33m- 5173 !!! IGNORED !!![0m
[33m- 5174 !!! IGNORED !!![0m
[33m- 5175 !!! IGNORED !!![0m
[33m- 5176 !!! IGNORED !!![0m
[33m- 5177 !!! IGNORED !!![0m
[33m- 5178 !!! IGNORED !!![0m
[33m- 5179 !!! IGNORED !!![0m
[33m- 5180 !!! IGNORED !!![0m
[33m- 5181 !!! IGNORED !!![0m
[33m- 5182 !!! IGNORED !!![0m
[33m- 5183 !!! IGNORED !!![0m
[33m- 5184 !!! IGNORED !!![0m
[33m- 5185 !!! IGNORED !!![0m
[33m- 5186 !!! IGNORED !!![0m
[33m- 5187 !!! IGNORED !!![0m
[33m- 5188 !!! IGNORED !!![0m
[33m- 5189 !!! IGNORED !!![0m
[33m- 5190 !!! IGNORED !!![0m
[33m- 5191 !!! IGNORED !!![0m
[33m- 5192 !!! IGNORED !!![0m
[33m- 5193 !!! IGNORED !!![0m
[33m- 5194 !!! IGNORED !!![0m
[33m- 5195 !!! IGNORED !!![0m
[33m- 5196 !!! IGNORED !!![0m
[33m- 5197 !!! IGNORED !!![0m
[33m- 5198 !!! IGNORED !!![0m
[33m- 5199 !!! IGNORED !!![0m
[33m- 5200 !!! IGNORED !!![0m
[33m- 5201 !!! IGNORED !!![0m
[33m- 5202 !!! IGNORED !!![0m
[33m- 5203 !!! IGNORED !!![0m
[33m- 5204 !!! IGNORED !!![0m
[33m- 5205 !!! IGNORED !!![0m
[33m- 5206 !!! IGNORED !!![0m
[33m- 5207 !!! IGNORED !!![0m
[33m- 5208 !!! IGNORED !!![0m
[33m- 5209 !!! IGNORED !!![0m
[33m- 5210 !!! IGNORED !!![0m
[33m- 5211 !!! IGNORED !!![0m
[33m- 5212 !!! IGNORED !!![0m
[33m- 5213 !!! IGNORED !!![0m
[33m- 5214 !!! IGNORED !!![0m
[33m- 5215 !!! IGNORED !!![0m
[33m- 5216 !!! IGNORED !!![0m
[33m- 5217 !!! IGNORED !!![0m
[33m- 5218 !!! IGNORED !!![0m
[33m- 5219 !!! IGNORED !!![0m
[33m- 5220 !!! IGNORED !!![0m
[33m- 5221 !!! IGNORED !!![0m
[33m- 5222 !!! IGNORED !!![0m
[33m- 5223 !!! IGNORED !!![0m
[33m- 5224 !!! IGNORED !!![0m
[33m- 5225 !!! IGNORED !!![0m
[33m- 5226 !!! IGNORED !!![0m
[33m- 5227 !!! IGNORED !!![0m
[33m- 5228 !!! IGNORED !!![0m
[33m- 5229 !!! IGNORED !!![0m
[33m- 5230 !!! IGNORED !!![0m
[33m- 5231 !!! IGNORED !!![0m
[33m- 5232 !!! IGNORED !!![0m
[33m- 5233 !!! IGNORED !!![0m
[33m- 5234 !!! IGNORED !!![0m
[33m- 5235 !!! IGNORED !!![0m
[33m- 5236 !!! IGNORED !!![0m
[33m- 5237 !!! IGNORED !!![0m
[33m- 5238 !!! IGNORED !!![0m
[33m- 5239 !!! IGNORED !!![0m
[33m- 5240 !!! IGNORED !!![0m
[33m- 5241 !!! IGNORED !!![0m
[33m- 5242 !!! IGNORED !!![0m
[33m- 5243 !!! IGNORED !!![0m
[33m- 5244 !!! IGNORED !!![0m
[33m- 5245 !!! IGNORED !!![0m
[33m- 5246 !!! IGNORED !!![0m
[33m- 5247 !!! IGNORED !!![0m
[33m- 5248 !!! IGNORED !!![0m
[33m- 5249 !!! IGNORED !!![0m
[33m- 5250 !!! IGNORED !!![0m
[33m- 5251 !!! IGNORED !!![0m
[33m- 5252 !!! IGNORED !!![0m
[33m- 5253 !!! IGNORED !!![0m
[33m- 5254 !!! IGNORED !!![0m
[33m- 5255 !!! IGNORED !!![0m
[33m- 5256 !!! IGNORED !!![0m
[33m- 5257 !!! IGNORED !!![0m
[33m- 5258 !!! IGNORED !!![0m
[33m- 5259 !!! IGNORED !!![0m
[33m- 5260 !!! IGNORED !!![0m
[33m- 5261 !!! IGNORED !!![0m
[33m- 5262 !!! IGNORED !!![0m
[33m- 5263 !!! IGNORED !!![0m
[33m- 5264 !!! IGNORED !!![0m
[33m- 5265 !!! IGNORED !!![0m
[33m- 5266 !!! IGNORED !!![0m
[33m- 5267 !!! IGNORED !!![0m
[33m- 5268 !!! IGNORED !!![0m
[33m- 5269 !!! IGNORED !!![0m
[33m- 5270 !!! IGNORED !!![0m
[33m- 5271 !!! IGNORED !!![0m
[33m- 5272 !!! IGNORED !!![0m
[33m- 5273 !!! IGNORED !!![0m
[33m- 5274 !!! IGNORED !!![0m
[33m- 5275 !!! IGNORED !!![0m
[33m- 5276 !!! IGNORED !!![0m
[33m- 5277 !!! IGNORED !!![0m
[33m- 5278 !!! IGNORED !!![0m
[33m- 5279 !!! IGNORED !!![0m
[33m- 5280 !!! IGNORED !!![0m
[33m- 5281 !!! IGNORED !!![0m
[33m- 5282 !!! IGNORED !!![0m
[33m- 5283 !!! IGNORED !!![0m
[33m- 5284 !!! IGNORED !!![0m
[33m- 5285 !!! IGNORED !!![0m
[33m- 5286 !!! IGNORED !!![0m
[33m- 5287 !!! IGNORED !!![0m
[33m- 5288 !!! IGNORED !!![0m
[33m- 5289 !!! IGNORED !!![0m
[33m- 5290 !!! IGNORED !!![0m
[33m- 5291 !!! IGNORED !!![0m
[33m- 5292 !!! IGNORED !!![0m
[33m- 5293 !!! IGNORED !!![0m
[33m- 5294 !!! IGNORED !!![0m
[33m- 5295 !!! IGNORED !!![0m
[33m- 5296 !!! IGNORED !!![0m
[33m- 5297 !!! IGNORED !!![0m
[33m- 5298 !!! IGNORED !!![0m
[33m- 5299 !!! IGNORED !!![0m
[33m- 5300 !!! IGNORED !!![0m
[33m- 5301 !!! IGNORED !!![0m
[33m- 5302 !!! IGNORED !!![0m
[33m- 5303 !!! IGNORED !!![0m
[33m- 5304 !!! IGNORED !!![0m
[33m- 5305 !!! IGNORED !!![0m
[33m- 5306 !!! IGNORED !!![0m
[33m- 5307 !!! IGNORED !!![0m
[33m- 5308 !!! IGNORED !!![0m
[33m- 5309 !!! IGNORED !!![0m
[33m- 5310 !!! IGNORED !!![0m
[33m- 5311 !!! IGNORED !!![0m
[33m- 5312 !!! IGNORED !!![0m
[33m- 5313 !!! IGNORED !!![0m
[33m- 5314 !!! IGNORED !!![0m
[33m- 5315 !!! IGNORED !!![0m
[33m- 5316 !!! IGNORED !!![0m
[33m- 5317 !!! IGNORED !!![0m
[33m- 5318 !!! IGNORED !!![0m
[33m- 5319 !!! IGNORED !!![0m
[33m- 5320 !!! IGNORED !!![0m
[33m- 5321 !!! IGNORED !!![0m
[33m- 5322 !!! IGNORED !!![0m
[33m- 5323 !!! IGNORED !!![0m
[33m- 5324 !!! IGNORED !!![0m
[33m- 5325 !!! IGNORED !!![0m
[33m- 5326 !!! IGNORED !!![0m
[33m- 5327 !!! IGNORED !!![0m
[33m- 5328 !!! IGNORED !!![0m
[33m- 5329 !!! IGNORED !!![0m
[33m- 5330 !!! IGNORED !!![0m
[33m- 5331 !!! IGNORED !!![0m
[33m- 5332 !!! IGNORED !!![0m
[33m- 5333 !!! IGNORED !!![0m
[33m- 5334 !!! IGNORED !!![0m
[33m- 5335 !!! IGNORED !!![0m
[33m- 5336 !!! IGNORED !!![0m
[33m- 5337 !!! IGNORED !!![0m
[33m- 5338 !!! IGNORED !!![0m
[33m- 5339 !!! IGNORED !!![0m
[33m- 5340 !!! IGNORED !!![0m
[33m- 5341 !!! IGNORED !!![0m
[33m- 5342 !!! IGNORED !!![0m
[33m- 5343 !!! IGNORED !!![0m
[33m- 5344 !!! IGNORED !!![0m
[33m- 5345 !!! IGNORED !!![0m
[33m- 5346 !!! IGNORED !!![0m
[33m- 5347 !!! IGNORED !!![0m
[33m- 5348 !!! IGNORED !!![0m
[33m- 5349 !!! IGNORED !!![0m
[33m- 5350 !!! IGNORED !!![0m
[33m- 5351 !!! IGNORED !!![0m
[33m- 5352 !!! IGNORED !!![0m
[33m- 5353 !!! IGNORED !!![0m
[33m- 5354 !!! IGNORED !!![0m
[33m- 5355 !!! IGNORED !!![0m
[33m- 5356 !!! IGNORED !!![0m
[33m- 5357 !!! IGNORED !!![0m
[33m- 5358 !!! IGNORED !!![0m
[33m- 5359 !!! IGNORED !!![0m
[33m- 5360 !!! IGNORED !!![0m
[33m- 5361 !!! IGNORED !!![0m
[33m- 5362 !!! IGNORED !!![0m
[33m- 5363 !!! IGNORED !!![0m
[33m- 5364 !!! IGNORED !!![0m
[33m- 5365 !!! IGNORED !!![0m
[33m- 5366 !!! IGNORED !!![0m
[33m- 5367 !!! IGNORED !!![0m
[33m- 5368 !!! IGNORED !!![0m
[33m- 5369 !!! IGNORED !!![0m
[33m- 5370 !!! IGNORED !!![0m
[33m- 5371 !!! IGNORED !!![0m
[33m- 5372 !!! IGNORED !!![0m
[33m- 5373 !!! IGNORED !!![0m
[33m- 5374 !!! IGNORED !!![0m
[33m- 5375 !!! IGNORED !!![0m
[33m- 5376 !!! IGNORED !!![0m
[33m- 5377 !!! IGNORED !!![0m
[33m- 5378 !!! IGNORED !!![0m
[33m- 5379 !!! IGNORED !!![0m
[33m- 5380 !!! IGNORED !!![0m
[33m- 5381 !!! IGNORED !!![0m
[33m- 5382 !!! IGNORED !!![0m
[33m- 5383 !!! IGNORED !!![0m
[33m- 5384 !!! IGNORED !!![0m
[33m- 5385 !!! IGNORED !!![0m
[33m- 5386 !!! IGNORED !!![0m
[33m- 5387 !!! IGNORED !!![0m
[33m- 5388 !!! IGNORED !!![0m
[33m- 5389 !!! IGNORED !!![0m
[33m- 5390 !!! IGNORED !!![0m
[33m- 5391 !!! IGNORED !!![0m
[33m- 5392 !!! IGNORED !!![0m
[33m- 5393 !!! IGNORED !!![0m
[33m- 5394 !!! IGNORED !!![0m
[33m- 5395 !!! IGNORED !!![0m
[33m- 5396 !!! IGNORED !!![0m
[33m- 5397 !!! IGNORED !!![0m
[33m- 5398 !!! IGNORED !!![0m
[33m- 5399 !!! IGNORED !!![0m
[33m- 5400 !!! IGNORED !!![0m
[33m- 5401 !!! IGNORED !!![0m
[33m- 5402 !!! IGNORED !!![0m
[33m- 5403 !!! IGNORED !!![0m
[33m- 5404 !!! IGNORED !!![0m
[33m- 5405 !!! IGNORED !!![0m
[33m- 5406 !!! IGNORED !!![0m
[33m- 5407 !!! IGNORED !!![0m
[33m- 5408 !!! IGNORED !!![0m
[33m- 5409 !!! IGNORED !!![0m
[33m- 5410 !!! IGNORED !!![0m
[33m- 5411 !!! IGNORED !!![0m
[33m- 5412 !!! IGNORED !!![0m
[33m- 5413 !!! IGNORED !!![0m
[33m- 5414 !!! IGNORED !!![0m
[33m- 5415 !!! IGNORED !!![0m
[33m- 5416 !!! IGNORED !!![0m
[33m- 5417 !!! IGNORED !!![0m
[33m- 5418 !!! IGNORED !!![0m
[33m- 5419 !!! IGNORED !!![0m
[33m- 5420 !!! IGNORED !!![0m
[33m- 5421 !!! IGNORED !!![0m
[33m- 5422 !!! IGNORED !!![0m
[33m- 5423 !!! IGNORED !!![0m
[33m- 5424 !!! IGNORED !!![0m
[33m- 5425 !!! IGNORED !!![0m
[33m- 5426 !!! IGNORED !!![0m
[33m- 5427 !!! IGNORED !!![0m
[33m- 5428 !!! IGNORED !!![0m
[33m- 5429 !!! IGNORED !!![0m
[33m- 5430 !!! IGNORED !!![0m
[33m- 5431 !!! IGNORED !!![0m
[33m- 5432 !!! IGNORED !!![0m
[33m- 5433 !!! IGNORED !!![0m
[33m- 5434 !!! IGNORED !!![0m
[33m- 5435 !!! IGNORED !!![0m
[33m- 5436 !!! IGNORED !!![0m
[33m- 5437 !!! IGNORED !!![0m
[33m- 5438 !!! IGNORED !!![0m
[33m- 5439 !!! IGNORED !!![0m
[33m- 5440 !!! IGNORED !!![0m
[33m- 5441 !!! IGNORED !!![0m
[33m- 5442 !!! IGNORED !!![0m
[33m- 5443 !!! IGNORED !!![0m
[33m- 5444 !!! IGNORED !!![0m
[33m- 5445 !!! IGNORED !!![0m
[33m- 5446 !!! IGNORED !!![0m
[33m- 5447 !!! IGNORED !!![0m
[33m- 5448 !!! IGNORED !!![0m
[33m- 5449 !!! IGNORED !!![0m
[33m- 5450 !!! IGNORED !!![0m
[33m- 5451 !!! IGNORED !!![0m
[33m- 5452 !!! IGNORED !!![0m
[33m- 5453 !!! IGNORED !!![0m
[33m- 5454 !!! IGNORED !!![0m
[33m- 5455 !!! IGNORED !!![0m
[33m- 5456 !!! IGNORED !!![0m
[33m- 5457 !!! IGNORED !!![0m
[33m- 5458 !!! IGNORED !!![0m
[33m- 5459 !!! IGNORED !!![0m
[33m- 5460 !!! IGNORED !!![0m
[33m- 5461 !!! IGNORED !!![0m
[33m- 5462 !!! IGNORED !!![0m
[33m- 5463 !!! IGNORED !!![0m
[33m- 5464 !!! IGNORED !!![0m
[33m- 5465 !!! IGNORED !!![0m
[33m- 5466 !!! IGNORED !!![0m
[33m- 5467 !!! IGNORED !!![0m
[33m- 5468 !!! IGNORED !!![0m
[33m- 5469 !!! IGNORED !!![0m
[33m- 5470 !!! IGNORED !!![0m
[33m- 5471 !!! IGNORED !!![0m
[33m- 5472 !!! IGNORED !!![0m
[33m- 5473 !!! IGNORED !!![0m
[33m- 5474 !!! IGNORED !!![0m
[33m- 5475 !!! IGNORED !!![0m
[33m- 5476 !!! IGNORED !!![0m
[33m- 5477 !!! IGNORED !!![0m
[33m- 5478 !!! IGNORED !!![0m
[33m- 5479 !!! IGNORED !!![0m
[33m- 5480 !!! IGNORED !!![0m
[33m- 5481 !!! IGNORED !!![0m
[33m- 5482 !!! IGNORED !!![0m
[33m- 5483 !!! IGNORED !!![0m
[33m- 5484 !!! IGNORED !!![0m
[33m- 5485 !!! IGNORED !!![0m
[33m- 5486 !!! IGNORED !!![0m
[33m- 5487 !!! IGNORED !!![0m
[33m- 5488 !!! IGNORED !!![0m
[33m- 5489 !!! IGNORED !!![0m
[33m- 5490 !!! IGNORED !!![0m
[33m- 5491 !!! IGNORED !!![0m
[33m- 5492 !!! IGNORED !!![0m
[33m- 5493 !!! IGNORED !!![0m
[33m- 5494 !!! IGNORED !!![0m
[33m- 5495 !!! IGNORED !!![0m
[33m- 5496 !!! IGNORED !!![0m
[33m- 5497 !!! IGNORED !!![0m
[33m- 5498 !!! IGNORED !!![0m
[33m- 5499 !!! IGNORED !!![0m
[33m- 5500 !!! IGNORED !!![0m
[33m- 5501 !!! IGNORED !!![0m
[33m- 5502 !!! IGNORED !!![0m
[33m- 5503 !!! IGNORED !!![0m
[33m- 5504 !!! IGNORED !!![0m
[33m- 5505 !!! IGNORED !!![0m
[33m- 5506 !!! IGNORED !!![0m
[33m- 5507 !!! IGNORED !!![0m
[33m- 5508 !!! IGNORED !!![0m
[33m- 5509 !!! IGNORED !!![0m
[33m- 5510 !!! IGNORED !!![0m
[33m- 5511 !!! IGNORED !!![0m
[33m- 5512 !!! IGNORED !!![0m
[33m- 5513 !!! IGNORED !!![0m
[33m- 5514 !!! IGNORED !!![0m
[33m- 5515 !!! IGNORED !!![0m
[33m- 5516 !!! IGNORED !!![0m
[33m- 5517 !!! IGNORED !!![0m
[33m- 5518 !!! IGNORED !!![0m
[33m- 5519 !!! IGNORED !!![0m
[33m- 5520 !!! IGNORED !!![0m
[33m- 5521 !!! IGNORED !!![0m
[33m- 5522 !!! IGNORED !!![0m
[33m- 5523 !!! IGNORED !!![0m
[33m- 5524 !!! IGNORED !!![0m
[33m- 5525 !!! IGNORED !!![0m
[33m- 5526 !!! IGNORED !!![0m
[33m- 5527 !!! IGNORED !!![0m
[33m- 5528 !!! IGNORED !!![0m
[33m- 5529 !!! IGNORED !!![0m
[33m- 5530 !!! IGNORED !!![0m
[33m- 5531 !!! IGNORED !!![0m
[33m- 5532 !!! IGNORED !!![0m
[33m- 5533 !!! IGNORED !!![0m
[33m- 5534 !!! IGNORED !!![0m
[33m- 5535 !!! IGNORED !!![0m
[33m- 5536 !!! IGNORED !!![0m
[33m- 5537 !!! IGNORED !!![0m
[33m- 5538 !!! IGNORED !!![0m
[33m- 5539 !!! IGNORED !!![0m
[33m- 5540 !!! IGNORED !!![0m
[33m- 5541 !!! IGNORED !!![0m
[33m- 5542 !!! IGNORED !!![0m
[33m- 5543 !!! IGNORED !!![0m
[33m- 5544 !!! IGNORED !!![0m
[33m- 5545 !!! IGNORED !!![0m
[33m- 5546 !!! IGNORED !!![0m
[33m- 5547 !!! IGNORED !!![0m
[33m- 5548 !!! IGNORED !!![0m
[33m- 5549 !!! IGNORED !!![0m
[33m- 5550 !!! IGNORED !!![0m
[33m- 5551 !!! IGNORED !!![0m
[33m- 5552 !!! IGNORED !!![0m
[33m- 5553 !!! IGNORED !!![0m
[33m- 5554 !!! IGNORED !!![0m
[33m- 5555 !!! IGNORED !!![0m
[33m- 5556 !!! IGNORED !!![0m
[33m- 5557 !!! IGNORED !!![0m
[33m- 5558 !!! IGNORED !!![0m
[33m- 5559 !!! IGNORED !!![0m
[33m- 5560 !!! IGNORED !!![0m
[33m- 5561 !!! IGNORED !!![0m
[33m- 5562 !!! IGNORED !!![0m
[33m- 5563 !!! IGNORED !!![0m
[33m- 5564 !!! IGNORED !!![0m
[33m- 5565 !!! IGNORED !!![0m
[33m- 5566 !!! IGNORED !!![0m
[33m- 5567 !!! IGNORED !!![0m
[33m- 5568 !!! IGNORED !!![0m
[33m- 5569 !!! IGNORED !!![0m
[33m- 5570 !!! IGNORED !!![0m
[33m- 5571 !!! IGNORED !!![0m
[33m- 5572 !!! IGNORED !!![0m
[33m- 5573 !!! IGNORED !!![0m
[33m- 5574 !!! IGNORED !!![0m
[33m- 5575 !!! IGNORED !!![0m
[33m- 5576 !!! IGNORED !!![0m
[33m- 5577 !!! IGNORED !!![0m
[33m- 5578 !!! IGNORED !!![0m
[33m- 5579 !!! IGNORED !!![0m
[33m- 5580 !!! IGNORED !!![0m
[33m- 5581 !!! IGNORED !!![0m
[33m- 5582 !!! IGNORED !!![0m
[33m- 5583 !!! IGNORED !!![0m
[33m- 5584 !!! IGNORED !!![0m
[33m- 5585 !!! IGNORED !!![0m
[33m- 5586 !!! IGNORED !!![0m
[33m- 5587 !!! IGNORED !!![0m
[33m- 5588 !!! IGNORED !!![0m
[33m- 5589 !!! IGNORED !!![0m
[33m- 5590 !!! IGNORED !!![0m
[33m- 5591 !!! IGNORED !!![0m
[33m- 5592 !!! IGNORED !!![0m
[33m- 5593 !!! IGNORED !!![0m
[33m- 5594 !!! IGNORED !!![0m
[33m- 5595 !!! IGNORED !!![0m
[33m- 5596 !!! IGNORED !!![0m
[33m- 5597 !!! IGNORED !!![0m
[33m- 5598 !!! IGNORED !!![0m
[33m- 5599 !!! IGNORED !!![0m
[33m- 5600 !!! IGNORED !!![0m
[33m- 5601 !!! IGNORED !!![0m
[33m- 5602 !!! IGNORED !!![0m
[33m- 5603 !!! IGNORED !!![0m
[33m- 5604 !!! IGNORED !!![0m
[33m- 5605 !!! IGNORED !!![0m
[33m- 5606 !!! IGNORED !!![0m
[33m- 5607 !!! IGNORED !!![0m
[33m- 5608 !!! IGNORED !!![0m
[33m- 5609 !!! IGNORED !!![0m
[33m- 5610 !!! IGNORED !!![0m
[33m- 5611 !!! IGNORED !!![0m
[33m- 5612 !!! IGNORED !!![0m
[33m- 5613 !!! IGNORED !!![0m
[33m- 5614 !!! IGNORED !!![0m
[33m- 5615 !!! IGNORED !!![0m
[33m- 5616 !!! IGNORED !!![0m
[33m- 5617 !!! IGNORED !!![0m
[33m- 5618 !!! IGNORED !!![0m
[33m- 5619 !!! IGNORED !!![0m
[33m- 5620 !!! IGNORED !!![0m
[33m- 5621 !!! IGNORED !!![0m
[33m- 5622 !!! IGNORED !!![0m
[33m- 5623 !!! IGNORED !!![0m
[33m- 5624 !!! IGNORED !!![0m
[33m- 5625 !!! IGNORED !!![0m
[33m- 5626 !!! IGNORED !!![0m
[33m- 5627 !!! IGNORED !!![0m
[33m- 5628 !!! IGNORED !!![0m
[33m- 5629 !!! IGNORED !!![0m
[33m- 5630 !!! IGNORED !!![0m
[33m- 5631 !!! IGNORED !!![0m
[33m- 5632 !!! IGNORED !!![0m
[33m- 5633 !!! IGNORED !!![0m
[33m- 5634 !!! IGNORED !!![0m
[33m- 5635 !!! IGNORED !!![0m
[33m- 5636 !!! IGNORED !!![0m
[33m- 5637 !!! IGNORED !!![0m
[33m- 5638 !!! IGNORED !!![0m
[33m- 5639 !!! IGNORED !!![0m
[33m- 5640 !!! IGNORED !!![0m
[33m- 5641 !!! IGNORED !!![0m
[33m- 5642 !!! IGNORED !!![0m
[33m- 5643 !!! IGNORED !!![0m
[33m- 5644 !!! IGNORED !!![0m
[33m- 5645 !!! IGNORED !!![0m
[33m- 5646 !!! IGNORED !!![0m
[33m- 5647 !!! IGNORED !!![0m
[33m- 5648 !!! IGNORED !!![0m
[33m- 5649 !!! IGNORED !!![0m
[33m- 5650 !!! IGNORED !!![0m
[33m- 5651 !!! IGNORED !!![0m
[33m- 5652 !!! IGNORED !!![0m
[33m- 5653 !!! IGNORED !!![0m
[33m- 5654 !!! IGNORED !!![0m
[33m- 5655 !!! IGNORED !!![0m
[33m- 5656 !!! IGNORED !!![0m
[33m- 5657 !!! IGNORED !!![0m
[33m- 5658 !!! IGNORED !!![0m
[33m- 5659 !!! IGNORED !!![0m
[33m- 5660 !!! IGNORED !!![0m
[33m- 5661 !!! IGNORED !!![0m
[33m- 5662 !!! IGNORED !!![0m
[33m- 5663 !!! IGNORED !!![0m
[33m- 5664 !!! IGNORED !!![0m
[33m- 5665 !!! IGNORED !!![0m
[33m- 5666 !!! IGNORED !!![0m
[33m- 5667 !!! IGNORED !!![0m
[33m- 5668 !!! IGNORED !!![0m
[33m- 5669 !!! IGNORED !!![0m
[33m- 5670 !!! IGNORED !!![0m
[33m- 5671 !!! IGNORED !!![0m
[33m- 5672 !!! IGNORED !!![0m
[33m- 5673 !!! IGNORED !!![0m
[33m- 5674 !!! IGNORED !!![0m
[33m- 5675 !!! IGNORED !!![0m
[33m- 5676 !!! IGNORED !!![0m
[33m- 5677 !!! IGNORED !!![0m
[33m- 5678 !!! IGNORED !!![0m
[33m- 5679 !!! IGNORED !!![0m
[33m- 5680 !!! IGNORED !!![0m
[33m- 5681 !!! IGNORED !!![0m
[33m- 5682 !!! IGNORED !!![0m
[33m- 5683 !!! IGNORED !!![0m
[33m- 5684 !!! IGNORED !!![0m
[33m- 5685 !!! IGNORED !!![0m
[33m- 5686 !!! IGNORED !!![0m
[33m- 5687 !!! IGNORED !!![0m
[33m- 5688 !!! IGNORED !!![0m
[33m- 5689 !!! IGNORED !!![0m
[33m- 5690 !!! IGNORED !!![0m
[33m- 5691 !!! IGNORED !!![0m
[33m- 5692 !!! IGNORED !!![0m
[33m- 5693 !!! IGNORED !!![0m
[33m- 5694 !!! IGNORED !!![0m
[33m- 5695 !!! IGNORED !!![0m
[33m- 5696 !!! IGNORED !!![0m
[33m- 5697 !!! IGNORED !!![0m
[33m- 5698 !!! IGNORED !!![0m
[33m- 5699 !!! IGNORED !!![0m
[33m- 5700 !!! IGNORED !!![0m
[33m- 5701 !!! IGNORED !!![0m
[33m- 5702 !!! IGNORED !!![0m
[33m- 5703 !!! IGNORED !!![0m
[33m- 5704 !!! IGNORED !!![0m
[33m- 5705 !!! IGNORED !!![0m
[33m- 5706 !!! IGNORED !!![0m
[33m- 5707 !!! IGNORED !!![0m
[33m- 5708 !!! IGNORED !!![0m
[33m- 5709 !!! IGNORED !!![0m
[33m- 5710 !!! IGNORED !!![0m
[33m- 5711 !!! IGNORED !!![0m
[33m- 5712 !!! IGNORED !!![0m
[33m- 5713 !!! IGNORED !!![0m
[33m- 5714 !!! IGNORED !!![0m
[33m- 5715 !!! IGNORED !!![0m
[33m- 5716 !!! IGNORED !!![0m
[33m- 5717 !!! IGNORED !!![0m
[33m- 5718 !!! IGNORED !!![0m
[33m- 5719 !!! IGNORED !!![0m
[33m- 5720 !!! IGNORED !!![0m
[33m- 5721 !!! IGNORED !!![0m
[33m- 5722 !!! IGNORED !!![0m
[33m- 5723 !!! IGNORED !!![0m
[33m- 5724 !!! IGNORED !!![0m
[33m- 5725 !!! IGNORED !!![0m
[33m- 5726 !!! IGNORED !!![0m
[33m- 5727 !!! IGNORED !!![0m
[33m- 5728 !!! IGNORED !!![0m
[33m- 5729 !!! IGNORED !!![0m
[33m- 5730 !!! IGNORED !!![0m
[33m- 5731 !!! IGNORED !!![0m
[33m- 5732 !!! IGNORED !!![0m
[33m- 5733 !!! IGNORED !!![0m
[33m- 5734 !!! IGNORED !!![0m
[33m- 5735 !!! IGNORED !!![0m
[33m- 5736 !!! IGNORED !!![0m
[33m- 5737 !!! IGNORED !!![0m
[33m- 5738 !!! IGNORED !!![0m
[33m- 5739 !!! IGNORED !!![0m
[33m- 5740 !!! IGNORED !!![0m
[33m- 5741 !!! IGNORED !!![0m
[33m- 5742 !!! IGNORED !!![0m
[33m- 5743 !!! IGNORED !!![0m
[33m- 5744 !!! IGNORED !!![0m
[33m- 5745 !!! IGNORED !!![0m
[33m- 5746 !!! IGNORED !!![0m
[33m- 5747 !!! IGNORED !!![0m
[33m- 5748 !!! IGNORED !!![0m
[33m- 5749 !!! IGNORED !!![0m
[33m- 5750 !!! IGNORED !!![0m
[33m- 5751 !!! IGNORED !!![0m
[33m- 5752 !!! IGNORED !!![0m
[33m- 5753 !!! IGNORED !!![0m
[33m- 5754 !!! IGNORED !!![0m
[33m- 5755 !!! IGNORED !!![0m
[33m- 5756 !!! IGNORED !!![0m
[33m- 5757 !!! IGNORED !!![0m
[33m- 5758 !!! IGNORED !!![0m
[33m- 5759 !!! IGNORED !!![0m
[33m- 5760 !!! IGNORED !!![0m
[33m- 5761 !!! IGNORED !!![0m
[33m- 5762 !!! IGNORED !!![0m
[33m- 5763 !!! IGNORED !!![0m
[33m- 5764 !!! IGNORED !!![0m
[33m- 5765 !!! IGNORED !!![0m
[33m- 5766 !!! IGNORED !!![0m
[33m- 5767 !!! IGNORED !!![0m
[33m- 5768 !!! IGNORED !!![0m
[33m- 5769 !!! IGNORED !!![0m
[33m- 5770 !!! IGNORED !!![0m
[33m- 5771 !!! IGNORED !!![0m
[33m- 5772 !!! IGNORED !!![0m
[33m- 5773 !!! IGNORED !!![0m
[33m- 5774 !!! IGNORED !!![0m
[33m- 5775 !!! IGNORED !!![0m
[33m- 5776 !!! IGNORED !!![0m
[33m- 5777 !!! IGNORED !!![0m
[33m- 5778 !!! IGNORED !!![0m
[33m- 5779 !!! IGNORED !!![0m
[33m- 5780 !!! IGNORED !!![0m
[33m- 5781 !!! IGNORED !!![0m
[33m- 5782 !!! IGNORED !!![0m
[33m- 5783 !!! IGNORED !!![0m
[33m- 5784 !!! IGNORED !!![0m
[33m- 5785 !!! IGNORED !!![0m
[33m- 5786 !!! IGNORED !!![0m
[33m- 5787 !!! IGNORED !!![0m
[33m- 5788 !!! IGNORED !!![0m
[33m- 5789 !!! IGNORED !!![0m
[33m- 5790 !!! IGNORED !!![0m
[33m- 5791 !!! IGNORED !!![0m
[33m- 5792 !!! IGNORED !!![0m
[33m- 5793 !!! IGNORED !!![0m
[33m- 5794 !!! IGNORED !!![0m
[33m- 5795 !!! IGNORED !!![0m
[33m- 5796 !!! IGNORED !!![0m
[33m- 5797 !!! IGNORED !!![0m
[33m- 5798 !!! IGNORED !!![0m
[33m- 5799 !!! IGNORED !!![0m
[33m- 5800 !!! IGNORED !!![0m
[33m- 5801 !!! IGNORED !!![0m
[33m- 5802 !!! IGNORED !!![0m
[33m- 5803 !!! IGNORED !!![0m
[33m- 5804 !!! IGNORED !!![0m
[33m- 5805 !!! IGNORED !!![0m
[33m- 5806 !!! IGNORED !!![0m
[33m- 5807 !!! IGNORED !!![0m
[33m- 5808 !!! IGNORED !!![0m
[33m- 5809 !!! IGNORED !!![0m
[33m- 5810 !!! IGNORED !!![0m
[33m- 5811 !!! IGNORED !!![0m
[33m- 5812 !!! IGNORED !!![0m
[33m- 5813 !!! IGNORED !!![0m
[33m- 5814 !!! IGNORED !!![0m
[33m- 5815 !!! IGNORED !!![0m
[33m- 5816 !!! IGNORED !!![0m
[33m- 5817 !!! IGNORED !!![0m
[33m- 5818 !!! IGNORED !!![0m
[33m- 5819 !!! IGNORED !!![0m
[33m- 5820 !!! IGNORED !!![0m
[33m- 5821 !!! IGNORED !!![0m
[33m- 5822 !!! IGNORED !!![0m
[33m- 5823 !!! IGNORED !!![0m
[33m- 5824 !!! IGNORED !!![0m
[33m- 5825 !!! IGNORED !!![0m
[33m- 5826 !!! IGNORED !!![0m
[33m- 5827 !!! IGNORED !!![0m
[33m- 5828 !!! IGNORED !!![0m
[33m- 5829 !!! IGNORED !!![0m
[33m- 5830 !!! IGNORED !!![0m
[33m- 5831 !!! IGNORED !!![0m
[33m- 5832 !!! IGNORED !!![0m
[33m- 5833 !!! IGNORED !!![0m
[33m- 5834 !!! IGNORED !!![0m
[33m- 5835 !!! IGNORED !!![0m
[33m- 5836 !!! IGNORED !!![0m
[33m- 5837 !!! IGNORED !!![0m
[33m- 5838 !!! IGNORED !!![0m
[33m- 5839 !!! IGNORED !!![0m
[33m- 5840 !!! IGNORED !!![0m
[33m- 5841 !!! IGNORED !!![0m
[33m- 5842 !!! IGNORED !!![0m
[33m- 5843 !!! IGNORED !!![0m
[33m- 5844 !!! IGNORED !!![0m
[33m- 5845 !!! IGNORED !!![0m
[33m- 5846 !!! IGNORED !!![0m
[33m- 5847 !!! IGNORED !!![0m
[33m- 5848 !!! IGNORED !!![0m
[33m- 5849 !!! IGNORED !!![0m
[33m- 5850 !!! IGNORED !!![0m
[33m- 5851 !!! IGNORED !!![0m
[33m- 5852 !!! IGNORED !!![0m
[33m- 5853 !!! IGNORED !!![0m
[33m- 5854 !!! IGNORED !!![0m
[33m- 5855 !!! IGNORED !!![0m
[33m- 5856 !!! IGNORED !!![0m
[33m- 5857 !!! IGNORED !!![0m
[33m- 5858 !!! IGNORED !!![0m
[33m- 5859 !!! IGNORED !!![0m
[33m- 5860 !!! IGNORED !!![0m
[33m- 5861 !!! IGNORED !!![0m
[33m- 5862 !!! IGNORED !!![0m
[33m- 5863 !!! IGNORED !!![0m
[33m- 5864 !!! IGNORED !!![0m
[33m- 5865 !!! IGNORED !!![0m
[33m- 5866 !!! IGNORED !!![0m
[33m- 5867 !!! IGNORED !!![0m
[33m- 5868 !!! IGNORED !!![0m
[33m- 5869 !!! IGNORED !!![0m
[33m- 5870 !!! IGNORED !!![0m
[33m- 5871 !!! IGNORED !!![0m
[33m- 5872 !!! IGNORED !!![0m
[33m- 5873 !!! IGNORED !!![0m
[33m- 5874 !!! IGNORED !!![0m
[33m- 5875 !!! IGNORED !!![0m
[33m- 5876 !!! IGNORED !!![0m
[33m- 5877 !!! IGNORED !!![0m
[33m- 5878 !!! IGNORED !!![0m
[33m- 5879 !!! IGNORED !!![0m
[33m- 5880 !!! IGNORED !!![0m
[33m- 5881 !!! IGNORED !!![0m
[33m- 5882 !!! IGNORED !!![0m
[33m- 5883 !!! IGNORED !!![0m
[33m- 5884 !!! IGNORED !!![0m
[33m- 5885 !!! IGNORED !!![0m
[33m- 5886 !!! IGNORED !!![0m
[33m- 5887 !!! IGNORED !!![0m
[33m- 5888 !!! IGNORED !!![0m
[33m- 5889 !!! IGNORED !!![0m
[33m- 5890 !!! IGNORED !!![0m
[33m- 5891 !!! IGNORED !!![0m
[33m- 5892 !!! IGNORED !!![0m
[33m- 5893 !!! IGNORED !!![0m
[33m- 5894 !!! IGNORED !!![0m
[33m- 5895 !!! IGNORED !!![0m
[33m- 5896 !!! IGNORED !!![0m
[33m- 5897 !!! IGNORED !!![0m
[33m- 5898 !!! IGNORED !!![0m
[33m- 5899 !!! IGNORED !!![0m
[33m- 5900 !!! IGNORED !!![0m
[33m- 5901 !!! IGNORED !!![0m
[33m- 5902 !!! IGNORED !!![0m
[33m- 5903 !!! IGNORED !!![0m
[33m- 5904 !!! IGNORED !!![0m
[33m- 5905 !!! IGNORED !!![0m
[33m- 5906 !!! IGNORED !!![0m
[33m- 5907 !!! IGNORED !!![0m
[33m- 5908 !!! IGNORED !!![0m
[33m- 5909 !!! IGNORED !!![0m
[33m- 5910 !!! IGNORED !!![0m
[33m- 5911 !!! IGNORED !!![0m
[33m- 5912 !!! IGNORED !!![0m
[33m- 5913 !!! IGNORED !!![0m
[33m- 5914 !!! IGNORED !!![0m
[33m- 5915 !!! IGNORED !!![0m
[33m- 5916 !!! IGNORED !!![0m
[33m- 5917 !!! IGNORED !!![0m
[33m- 5918 !!! IGNORED !!![0m
[33m- 5919 !!! IGNORED !!![0m
[33m- 5920 !!! IGNORED !!![0m
[33m- 5921 !!! IGNORED !!![0m
[33m- 5922 !!! IGNORED !!![0m
[33m- 5923 !!! IGNORED !!![0m
[33m- 5924 !!! IGNORED !!![0m
[33m- 5925 !!! IGNORED !!![0m
[33m- 5926 !!! IGNORED !!![0m
[33m- 5927 !!! IGNORED !!![0m
[33m- 5928 !!! IGNORED !!![0m
[33m- 5929 !!! IGNORED !!![0m
[33m- 5930 !!! IGNORED !!![0m
[33m- 5931 !!! IGNORED !!![0m
[33m- 5932 !!! IGNORED !!![0m
[33m- 5933 !!! IGNORED !!![0m
[33m- 5934 !!! IGNORED !!![0m
[33m- 5935 !!! IGNORED !!![0m
[33m- 5936 !!! IGNORED !!![0m
[33m- 5937 !!! IGNORED !!![0m
[33m- 5938 !!! IGNORED !!![0m
[33m- 5939 !!! IGNORED !!![0m
[33m- 5940 !!! IGNORED !!![0m
[33m- 5941 !!! IGNORED !!![0m
[33m- 5942 !!! IGNORED !!![0m
[33m- 5943 !!! IGNORED !!![0m
[33m- 5944 !!! IGNORED !!![0m
[33m- 5945 !!! IGNORED !!![0m
[33m- 5946 !!! IGNORED !!![0m
[33m- 5947 !!! IGNORED !!![0m
[33m- 5948 !!! IGNORED !!![0m
[33m- 5949 !!! IGNORED !!![0m
[33m- 5950 !!! IGNORED !!![0m
[33m- 5951 !!! IGNORED !!![0m
[33m- 5952 !!! IGNORED !!![0m
[33m- 5953 !!! IGNORED !!![0m
[33m- 5954 !!! IGNORED !!![0m
[33m- 5955 !!! IGNORED !!![0m
[33m- 5956 !!! IGNORED !!![0m
[33m- 5957 !!! IGNORED !!![0m
[33m- 5958 !!! IGNORED !!![0m
[33m- 5959 !!! IGNORED !!![0m
[33m- 5960 !!! IGNORED !!![0m
[33m- 5961 !!! IGNORED !!![0m
[33m- 5962 !!! IGNORED !!![0m
[33m- 5963 !!! IGNORED !!![0m
[33m- 5964 !!! IGNORED !!![0m
[33m- 5965 !!! IGNORED !!![0m
[33m- 5966 !!! IGNORED !!![0m
[33m- 5967 !!! IGNORED !!![0m
[33m- 5968 !!! IGNORED !!![0m
[33m- 5969 !!! IGNORED !!![0m
[33m- 5970 !!! IGNORED !!![0m
[33m- 5971 !!! IGNORED !!![0m
[33m- 5972 !!! IGNORED !!![0m
[33m- 5973 !!! IGNORED !!![0m
[33m- 5974 !!! IGNORED !!![0m
[33m- 5975 !!! IGNORED !!![0m
[33m- 5976 !!! IGNORED !!![0m
[33m- 5977 !!! IGNORED !!![0m
[33m- 5978 !!! IGNORED !!![0m
[33m- 5979 !!! IGNORED !!![0m
[33m- 5980 !!! IGNORED !!![0m
[33m- 5981 !!! IGNORED !!![0m
[33m- 5982 !!! IGNORED !!![0m
[33m- 5983 !!! IGNORED !!![0m
[33m- 5984 !!! IGNORED !!![0m
[33m- 5985 !!! IGNORED !!![0m
[33m- 5986 !!! IGNORED !!![0m
[33m- 5987 !!! IGNORED !!![0m
[33m- 5988 !!! IGNORED !!![0m
[33m- 5989 !!! IGNORED !!![0m
[33m- 5990 !!! IGNORED !!![0m
[33m- 5991 !!! IGNORED !!![0m
[33m- 5992 !!! IGNORED !!![0m
[33m- 5993 !!! IGNORED !!![0m
[33m- 5994 !!! IGNORED !!![0m
[33m- 5995 !!! IGNORED !!![0m
[33m- 5996 !!! IGNORED !!![0m
[33m- 5997 !!! IGNORED !!![0m
[33m- 5998 !!! IGNORED !!![0m
[33m- 5999 !!! IGNORED !!![0m
[33m- 6000 !!! IGNORED !!![0m
[33m- 6001 !!! IGNORED !!![0m
[33m- 6002 !!! IGNORED !!![0m
[33m- 6003 !!! IGNORED !!![0m
[33m- 6004 !!! IGNORED !!![0m
[33m- 6005 !!! IGNORED !!![0m
[33m- 6006 !!! IGNORED !!![0m
[33m- 6007 !!! IGNORED !!![0m
[33m- 6008 !!! IGNORED !!![0m
[33m- 6009 !!! IGNORED !!![0m
[33m- 6010 !!! IGNORED !!![0m
[33m- 6011 !!! IGNORED !!![0m
[33m- 6012 !!! IGNORED !!![0m
[33m- 6013 !!! IGNORED !!![0m
[33m- 6014 !!! IGNORED !!![0m
[33m- 6015 !!! IGNORED !!![0m
[33m- 6016 !!! IGNORED !!![0m
[33m- 6017 !!! IGNORED !!![0m
[33m- 6018 !!! IGNORED !!![0m
[33m- 6019 !!! IGNORED !!![0m
[33m- 6020 !!! IGNORED !!![0m
[33m- 6021 !!! IGNORED !!![0m
[33m- 6022 !!! IGNORED !!![0m
[33m- 6023 !!! IGNORED !!![0m
[33m- 6024 !!! IGNORED !!![0m
[33m- 6025 !!! IGNORED !!![0m
[33m- 6026 !!! IGNORED !!![0m
[33m- 6027 !!! IGNORED !!![0m
[33m- 6028 !!! IGNORED !!![0m
[33m- 6029 !!! IGNORED !!![0m
[33m- 6030 !!! IGNORED !!![0m
[33m- 6031 !!! IGNORED !!![0m
[33m- 6032 !!! IGNORED !!![0m
[33m- 6033 !!! IGNORED !!![0m
[33m- 6034 !!! IGNORED !!![0m
[33m- 6035 !!! IGNORED !!![0m
[33m- 6036 !!! IGNORED !!![0m
[33m- 6037 !!! IGNORED !!![0m
[33m- 6038 !!! IGNORED !!![0m
[33m- 6039 !!! IGNORED !!![0m
[33m- 6040 !!! IGNORED !!![0m
[33m- 6041 !!! IGNORED !!![0m
[33m- 6042 !!! IGNORED !!![0m
[33m- 6043 !!! IGNORED !!![0m
[33m- 6044 !!! IGNORED !!![0m
[33m- 6045 !!! IGNORED !!![0m
[33m- 6046 !!! IGNORED !!![0m
[33m- 6047 !!! IGNORED !!![0m
[33m- 6048 !!! IGNORED !!![0m
[33m- 6049 !!! IGNORED !!![0m
[33m- 6050 !!! IGNORED !!![0m
[33m- 6051 !!! IGNORED !!![0m
[33m- 6052 !!! IGNORED !!![0m
[33m- 6053 !!! IGNORED !!![0m
[33m- 6054 !!! IGNORED !!![0m
[33m- 6055 !!! IGNORED !!![0m
[33m- 6056 !!! IGNORED !!![0m
[33m- 6057 !!! IGNORED !!![0m
[33m- 6058 !!! IGNORED !!![0m
[33m- 6059 !!! IGNORED !!![0m
[33m- 6060 !!! IGNORED !!![0m
[33m- 6061 !!! IGNORED !!![0m
[33m- 6062 !!! IGNORED !!![0m
[33m- 6063 !!! IGNORED !!![0m
[33m- 6064 !!! IGNORED !!![0m
[33m- 6065 !!! IGNORED !!![0m
[33m- 6066 !!! IGNORED !!![0m
[33m- 6067 !!! IGNORED !!![0m
[33m- 6068 !!! IGNORED !!![0m
[33m- 6069 !!! IGNORED !!![0m
[33m- 6070 !!! IGNORED !!![0m
[33m- 6071 !!! IGNORED !!![0m
[33m- 6072 !!! IGNORED !!![0m
[33m- 6073 !!! IGNORED !!![0m
[33m- 6074 !!! IGNORED !!![0m
[33m- 6075 !!! IGNORED !!![0m
[33m- 6076 !!! IGNORED !!![0m
[33m- 6077 !!! IGNORED !!![0m
[33m- 6078 !!! IGNORED !!![0m
[33m- 6079 !!! IGNORED !!![0m
[33m- 6080 !!! IGNORED !!![0m
[33m- 6081 !!! IGNORED !!![0m
[33m- 6082 !!! IGNORED !!![0m
[33m- 6083 !!! IGNORED !!![0m
[33m- 6084 !!! IGNORED !!![0m
[33m- 6085 !!! IGNORED !!![0m
[33m- 6086 !!! IGNORED !!![0m
[33m- 6087 !!! IGNORED !!![0m
[33m- 6088 !!! IGNORED !!![0m
[33m- 6089 !!! IGNORED !!![0m
[33m- 6090 !!! IGNORED !!![0m
[33m- 6091 !!! IGNORED !!![0m
[33m- 6092 !!! IGNORED !!![0m
[33m- 6093 !!! IGNORED !!![0m
[33m- 6094 !!! IGNORED !!![0m
[33m- 6095 !!! IGNORED !!![0m
[33m- 6096 !!! IGNORED !!![0m
[33m- 6097 !!! IGNORED !!![0m
[33m- 6098 !!! IGNORED !!![0m
[33m- 6099 !!! IGNORED !!![0m
[33m- 6100 !!! IGNORED !!![0m
[33m- 6101 !!! IGNORED !!![0m
[33m- 6102 !!! IGNORED !!![0m
[33m- 6103 !!! IGNORED !!![0m
[33m- 6104 !!! IGNORED !!![0m
[36mRun completed in 13 minutes, 56 seconds.[0m
[36mTotal number of tests run: 492[0m
[36mSuites: completed 2, aborted 0[0m
[36mTests: succeeded 324, failed 168, canceled 0, ignored 1660, pending 0[0m
[31m*** 168 TESTS FAILED ***[0m
[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 14:25 min
[INFO] Finished at: 2015-10-28T09:54:34+08:00
[INFO] Final Memory: 27M/1896M
[INFO] ------------------------------------------------------------------------
[ERROR] Failed to execute goal org.scalatest:scalatest-maven-plugin:1.0:test (test) on project spark-calcite-parser: There are test failures -> [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException
